{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1MpkPW5SsVv8fupv64RxGCghgWl6JKuVU","timestamp":1695961594111}],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyMdpLyHrbD1OpJAQQwXeWxX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PbOdBqxF_9sl","executionInfo":{"status":"ok","timestamp":1699113087080,"user_tz":240,"elapsed":19606,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}},"outputId":"e3d12a34-b6de-4596-80d0-666be76174b3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["**Code reference:** https://www.appsloveworld.com/python/1383/how-to-extract-foreground-objects-from-coco-dataset-or-open-images-v6-dataset?expand_article=1"],"metadata":{"id":"WuTpCy9iaLia"}},{"cell_type":"markdown","source":["### **Preprocess COCO dataset**"],"metadata":{"id":"0hmCPosKMJPR"}},{"cell_type":"code","source":["import os\n","import cv2 as cv\n","import numpy as np"],"metadata":{"id":"Hk4nEOUcMpqH","executionInfo":{"status":"ok","timestamp":1699113087400,"user_tz":240,"elapsed":323,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def extract_classwise_instances(samples, output_dir, label_field, ext=\".png\"):\n","    print(\"Extracting object instances...\")\n","    for sample in samples.iter_samples(progress=True):\n","        img = cv.imread(sample.filepath)\n","        img_h, img_w, c = img.shape\n","        for det in sample[label_field].detections:\n","            mask = det.mask\n","            [x, y, w, h] = det.bounding_box\n","            x = int(x * img_w)\n","            y = int(y * img_h)\n","            h, w = mask.shape\n","            mask_img = img[y:y+h, x:x+w, :]\n","            alpha = mask.astype(np.uint8)*255\n","            alpha = np.expand_dims(alpha, 2)\n","            mask_img = np.concatenate((mask_img, alpha), axis=2)\n","\n","            label = det.label\n","            label_dir = os.path.join(output_dir, label)\n","            if not os.path.exists(label_dir):\n","                os.mkdir(label_dir)\n","            output_filepath = os.path.join(label_dir, det.id+ext)\n","            cv.imwrite(output_filepath, mask_img)"],"metadata":{"id":"gFXePTrOMvoB","executionInfo":{"status":"ok","timestamp":1699113087401,"user_tz":240,"elapsed":8,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","def save_composite(samples, output_dir, label_field, ext=\".png\"):\n","    print(\"Saving composite images...\")\n","    for sample in samples.iter_samples(progress=True):\n","        img = cv.imread(sample.filepath)\n","        img_h, img_w, c = img.shape\n","        output_filepath = output_dir\n","\n","        counter = 0\n","        for i, det in enumerate(sample[label_field].detections):\n","            if counter > 0:\n","              break\n","            label = det.label\n","            label_dir = os.path.join(output_dir, label)\n","            if not os.path.exists(label_dir):\n","                os.mkdir(label_dir)\n","            output_filepath = os.path.join(label_dir, det.id+ext)\n","        cv.imwrite(output_filepath, img)\n","\"\"\""],"metadata":{"id":"s9ex5lm82aEU","executionInfo":{"status":"ok","timestamp":1699113087401,"user_tz":240,"elapsed":7,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}},"colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"a89d75fa-8eb4-4e89-843c-563fb674a50d"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ndef save_composite(samples, output_dir, label_field, ext=\".png\"):\\n    print(\"Saving composite images...\")\\n    for sample in samples.iter_samples(progress=True):\\n        img = cv.imread(sample.filepath)\\n        img_h, img_w, c = img.shape\\n        output_filepath = output_dir\\n\\n        counter = 0\\n        for i, det in enumerate(sample[label_field].detections):\\n            if counter > 0:\\n              break\\n            label = det.label\\n            label_dir = os.path.join(output_dir, label)\\n            if not os.path.exists(label_dir):\\n                os.mkdir(label_dir)\\n            output_filepath = os.path.join(label_dir, det.id+ext)\\n        cv.imwrite(output_filepath, img)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["!pip install fiftyone\n","!pip install fiftyone-db-ubuntu2204"],"metadata":{"id":"6U8FeIKbISdY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699113130103,"user_tz":240,"elapsed":42707,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}},"outputId":"8b16fb0e-ebe5-4571-a261-0ded37dcffee"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fiftyone\n","  Downloading fiftyone-0.22.3-py3-none-any.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles (from fiftyone)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Collecting argcomplete (from fiftyone)\n","  Downloading argcomplete-3.1.4-py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.11.2)\n","Collecting boto3 (from fiftyone)\n","  Downloading boto3-1.28.78-py3-none-any.whl (135 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.3.2)\n","Collecting dacite<1.8.0,>=1.6.0 (from fiftyone)\n","  Downloading dacite-1.7.0-py3-none-any.whl (12 kB)\n","Collecting Deprecated (from fiftyone)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Collecting ftfy (from fiftyone)\n","  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.7.0)\n","Collecting hypercorn>=0.13.2 (from fiftyone)\n","  Downloading hypercorn-0.15.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Jinja2>=3 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.1.2)\n","Collecting kaleido!=0.2.1.post1 (from fiftyone)\n","  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.7.1)\n","Collecting mongoengine==0.24.2 (from fiftyone)\n","  Downloading mongoengine-0.24.2-py3-none-any.whl (108 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting motor>=2.5 (from fiftyone)\n","  Downloading motor-3.3.1-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fiftyone) (23.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.5.3)\n","Requirement already satisfied: Pillow>=6.2 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (9.4.0)\n","Requirement already satisfied: plotly>=4.14 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.15.0)\n","Collecting pprintpp (from fiftyone)\n","  Downloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.9.5)\n","Collecting pymongo>=3.12 (from fiftyone)\n","  Downloading pymongo-4.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.1/677.1 kB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2023.3.post1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from fiftyone) (6.0.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2023.6.3)\n","Collecting retrying (from fiftyone)\n","  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.2.2)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.19.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (67.7.2)\n","Collecting sseclient-py<2,>=1.7.2 (from fiftyone)\n","  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n","Collecting sse-starlette<1,>=0.10.3 (from fiftyone)\n","  Downloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\n","Collecting starlette>=0.24.0 (from fiftyone)\n","  Downloading starlette-0.31.1-py3-none-any.whl (69 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.9/69.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting strawberry-graphql==0.138.1 (from fiftyone)\n","  Downloading strawberry_graphql-0.138.1-py3-none-any.whl (192 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.5/192.5 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.9.0)\n","Collecting xmltodict (from fiftyone)\n","  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n","Collecting universal-analytics-python3<2,>=1.0.1 (from fiftyone)\n","  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\n","Collecting fiftyone-brain~=0.13.2 (from fiftyone)\n","  Downloading fiftyone_brain-0.13.3-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fiftyone-db~=0.4 (from fiftyone)\n","  Downloading fiftyone_db-0.4.2.tar.gz (7.7 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting voxel51-eta~=0.12 (from fiftyone)\n","  Downloading voxel51_eta-0.12.0-py2.py3-none-any.whl (570 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.0/570.0 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.8.1.78)\n","Collecting graphql-core<3.3.0,>=3.2.0 (from strawberry-graphql==0.138.1->fiftyone)\n","  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (2.8.2)\n","Requirement already satisfied: typing_extensions<5.0.0,>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (4.5.0)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from fiftyone-brain~=0.13.2->fiftyone) (1.11.3)\n","Collecting h11 (from hypercorn>=0.13.2->fiftyone)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h2>=3.1.0 (from hypercorn>=0.13.2->fiftyone)\n","  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting priority (from hypercorn>=0.13.2->fiftyone)\n","  Downloading priority-2.0.0-py3-none-any.whl (8.9 kB)\n","Collecting taskgroup (from hypercorn>=0.13.2->fiftyone)\n","  Downloading taskgroup-0.0.0a4-py2.py3-none-any.whl (9.1 kB)\n","Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (2.0.1)\n","Collecting wsproto>=0.14.0 (from hypercorn>=0.13.2->fiftyone)\n","  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3->fiftyone) (2.1.3)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.14->fiftyone) (8.2.3)\n","Collecting dnspython<3.0.0,>=1.16.0 (from pymongo>=3.12->fiftyone)\n","  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette>=0.24.0->fiftyone) (3.7.1)\n","Collecting httpx>=0.10.0 (from universal-analytics-python3<2,>=1.0.1->fiftyone)\n","  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill (from voxel51-eta~=0.12->fiftyone)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (0.18.3)\n","Requirement already satisfied: glob2 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (0.7)\n","Collecting jsonlines (from voxel51-eta~=0.12->fiftyone)\n","  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n","Collecting py7zr (from voxel51-eta~=0.12->fiftyone)\n","  Downloading py7zr-0.20.6-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rarfile (from voxel51-eta~=0.12->fiftyone)\n","  Downloading rarfile-4.1-py3-none-any.whl (28 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (1.16.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (2.4.0)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (5.2)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12->fiftyone) (2.0.7)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->fiftyone) (2.5)\n","Collecting botocore<1.32.0,>=1.31.78 (from boto3->fiftyone)\n","  Downloading botocore-1.31.78-py3-none-any.whl (11.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->fiftyone)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.8.0,>=0.7.0 (from boto3->fiftyone)\n","  Downloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->fiftyone) (1.14.1)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->fiftyone) (0.2.8)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (4.43.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (3.1.1)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (3.2)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2023.9.26)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (1.4.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (3.2.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (3.4)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.1.3)\n","Collecting hyperframe<7,>=6.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n","  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n","Collecting hpack<5,>=4.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n","  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2023.7.22)\n","Collecting httpcore (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone)\n","  Downloading httpcore-1.0.1-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->voxel51-eta~=0.12->fiftyone) (23.1.0)\n","Collecting texttable (from py7zr->voxel51-eta~=0.12->fiftyone)\n","  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n","Collecting pycryptodomex>=3.6.6 (from py7zr->voxel51-eta~=0.12->fiftyone)\n","  Downloading pycryptodomex-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyzstd>=0.14.4 (from py7zr->voxel51-eta~=0.12->fiftyone)\n","  Downloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1 (from py7zr->voxel51-eta~=0.12->fiftyone)\n","  Downloading pyppmd-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pybcj>=0.6.0 (from py7zr->voxel51-eta~=0.12->fiftyone)\n","  Downloading pybcj-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr->voxel51-eta~=0.12->fiftyone)\n","  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n","Collecting brotli>=1.0.9 (from py7zr->voxel51-eta~=0.12->fiftyone)\n","  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting inflate64>=0.3.1 (from py7zr->voxel51-eta~=0.12->fiftyone)\n","  Downloading inflate64-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->voxel51-eta~=0.12->fiftyone) (3.3.1)\n","Building wheels for collected packages: fiftyone-db\n","  Building wheel for fiftyone-db (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fiftyone-db: filename=fiftyone_db-0.4.2-py3-none-manylinux1_x86_64.whl size=42156165 sha256=0f887c4dfaba21153c7d47c7c5036f5065eb39a0b9609405a2052a4cc3f075ab\n","  Stored in directory: /root/.cache/pip/wheels/5a/de/29/0fc86b17f83d9466513fa2c2182676983b5af53bb0b72ec1a7\n","Successfully built fiftyone-db\n","Installing collected packages: texttable, sseclient-py, pprintpp, kaleido, brotli, xmltodict, taskgroup, retrying, rarfile, pyzstd, pyppmd, pycryptodomex, pybcj, priority, multivolumefile, jsonlines, jmespath, inflate64, hyperframe, hpack, h11, graphql-core, ftfy, fiftyone-db, dnspython, dill, Deprecated, dacite, argcomplete, aiofiles, wsproto, strawberry-graphql, starlette, pymongo, py7zr, httpcore, h2, botocore, voxel51-eta, sse-starlette, s3transfer, motor, mongoengine, hypercorn, httpx, fiftyone-brain, universal-analytics-python3, boto3, fiftyone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Deprecated-1.2.14 aiofiles-23.2.1 argcomplete-3.1.4 boto3-1.28.78 botocore-1.31.78 brotli-1.1.0 dacite-1.7.0 dill-0.3.7 dnspython-2.4.2 fiftyone-0.22.3 fiftyone-brain-0.13.3 fiftyone-db-0.4.2 ftfy-6.1.1 graphql-core-3.2.3 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.1 httpx-0.25.1 hypercorn-0.15.0 hyperframe-6.0.1 inflate64-0.3.1 jmespath-1.0.1 jsonlines-4.0.0 kaleido-0.2.1 mongoengine-0.24.2 motor-3.3.1 multivolumefile-0.2.3 pprintpp-0.4.0 priority-2.0.0 py7zr-0.20.6 pybcj-1.0.1 pycryptodomex-3.19.0 pymongo-4.6.0 pyppmd-1.0.0 pyzstd-0.15.9 rarfile-4.1 retrying-1.3.4 s3transfer-0.7.0 sse-starlette-0.10.3 sseclient-py-1.8.0 starlette-0.31.1 strawberry-graphql-0.138.1 taskgroup-0.0.0a4 texttable-1.7.0 universal-analytics-python3-1.1.1 voxel51-eta-0.12.0 wsproto-1.2.0 xmltodict-0.13.0\n","Collecting fiftyone-db-ubuntu2204\n","  Downloading fiftyone_db_ubuntu2204-0.4.0-py3-none-manylinux1_x86_64.whl (42.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: fiftyone-db-ubuntu2204\n","Successfully installed fiftyone-db-ubuntu2204-0.4.0\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"GW0YoZnCGWE0","executionInfo":{"status":"ok","timestamp":1699113137288,"user_tz":240,"elapsed":7189,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"94cf885b-4195-4119-fb22-eade6ea383c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Migrating database to v0.22.3\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.migrations.runner:Migrating database to v0.22.3\n"]}],"source":["import fiftyone as fo\n","import fiftyone.zoo as foz\n","from fiftyone import ViewField as F"]},{"cell_type":"code","source":["\"\"\"\n","dataset_name = \"coco-image-example\"\n","if dataset_name in fo.list_datasets():\n","    fo.delete_dataset(dataset_name)\n","\"\"\""],"metadata":{"id":"vvgHIsRHIfaU","executionInfo":{"status":"ok","timestamp":1699113137289,"user_tz":240,"elapsed":9,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}},"colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"cd6cd708-1c0e-4622-dd94-fd609ca8fb21"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ndataset_name = \"coco-image-example\"\\nif dataset_name in fo.list_datasets():\\n    fo.delete_dataset(dataset_name)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["label_field = \"ground_truth\"\n","classes = [\"horse\", \"airplane\", \"toilet\", \"train\"]"],"metadata":{"id":"OtQkl5U4L5Km","executionInfo":{"status":"ok","timestamp":1699113137289,"user_tz":240,"elapsed":6,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["train_dataset = foz.load_zoo_dataset(\"coco-2017\",\n","                                     split=\"train\",\n","                                     label_types=[\"segmentations\"],\n","                                     classes=classes,\n","                                     # max_samples=6000,\n","                                     shuffle=True,\n","                                     label_field=label_field)\n","print(len(train_dataset))"],"metadata":{"id":"B6ZQTp3qMQZT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"90fd0b07-c728-4427-b643-70250f4f8e78","executionInfo":{"status":"ok","timestamp":1699114164436,"user_tz":240,"elapsed":1027153,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.zoo.datasets:Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"]},{"output_type":"stream","name":"stdout","text":["Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.utils.coco:Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"]},{"output_type":"stream","name":"stdout","text":[" 100% |██████|    1.9Gb/1.9Gb [6.4s elapsed, 0s remaining, 339.1Mb/s]       \n"]},{"output_type":"stream","name":"stderr","text":["INFO:eta.core.utils: 100% |██████|    1.9Gb/1.9Gb [6.4s elapsed, 0s remaining, 339.1Mb/s]       \n"]},{"output_type":"stream","name":"stdout","text":["Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.utils.coco:Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"]},{"output_type":"stream","name":"stdout","text":["Downloading 12825 images\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.utils.coco:Downloading 12825 images\n"]},{"output_type":"stream","name":"stdout","text":[" 100% |██████████████| 12825/12825 [14.4m elapsed, 0s remaining, 14.9 images/s]      \n"]},{"output_type":"stream","name":"stderr","text":["INFO:eta.core.utils: 100% |██████████████| 12825/12825 [14.4m elapsed, 0s remaining, 14.9 images/s]      \n"]},{"output_type":"stream","name":"stdout","text":["Writing annotations for 12825 downloaded samples to '/root/fiftyone/coco-2017/train/labels.json'\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.utils.coco:Writing annotations for 12825 downloaded samples to '/root/fiftyone/coco-2017/train/labels.json'\n"]},{"output_type":"stream","name":"stdout","text":["Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"]},{"output_type":"stream","name":"stdout","text":["Loading 'coco-2017' split 'train'\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'train'\n"]},{"output_type":"stream","name":"stdout","text":[" 100% |█████████████| 12825/12825 [2.1m elapsed, 0s remaining, 114.1 samples/s]      \n"]},{"output_type":"stream","name":"stderr","text":["INFO:eta.core.utils: 100% |█████████████| 12825/12825 [2.1m elapsed, 0s remaining, 114.1 samples/s]      \n"]},{"output_type":"stream","name":"stdout","text":["Dataset 'coco-2017-train' created\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-train' created\n"]},{"output_type":"stream","name":"stdout","text":["12825\n"]}]},{"cell_type":"code","source":["test_dataset = foz.load_zoo_dataset(\"coco-2017\",\n","                                    split=\"validation\",\n","                                    label_types=[\"segmentations\"],\n","                                    classes=classes,\n","                                    # max_samples=500,\n","                                    shuffle=True,\n","                                    label_field=label_field)\n","print(len(test_dataset))"],"metadata":{"id":"q71MMrg49fvD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699114207125,"user_tz":240,"elapsed":42706,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}},"outputId":"eb0eb4a4-a3e9-471b-e7dc-ac97db102033"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"]},{"output_type":"stream","name":"stdout","text":["Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.utils.coco:Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"]},{"output_type":"stream","name":"stdout","text":["Downloading 527 images\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.utils.coco:Downloading 527 images\n"]},{"output_type":"stream","name":"stdout","text":[" 100% |██████████████████| 527/527 [36.3s elapsed, 0s remaining, 15.3 images/s]      \n"]},{"output_type":"stream","name":"stderr","text":["INFO:eta.core.utils: 100% |██████████████████| 527/527 [36.3s elapsed, 0s remaining, 15.3 images/s]      \n"]},{"output_type":"stream","name":"stdout","text":["Writing annotations for 527 downloaded samples to '/root/fiftyone/coco-2017/validation/labels.json'\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.utils.coco:Writing annotations for 527 downloaded samples to '/root/fiftyone/coco-2017/validation/labels.json'\n"]},{"output_type":"stream","name":"stdout","text":["Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"]},{"output_type":"stream","name":"stdout","text":["Loading 'coco-2017' split 'validation'\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'validation'\n"]},{"output_type":"stream","name":"stdout","text":[" 100% |█████████████████| 527/527 [5.4s elapsed, 0s remaining, 92.1 samples/s]       \n"]},{"output_type":"stream","name":"stderr","text":["INFO:eta.core.utils: 100% |█████████████████| 527/527 [5.4s elapsed, 0s remaining, 92.1 samples/s]       \n"]},{"output_type":"stream","name":"stdout","text":["Dataset 'coco-2017-validation' created\n"]},{"output_type":"stream","name":"stderr","text":["INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-validation' created\n"]},{"output_type":"stream","name":"stdout","text":["527\n"]}]},{"cell_type":"code","source":["train_view = train_dataset.filter_labels(label_field, F(\"label\").is_in(classes))\n","print(train_view)\n","test_view = test_dataset.filter_labels(label_field, F(\"label\").is_in(classes))\n","print(test_view)"],"metadata":{"id":"FdhxGsZ2MWnr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699114207126,"user_tz":240,"elapsed":22,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}},"outputId":"e745be2d-192c-4534-9f9d-181db3fc847f"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset:     coco-2017-train\n","Media type:  image\n","Num samples: 12825\n","Sample fields:\n","    id:           fiftyone.core.fields.ObjectIdField\n","    filepath:     fiftyone.core.fields.StringField\n","    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n","    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n","    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n","View stages:\n","    1. FilterLabels(field='ground_truth', filter={'$in': ['$$this.label', [...]]}, only_matches=True, trajectories=False)\n","Dataset:     coco-2017-validation\n","Media type:  image\n","Num samples: 527\n","Sample fields:\n","    id:           fiftyone.core.fields.ObjectIdField\n","    filepath:     fiftyone.core.fields.StringField\n","    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n","    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n","    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n","View stages:\n","    1. FilterLabels(field='ground_truth', filter={'$in': ['$$this.label', [...]]}, only_matches=True, trajectories=False)\n"]}]},{"cell_type":"code","source":["foreground_train_output_dir = \"/data/foreground/train\"\n","foreground_test_output_dir = \"/data/foreground/test\"\n","# composite_train_output_dir = \"/data/composite/train\"\n","# composite_test_output_dir = \"/data/composite/test\"\n","\n","os.makedirs(foreground_train_output_dir, exist_ok=True)\n","os.makedirs(foreground_test_output_dir, exist_ok=True)\n","# os.makedirs(composite_train_output_dir, exist_ok=True)\n","# os.makedirs(composite_test_output_dir, exist_ok=True)"],"metadata":{"id":"AvhjTVqoMb72","executionInfo":{"status":"ok","timestamp":1699114207126,"user_tz":240,"elapsed":19,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["extract_classwise_instances(train_view, foreground_train_output_dir, label_field)\n","extract_classwise_instances(test_view, foreground_test_output_dir, label_field)"],"metadata":{"id":"sDPw0iSINaph","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699114418436,"user_tz":240,"elapsed":211329,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}},"outputId":"c7f77a82-a645-4af7-efc5-9d4e5addd2c4"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting object instances...\n"," 100% |█████████████| 12825/12825 [3.4m elapsed, 0s remaining, 64.6 samples/s]      \n"]},{"output_type":"stream","name":"stderr","text":["INFO:eta.core.utils: 100% |█████████████| 12825/12825 [3.4m elapsed, 0s remaining, 64.6 samples/s]      \n"]},{"output_type":"stream","name":"stdout","text":["Extracting object instances...\n"," 100% |█████████████████| 527/527 [8.0s elapsed, 0s remaining, 66.3 samples/s]      \n"]},{"output_type":"stream","name":"stderr","text":["INFO:eta.core.utils: 100% |█████████████████| 527/527 [8.0s elapsed, 0s remaining, 66.3 samples/s]      \n"]}]},{"cell_type":"code","source":["# save_composite(train_view, composite_train_output_dir, label_field)\n","# save_composite(test_view, composite_test_output_dir, label_field)"],"metadata":{"id":"0nKnJf32xRjl","executionInfo":{"status":"ok","timestamp":1699114418713,"user_tz":240,"elapsed":294,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["### **Turn preprocessed images into a custom dataset**"],"metadata":{"id":"GK3hyt5AsfrE"}},{"cell_type":"code","source":["import torch\n","from torchvision import transforms, datasets"],"metadata":{"id":"fKDrPnVxsk53","executionInfo":{"status":"ok","timestamp":1699114422799,"user_tz":240,"elapsed":4090,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["data_transform = transforms.Compose([transforms.ToTensor(),\n","                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                                          std=[0.229, 0.224, 0.225]),\n","                                     transforms.Resize([400, 600])])"],"metadata":{"id":"wNwdUef7srjX","executionInfo":{"status":"ok","timestamp":1699114422800,"user_tz":240,"elapsed":23,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","foreground_dataset = datasets.ImageFolder(root='/data/foreground',\n","                                          transform=data_transform)\n","\"\"\""],"metadata":{"id":"ZbpgKMxDs6F_","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1699114422800,"user_tz":240,"elapsed":23,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}},"outputId":"a77ba916-bf89-4157-8d43-4b1aa47d4a91"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nforeground_dataset = datasets.ImageFolder(root='/data/foreground',\\n                                          transform=data_transform)\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["\"\"\"\n","fore_dataset_loader = torch.utils.data.DataLoader(foreground_dataset,\n","                                                  batch_size=64, shuffle=True,\n","                                                  num_workers=1)\n","\"\"\""],"metadata":{"id":"ie0gwKcMtdWT","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1699114423046,"user_tz":240,"elapsed":251,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}},"outputId":"8f42d24f-2251-4fc0-feb5-621f5f7587a8"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nfore_dataset_loader = torch.utils.data.DataLoader(foreground_dataset,\\n                                                  batch_size=64, shuffle=True,\\n                                                  num_workers=1)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["foreground_train_dataset = datasets.ImageFolder(root='/data/foreground/train',\n","                                                transform=data_transform)\n","foreground_test_dataset = datasets.ImageFolder(root='/data/foreground/test',\n","                                               transform=data_transform)"],"metadata":{"id":"noHe6Mzj5Eoq","executionInfo":{"status":"ok","timestamp":1699114423046,"user_tz":240,"elapsed":12,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","generator = torch.Generator().manual_seed(42)\n","composite_train, composite_test = torch.utils.data.random_split(composite_dataset,\n","                                                                [int(len(composite_dataset)*0.8),\n","                                                                 int(len(composite_dataset)*0.2)],\n","                                                                generator=generator)\n","\"\"\""],"metadata":{"id":"PiGz-N6mNM8y","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1699114423047,"user_tz":240,"elapsed":12,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}},"outputId":"44bf98dc-f36f-4621-83fa-2d8f46d2ff8b"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ngenerator = torch.Generator().manual_seed(42)\\ncomposite_train, composite_test = torch.utils.data.random_split(composite_dataset,\\n                                                                [int(len(composite_dataset)*0.8),\\n                                                                 int(len(composite_dataset)*0.2)],\\n                                                                generator=generator)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["\"\"\"\n","composite_dataset_loader = torch.utils.data.DataLoader(composite_dataset,\n","                                                       batch_size=64, shuffle=True,\n","                                                       num_workers=1)\n","\"\"\"\n","foreground_train_loader = torch.utils.data.DataLoader(foreground_train_dataset,\n","                                                      batch_size=64, shuffle=True,\n","                                                      num_workers=1)\n","foreground_test_loader = torch.utils.data.DataLoader(foreground_test_dataset,\n","                                                     batch_size=16, shuffle=True,\n","                                                     num_workers=1)"],"metadata":{"id":"I5ma6u8k5I97","executionInfo":{"status":"ok","timestamp":1699114423047,"user_tz":240,"elapsed":11,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# print(fore_dataset_loader.dataset.classes)\n","print(foreground_train_loader.dataset.classes)\n","print(foreground_test_loader.dataset.classes)"],"metadata":{"id":"XnaQGxGgttKI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699114423047,"user_tz":240,"elapsed":11,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}},"outputId":"4d4d945e-99a9-45fe-9cf4-45b2a39bea3d"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["['airplane', 'horse', 'toilet', 'train']\n","['airplane', 'horse', 'toilet', 'train']\n"]}]},{"cell_type":"markdown","source":["**Code reference:** https://debuggercafe.com/training-resnet18-from-scratch-using-pytorch/"],"metadata":{"id":"b3GmgFNAY41O"}},{"cell_type":"markdown","source":["### **Build ResNet-18**"],"metadata":{"id":"4BbXlcapMb5U"}},{"cell_type":"code","source":["import torch.nn as nn\n","\n","from torch import Tensor\n","from typing import Type"],"metadata":{"id":"AOsFCZioMhwI","executionInfo":{"status":"ok","timestamp":1699114423047,"user_tz":240,"elapsed":9,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["class BasicBlock(nn.Module):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        stride: int = 1,\n","        expansion: int = 1,\n","        downsample: nn.Module = None\n","    ) -> None:\n","        super(BasicBlock, self).__init__()\n","        # Multiplicative factor for the subsequent conv2d layer's output channels\n","        # It is 1 for ResNet18 and ResNet34\n","        self.expansion = expansion\n","        self.downsample = downsample\n","        self.conv1 = nn.Conv2d(\n","            in_channels,\n","            out_channels,\n","            kernel_size=3,\n","            stride=stride,\n","            padding=1,\n","            bias=False\n","        )\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(\n","            out_channels,\n","            out_channels*self.expansion,\n","            kernel_size=3,\n","            padding=1,\n","            bias=False\n","        )\n","        self.bn2 = nn.BatchNorm2d(out_channels*self.expansion)\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","        return  out"],"metadata":{"id":"-deWpe4fMnIq","executionInfo":{"status":"ok","timestamp":1699114423047,"user_tz":240,"elapsed":9,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["class ResNet(nn.Module):\n","    def __init__(\n","        self,\n","        img_channels: int,\n","        num_layers: int,\n","        block: Type[BasicBlock],\n","        num_classes: int  = 1000\n","    ) -> None:\n","        super(ResNet, self).__init__()\n","        if num_layers == 18:\n","            # The following `layers` list defines the number of `BasicBlock`\n","            # to use to build the network and how many basic blocks to stack together\n","            layers = [2, 2, 2, 2]\n","            self.expansion = 1\n","\n","        self.in_channels = 64\n","        # All ResNets (18 to 152) contain a Conv2d => BN => ReLU for the first\n","        # three layers. Here, kernel size is 7\n","        self.conv1 = nn.Conv2d(\n","            in_channels=img_channels,\n","            out_channels=self.in_channels,\n","            kernel_size=7,\n","            stride=2,\n","            padding=3,\n","            bias=False\n","        )\n","        self.bn1 = nn.BatchNorm2d(self.in_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n","\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512*self.expansion, num_classes)\n","\n","    def _make_layer(\n","        self,\n","        block: Type[BasicBlock],\n","        out_channels: int,\n","        blocks: int,\n","        stride: int = 1\n","    ) -> nn.Sequential:\n","        downsample = None\n","        if stride != 1:\n","            \"\"\"\n","            This should pass from `layer2` to `layer4` or\n","            when building ResNets50 and above. Section 3.3 of the paper\n","            Deep Residual Learning for Image Recognition\n","            (https://arxiv.org/pdf/1512.03385v1.pdf).\n","            \"\"\"\n","            downsample = nn.Sequential(\n","                nn.Conv2d(\n","                    self.in_channels,\n","                    out_channels*self.expansion,\n","                    kernel_size=1,\n","                    stride=stride,\n","                    bias=False\n","                ),\n","                nn.BatchNorm2d(out_channels * self.expansion),\n","            )\n","        layers = []\n","        layers.append(\n","            block(\n","                self.in_channels, out_channels, stride, self.expansion, downsample\n","            )\n","        )\n","        self.in_channels = out_channels * self.expansion\n","\n","        for i in range(1, blocks):\n","            layers.append(block(\n","                self.in_channels,\n","                out_channels,\n","                expansion=self.expansion\n","            ))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        # The spatial dimension of the final layer's feature\n","        # map should be (7, 7) for all ResNets\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","\n","        return x"],"metadata":{"id":"J1e09e27Mvyl","executionInfo":{"status":"ok","timestamp":1699114423047,"user_tz":240,"elapsed":8,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["### **Utils**"],"metadata":{"id":"DVg_kXZHQH6O"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import os\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","\n","plt.style.use('ggplot')"],"metadata":{"id":"oRF75C9ZQExc","executionInfo":{"status":"ok","timestamp":1699114423047,"user_tz":240,"elapsed":8,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def save_plots(train_acc, valid_acc, train_loss, valid_loss, name=None):\n","    \"\"\"\n","    Function to save the loss and accuracy plots to disk.\n","    \"\"\"\n","    # Accuracy plots\n","    plt.figure(figsize=(10, 7))\n","    plt.ylim(0, 105)\n","    plt.plot(\n","        train_acc, color='tab:blue', linestyle='-',\n","        label='train accuracy'\n","    )\n","    plt.plot(\n","        valid_acc, color='tab:red', linestyle='-',\n","        label='validataion accuracy'\n","    )\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","    if not os.path.exists('outputs'):\n","        os.makedirs('outputs')\n","    plt.savefig(os.path.join('outputs', name+'_accuracy.png'))\n","\n","    # Loss plots\n","    plt.figure(figsize=(10, 7))\n","    plt.plot(\n","        train_loss, color='tab:blue', linestyle='-',\n","        label='train loss'\n","    )\n","    plt.plot(\n","        valid_loss, color='tab:red', linestyle='-',\n","        label='validataion loss'\n","    )\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.savefig(os.path.join('outputs', name+'_loss.png'))"],"metadata":{"id":"tYDNRa0YQRrV","executionInfo":{"status":"ok","timestamp":1699114423047,"user_tz":240,"elapsed":7,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["### **Set up for training**"],"metadata":{"id":"Al4ZxHChQUN4"}},{"cell_type":"code","source":["from tqdm import tqdm"],"metadata":{"id":"tWqOWUlPQWUh","executionInfo":{"status":"ok","timestamp":1699114423047,"user_tz":240,"elapsed":7,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def train(model, trainloader, optimizer, criterion, device):\n","    model.train()\n","    print('Training...')\n","    train_running_loss = 0.0\n","    train_running_correct = 0\n","    counter = 0\n","    for i, data in tqdm(enumerate(trainloader), total=len(trainloader)):\n","        counter += 1\n","        image, labels = data\n","        image = image.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        # Forward pass\n","        outputs = model(image)\n","        # Calculate loss\n","        loss = criterion(outputs, labels)\n","        train_running_loss += loss.item()\n","        # Calculate accuracy\n","        _, preds = torch.max(outputs.data, 1)\n","        train_running_correct += (preds == labels).sum().item()\n","        # Backpropagation\n","        loss.backward()\n","        # Update weights\n","        optimizer.step()\n","\n","    # Loss & accuracy for the complete epoch\n","    epoch_loss = train_running_loss / counter\n","    # epoch_acc = 100. * (train_running_correct / len(trainloader.dataset))\n","    epoch_acc = 100. * (train_running_correct / len(trainloader.dataset))\n","    return epoch_loss, epoch_acc"],"metadata":{"id":"Xa_NQE5lQYvJ","executionInfo":{"status":"ok","timestamp":1699114423047,"user_tz":240,"elapsed":6,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["def validate(model, testloader, criterion, device):\n","    model.eval()\n","    print('Validation')\n","    valid_running_loss = 0.0\n","    valid_running_correct = 0\n","    counter = 0\n","\n","    with torch.no_grad():\n","        for i, data in tqdm(enumerate(testloader), total=len(testloader)):\n","            counter += 1\n","\n","            image, labels = data\n","            image = image.to(device)\n","            labels = labels.to(device)\n","            # Forward pass\n","            outputs = model(image)\n","            # Calculate loss\n","            loss = criterion(outputs, labels)\n","            valid_running_loss += loss.item()\n","            # Calculate accuracy\n","            _, preds = torch.max(outputs.data, 1)\n","            valid_running_correct += (preds == labels).sum().item()\n","\n","    # Loss & accuracy for the complete epoch\n","    epoch_loss = valid_running_loss / counter\n","    epoch_acc = 100. * (valid_running_correct / len(testloader.dataset))\n","    return epoch_loss, epoch_acc"],"metadata":{"id":"9Z9iK7D7QcJw","executionInfo":{"status":"ok","timestamp":1699114423047,"user_tz":240,"elapsed":6,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["### **Training**"],"metadata":{"id":"HN3-dy-3QgKX"}},{"cell_type":"code","source":["import torch.optim as optim\n","import numpy as np\n","import random"],"metadata":{"id":"v5O-eI3dQv37","executionInfo":{"status":"ok","timestamp":1699114423047,"user_tz":240,"elapsed":6,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# Set seed\n","seed = 42\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = True\n","np.random.seed(seed)\n","random.seed(seed)"],"metadata":{"id":"0jCsqa69QxeD","executionInfo":{"status":"ok","timestamp":1699114423048,"user_tz":240,"elapsed":7,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["epochs = 40\n","batch_size = 64\n","learning_rate = 0.01\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"NfeFNuaLQzWE","executionInfo":{"status":"ok","timestamp":1699114423048,"user_tz":240,"elapsed":7,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["model = ResNet(img_channels=3, num_layers=18, block=BasicBlock, num_classes=4).to(device)\n","plot_name = 'ResNet-18 on COCO Foreground (40)'"],"metadata":{"id":"SkZXo4E9Q3SR","executionInfo":{"status":"ok","timestamp":1699114428817,"user_tz":240,"elapsed":5776,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# Total parameters & trainable parameters\n","total_params = sum(p.numel() for p in model.parameters())\n","print(f\"{total_params:,} total parameters.\")\n","total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(f\"{total_trainable_params:,} training parameters.\")\n","\n","# Optimizer\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n","\n","# Loss function\n","criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"evpnT6TxQ6QT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699114428817,"user_tz":240,"elapsed":23,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}},"outputId":"25a46606-0f4f-4d83-e088-b82fbe0790b1"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["11,178,564 total parameters.\n","11,178,564 training parameters.\n"]}]},{"cell_type":"code","source":["# Lists to keep track of losses & accuracies\n","train_loss, valid_loss = [], []\n","train_acc, valid_acc = [], []\n","\n","# Start training\n","for epoch in range(epochs):\n","    print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n","    train_epoch_loss, train_epoch_acc = train(model,\n","                                              foreground_train_loader,\n","                                              optimizer,\n","                                              criterion,\n","                                              device)\n","    valid_epoch_loss, valid_epoch_acc = validate(model,\n","                                                 foreground_test_loader,\n","                                                 criterion,\n","                                                 device)\n","    train_loss.append(train_epoch_loss)\n","    valid_loss.append(valid_epoch_loss)\n","    train_acc.append(train_epoch_acc)\n","    valid_acc.append(valid_epoch_acc)\n","    print(f\"Training loss: {train_epoch_loss:.3f}, training acc: {train_epoch_acc:.3f}\")\n","    print(f\"Validation loss: {valid_epoch_loss:.3f}, validation acc: {valid_epoch_acc:.3f}\")\n","    print('-'*50)\n","\n","# Save the loss & accuracy plots\n","save_plots(train_acc, valid_acc, train_loss, valid_loss, name=plot_name)\n","print('TRAINING COMPLETE')"],"metadata":{"id":"sXmTDlJGQ8jL","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"a91f3550-39fe-46d2-8794-89785bda6538","executionInfo":{"status":"ok","timestamp":1699125150947,"user_tz":240,"elapsed":10722148,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO]: Epoch 1 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:41<00:00,  1.14it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.75it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.691, training acc: 73.526\n","Validation loss: 0.683, validation acc: 74.268\n","--------------------------------------------------\n","[INFO]: Epoch 2 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:22<00:00,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.79it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.455, training acc: 83.501\n","Validation loss: 0.602, validation acc: 76.306\n","--------------------------------------------------\n","[INFO]: Epoch 3 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:25<00:00,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.79it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.368, training acc: 87.115\n","Validation loss: 0.388, validation acc: 87.771\n","--------------------------------------------------\n","[INFO]: Epoch 4 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:23<00:00,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.91it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.320, training acc: 88.748\n","Validation loss: 0.605, validation acc: 77.070\n","--------------------------------------------------\n","[INFO]: Epoch 5 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:23<00:00,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.82it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.274, training acc: 90.308\n","Validation loss: 0.319, validation acc: 87.516\n","--------------------------------------------------\n","[INFO]: Epoch 6 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:23<00:00,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.78it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.245, training acc: 91.330\n","Validation loss: 0.437, validation acc: 84.586\n","--------------------------------------------------\n","[INFO]: Epoch 7 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:24<00:00,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.87it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.211, training acc: 92.528\n","Validation loss: 0.606, validation acc: 81.783\n","--------------------------------------------------\n","[INFO]: Epoch 8 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:14<00:00,  1.26it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.99it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.182, training acc: 93.790\n","Validation loss: 0.632, validation acc: 81.146\n","--------------------------------------------------\n","[INFO]: Epoch 9 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:16<00:00,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.82it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.153, training acc: 94.626\n","Validation loss: 0.381, validation acc: 88.408\n","--------------------------------------------------\n","[INFO]: Epoch 10 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:15<00:00,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.87it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.133, training acc: 95.526\n","Validation loss: 0.308, validation acc: 88.535\n","--------------------------------------------------\n","[INFO]: Epoch 11 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:16<00:00,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.88it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.101, training acc: 96.572\n","Validation loss: 0.654, validation acc: 84.459\n","--------------------------------------------------\n","[INFO]: Epoch 12 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:17<00:00,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.95it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.078, training acc: 97.482\n","Validation loss: 4.105, validation acc: 46.242\n","--------------------------------------------------\n","[INFO]: Epoch 13 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:15<00:00,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.92it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.063, training acc: 98.020\n","Validation loss: 0.367, validation acc: 87.771\n","--------------------------------------------------\n","[INFO]: Epoch 14 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:19<00:00,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.68it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.044, training acc: 98.689\n","Validation loss: 0.319, validation acc: 91.465\n","--------------------------------------------------\n","[INFO]: Epoch 15 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:16<00:00,  1.25it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.91it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.043, training acc: 98.641\n","Validation loss: 0.832, validation acc: 78.854\n","--------------------------------------------------\n","[INFO]: Epoch 16 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:14<00:00,  1.26it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.93it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.030, training acc: 99.188\n","Validation loss: 0.457, validation acc: 88.790\n","--------------------------------------------------\n","[INFO]: Epoch 17 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:12<00:00,  1.27it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.95it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.017, training acc: 99.584\n","Validation loss: 0.351, validation acc: 91.720\n","--------------------------------------------------\n","[INFO]: Epoch 18 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:10<00:00,  1.28it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.92it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.014, training acc: 99.653\n","Validation loss: 0.412, validation acc: 88.790\n","--------------------------------------------------\n","[INFO]: Epoch 19 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:10<00:00,  1.28it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09<00:00,  5.10it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.014, training acc: 99.702\n","Validation loss: 0.281, validation acc: 92.994\n","--------------------------------------------------\n","[INFO]: Epoch 20 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:17<00:00,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.82it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.010, training acc: 99.780\n","Validation loss: 0.272, validation acc: 92.484\n","--------------------------------------------------\n","[INFO]: Epoch 21 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:20<00:00,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.90it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.006, training acc: 99.883\n","Validation loss: 0.304, validation acc: 91.720\n","--------------------------------------------------\n","[INFO]: Epoch 22 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:19<00:00,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.95it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.004, training acc: 99.946\n","Validation loss: 0.444, validation acc: 88.153\n","--------------------------------------------------\n","[INFO]: Epoch 23 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:22<00:00,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.82it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.004, training acc: 99.956\n","Validation loss: 0.260, validation acc: 92.739\n","--------------------------------------------------\n","[INFO]: Epoch 24 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:23<00:00,  1.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.80it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.006, training acc: 99.883\n","Validation loss: 0.391, validation acc: 90.573\n","--------------------------------------------------\n","[INFO]: Epoch 25 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:23<00:00,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.82it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.003, training acc: 99.990\n","Validation loss: 0.263, validation acc: 92.739\n","--------------------------------------------------\n","[INFO]: Epoch 26 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:22<00:00,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.59it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.002, training acc: 99.995\n","Validation loss: 0.273, validation acc: 92.611\n","--------------------------------------------------\n","[INFO]: Epoch 27 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:22<00:00,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.88it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.001, training acc: 100.000\n","Validation loss: 0.253, validation acc: 92.484\n","--------------------------------------------------\n","[INFO]: Epoch 28 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:23<00:00,  1.22it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.73it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.001, training acc: 100.000\n","Validation loss: 0.248, validation acc: 92.866\n","--------------------------------------------------\n","[INFO]: Epoch 29 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:21<00:00,  1.23it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.88it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.001, training acc: 99.990\n","Validation loss: 0.252, validation acc: 92.739\n","--------------------------------------------------\n","[INFO]: Epoch 30 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:17<00:00,  1.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.82it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.001, training acc: 99.995\n","Validation loss: 0.267, validation acc: 92.484\n","--------------------------------------------------\n","[INFO]: Epoch 31 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:13<00:00,  1.26it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.86it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.001, training acc: 100.000\n","Validation loss: 0.271, validation acc: 92.102\n","--------------------------------------------------\n","[INFO]: Epoch 32 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:10<00:00,  1.28it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.94it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.001, training acc: 100.000\n","Validation loss: 0.260, validation acc: 92.611\n","--------------------------------------------------\n","[INFO]: Epoch 33 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:11<00:00,  1.27it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09<00:00,  5.13it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.001, training acc: 100.000\n","Validation loss: 0.263, validation acc: 92.611\n","--------------------------------------------------\n","[INFO]: Epoch 34 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:10<00:00,  1.28it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.99it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.001, training acc: 99.995\n","Validation loss: 0.264, validation acc: 92.484\n","--------------------------------------------------\n","[INFO]: Epoch 35 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:10<00:00,  1.28it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10<00:00,  4.92it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.001, training acc: 100.000\n","Validation loss: 0.261, validation acc: 92.484\n","--------------------------------------------------\n","[INFO]: Epoch 36 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:10<00:00,  1.28it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09<00:00,  5.01it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.000, training acc: 100.000\n","Validation loss: 0.274, validation acc: 92.739\n","--------------------------------------------------\n","[INFO]: Epoch 37 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:10<00:00,  1.28it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09<00:00,  5.00it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.000, training acc: 100.000\n","Validation loss: 0.280, validation acc: 92.611\n","--------------------------------------------------\n","[INFO]: Epoch 38 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:10<00:00,  1.28it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09<00:00,  5.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.000, training acc: 100.000\n","Validation loss: 0.272, validation acc: 92.739\n","--------------------------------------------------\n","[INFO]: Epoch 39 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:10<00:00,  1.28it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09<00:00,  5.17it/s]"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.000, training acc: 100.000\n","Validation loss: 0.263, validation acc: 92.739\n","--------------------------------------------------\n","[INFO]: Epoch 40 of 40\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/320 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [04:09<00:00,  1.28it/s]"]},{"output_type":"stream","name":"stdout","text":["Validation\n"]},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09<00:00,  5.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training loss: 0.007, training acc: 99.829\n","Validation loss: 0.405, validation acc: 88.280\n","--------------------------------------------------\n","TRAINING COMPLETE\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x700 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAA1YAAAJeCAYAAAC3eJSyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACSr0lEQVR4nOzdd5hU1f3H8c+9U7ZXYCmL9I6AigiCCkrsRoMNY4olaozYYsFYURT9WROjYjRq1CRWIprYFSuCUmz03ouwsL1Nuff3x+wMLOzC7s7MnV32/Xoen92ZuXPvmcPuOp8553yPYdu2LQAAAABAk5mJbgAAAAAAtHQEKwAAAACIEsEKAAAAAKJEsAIAAACAKBGsAAAAACBKBCsAAAAAiBLBCgAAAACiRLACAAAAgCgRrAAAAAAgSgQrAAAAAIiSO9ENaM4KCwsVCAQS3Qy1a9dO27dvT3QzDnj0s3Poa2fQz86gn51DXzuDfnYG/eyMWPSz2+1WTk7O/o+L6ioHuEAgIL/fn9A2GIYRaYtt2wlty4GMfnYOfe0M+tkZ9LNz6Gtn0M/OoJ+d4XQ/MxUQAAAAAKJEsAIAAACAKBGsAAAAACBKBCsAAAAAiBLBCgAAAACiRLACAAAAgCgRrAAAAAAgSgQrAAAAAIgSwQoAAAAAokSwAgAAAIAoEawAAAAAIEoEKwAAAACIEsEKAAAAAKJEsAIAAACAKBGsAAAAACBKBCsAAAAAiBLBCgAAAACiRLACAAAAgCi5E92A3S1evFj//e9/tWbNGhUWFuqGG27QEUccEXnctm299tprmjFjhsrLy9WvXz9dcskl6tixY+SYsrIyPffcc5o/f74Mw9Dw4cN10UUXKTk5OREvCQAAAEAr0KxGrKqrq9WtWzf97ne/q/Pxt956S++9954uvfRS3XvvvUpKStKUKVPk8/kix/z1r3/Vhg0bdNttt+lPf/qTlixZoqeeesqplwAAAACgFWpWwerQQw/VeeedV2uUKsy2bb377rs688wzNWzYMHXt2lVXXnmlCgsLNXfuXEnSxo0b9f333+vyyy9X79691a9fP1188cWaNWuWdu7c6fTLAQAAANBKNKupgPuybds2FRUVafDgwZH7UlNT1atXLy1fvlyjRo3S8uXLlZaWpp49e0aOGTRokAzD0MqVK+sMbJLk9/vl9/sjtw3DUEpKSuT7RApfP9HtONDRz86hr51BP8efZdvyBW2VVPlVXBWUP2gpaNkKWPZeX0Pfq477dn0NWpItW5Jkh77U3ArdtmVH7t/zGFv2roMNyWUY8rgMuc3Qfx6XIVfke7Oe+3cd73YZchmGfEFLvoBd89VSddCWP2jXfG/JV/O9P2iHbkeODd32B235g1adryfyOvZ8Qbsft0efpyT/pMqqyj36Ye/n7XkNJxiGZES+NyL3SaH7jd0ONPZ4LGyf/bPbA7VeZx3Pqf2UxvdPcspWVVVW1n9AM7Hnnzej1mMN/9uXqJ+hltLPjWUYUorHVKrHpRSPqRSvS6keU6neXfelRu5zRY51u2L//yun/1/YYoJVUVGRJCkrK6vW/VlZWZHHioqKlJmZWetxl8ul9PT0yDF1mT59uqZNmxa53b17d91///1q165dTNoeCx06dEh0E1oF+tk59LUzWlo/W5atoB0OGqHQYYW/2jUhJBh68+4PWgrs9v2et/f83h+0QrcDtgJWTVCo+S/0fTByX+R20FK139oVLHZ7zB90+J074JjCRDeglaCfd+d1m0rzupSW5Faa1620JJd+NbyrzhraOepzO/X/whYTrOJp3LhxOu200yK3w6l2+/btCgQCiWpWpC0dOnTQ1q1ba32igtiin51DXzujqf1cFbC0vdSnbWV+/VTm07ZSn8p9VmSEJRDce7Rlz/sDe47IBHcblbGlYE1IClqKhCWr5v6W/BNhGoqM/rjNXSNBLkOhEaDd7zcMuVzhx8MjRKHz7BrJMGqNgsgIj3zUHg0Jfx8aBTFq+jY0shT+N/Lv+e8TtOWv599uz8DodRnyukx53TVfXYa87l1fk3a77XGZSnLXPt7jMiJt3qvdu12nvvvDDxiSMjMzVFpaKtuue8Rn11N2u14d548lu2awcM9Rj1qjdLuNNIWP33W3LcWgf+o7vr6XbezWr7WfYygzM0MlJaXae8wwseoayavr71t9o06793S9/Rl5vL7+iZXm28/RClq2qgKWKnyWKvxBVfgsVUa+7rqvwh9Upd+K/M3x1XxwVVixaxbZyC5p2rLF1eS2xOo9h9vtbtCAS4sJVtnZ2ZKk4uJi5eTkRO4vLi5Wt27dIseUlJTUel4wGFRZWVnk+XXxeDzyeDx1PtZc3vjZtt1s2nIgo5+dQ187Y/d+9gctbS/z66cyv7aV+mqCk1/byvzaVvN9UVViP0zaF5cZmuK2+9Q1T820tV1T2cza09pqjtnztttlym1KXpepJHfozf/uAcITDhCuvUNCOFx4XIaSPC4dlN9RBdt+qvcNbEtj26EAbFm23C5DZjOZTmoYhjp27KgtW7bwtyOO6Gdn0M+7+IPhwGWpwhcKWxW+oCr8lrrnJsekf5x6z9FiglVeXp6ys7O1YMGCSJCqqKjQypUrdcIJJ0iS+vTpo/Lycq1evVo9evSQJC1cuFC2batXr16JajoAOCJo2dpa6tO6wiqtL6xWSXCn1vxUqJ9KQ8FpZ0XDQlOy21Rehkft073Ky/AoI8m1a+3N7mtw6hid2ddxLlORERqXaURGeEzDkNuUzD3ud+9xTHNkGIaS3C6ZhnHAvDkyDENuQ6EhOACIM4/LlMdlKvMA2BmpWQWrqqoqbd26NXJ727ZtWrt2rdLT09W2bVudcsopeuONN9SxY0fl5eXplVdeUU5OjoYNGyZJ6ty5sw455BA99dRTuvTSSxUIBPTcc89p5MiRys3NTdTLAoCYqvAFtb6oWut2VmldYZXWFVZrXWGVNhZVy7efdT9el6G8msCUl+5RXrpX7TO8ykv3RL5mJLkoegEAQCM1q2C1atUq3XXXXZHbL774oiRp9OjRmjBhgs444wxVV1frqaeeUkVFhfr166dbbrlFXq838pyrr75azz77rCZPnhzZIPjiiy92/LUAQDRs29b2Mn+t4LSusErrdlZre7m/3ud5XYYOyk5Sl5xk9c1vo1SjWnlpu0JTdoqb0AQAQBw0q2A1cOBAvfbaa/U+bhiGxo8fr/Hjx9d7THp6uq655pp4NA8AJIUKLmwu9mn59got316pFdsrtWpHpXwBW649prS5a6ax7X7/7muFwlPdXDXHGIahbaU+rS+qVqXfqrcNOSludc1JVtfcJHXNSVaXnNDXDhleuUyD+fsAADisWQUrAGhu/EFLq3dUacX2Si0vqNSK7RVasb1SFfsIPbHiMqT87FBg6poTGoUKf5+ZzJ9vAACaE/7PDAA1yquDWlFQWWskas3OKgWsvUd8vC5DPdqkqE+70H+926UqzWvWlBJXrdLiu5cXD+/RtOuYXfdbNc/JTQ2NRuVneeVxmQnoCQAA0FgEKwCtTnXA0sbiaq2vWbu0YnsoTG0q9tV5fEaSS73DAaptqvrkpahrTrLcVE0DAAA1CFYADki2baugPFBTerxK64uqQ18Lq7WlxFfvdozt0z01ISo1EqY6ZHgp+AAAAPaJYAWgRavyW1pfFApMewaofa2DSve61CUnSV1yktSzza7pfNkp/FkEAACNxzsIAC1GwLK19KcKzd9Yqu83lWltYZV+Kq2/9LhpSJ0ykyIBqktOsrrWlCLPTaXsOAAAiB2CFYBmy7JtrSyo1PwNZZEwVdcoVEaSK1JyPFx2vEt2kvKzkuR1U/wBAADEH8EKQLNh27bWF1Vr/oZSzd9Ypm83lqq4KljrmIwkl4Z2TtdhnTPUu12KumQnsektAABIOIIVgITaUuLT/I2lkTBVUF57al+qx9SQ/HQN7ZyuoTVhyiREAQCAZoZgBcBRO8v9mvvDZs1YsF7zNpTuVeLc6zJ0cMc0De2cocMPSlf/vDS5XQQpAADQvBGsAMSVZdtatq1SX60p1qy1xVq6rbLW4y5D6t8+TUMPCo1IDeqYpiTWRQEAgBaGYAUg5ip8Qc3dUKpZa0o0a22xdlQEaj0+oGOmhnRI1mGd03VIp3SlJbkS1FIAAIDYIFgBiIktJdWataZEX60t1rcby+QL7tqCN9Vj6ogumRrVPVMju2VpYK8u2rJli2y7vm16AQAAWhaCFYAmCVq2Fm0t11c1YWr1jqpaj3fK9GpU9yyN6p6pQzqlR8qeU70PAAAciAhWABqstDqgOetKNXNNsb5eV1KrFLrLkAZ1TNeo7pka1T1LXXOSCFEAAKDVIFgBqFfAsrX0pwrN31iquRtK9cPmMgV32583I8mlI7tlamS3TI3omqnMZP6kAACA1ol3QQAigpatlQWVoX2lNpbph01lqvBbtY7plpMcWivVPUuDOqbJbTIqBQAAQLACWjHbtrV6Z5XmbyjVtxvL9N2mMpVWB2sdk5ns0mH56Tqsc4ZGdM1U5+ykBLUWAACg+SJYAa2IbdtaX1StbzeWhcLUpjIVVdYuhZ7qMXVoTZAaelC6erVNkclaKQAAgH0iWAEHuM3FoSA1b2NoVKqg3F/r8SS3oSGd0nVY53Qd3jlDffJSmd4HAADQSAQr4ABi2bbW7KzSD5vK9OOWcv2wqUw/ldUOUh7T0KCOaTqsc7qGHpShAe1T5XGZCWoxAADAgYFgBbRg/qClpdsq9ePmMv2wORSmSqpqr5FymdKA9jVBqnOGBnVMU5KbIAUAABBLBCugBSn3BbVoa7l+2BwajVr0U7mqA3atY5Ldpg7umKrBHdN1SH66BnZIVYrHlaAWAwAAtA4EK6AZ21nh14+by/VDzYjUiu2VCtbOUcpKdmlwp3QN6ZSmQzqlq0+7VLldrJECAABwEsEKaGZWFlTqg6U79eWaYq0vrN7r8Q4ZXg3plKYh+ek6pFO6uuQkUbUPAAAgwQhWQDPwU6lPHy4r1AfLdmr1jqpaj/Vok6whNSNSQzqlq32GN0GtBAAAQH0IVkCClFYH9OmKIn24rFDfbSpTeIafxzQ0qnumftYnR4cflKHMZH5NAQAAmjvesQEO8gUszV5Xog+WFmrW2mL5dlswdWh+uk7sm6MxvbIJUwAAAC0M796AOLNsWz9uLtcHy3bqkxVFKq3eVQ69e26yTuqXq+P75qgDU/yAfbJtW75p/1Fw1UqZnTrJzO8ss3O+XPn5MtLTE908tDJ2ICCZpgyT7SsAhBCsgDhZs6NSHywr1IfLCrW11Be5v22aRyf2zdEJfXPUq22KDApPAA3im/6mqp58ss7HjOxsmZ07y8zPrwlbodBl5ufLSElxuKWJY5WUKLhkidxDh8pwJ/5/8XZpqfxz50qSjKQkyZskI8krIzlZ8npD9yUl7fraDNosSXZFhayCAtnbt8vavl3W9gLZBaGv4fvt4uLQwR5P5DVEXofXG/qaHH7NSVKSV0ZScuhrTT9EnpeeLiMjU0ZWpozMTBkZGaE+wgHBtm2pqkp2SUnov9JS2SWlKkpJka+yUvJ6an4nav9cRL56vTJcTds2xbZtye+XqqtlV1fLrvZJvmrZVdWhr9XVUrVPdnWV5A/E5PUabXLlPvzwVvmhQ/P4CwYcILaX+fXx8lARiuXbKyP3p3pMHds7Wyf2zdWh+elymYQpoDH8c+aoaupUSZLnxBMkw5S1aaOsjZtkFxbKLipSsKhIwYUL93qu0abNboErPzLSZXbuHHoDfICwKytVfs21statk9mjh1L+eK3cAwcmpi22Lf9HH6vqb3+TXVTU8Ce6XDVvJr2hN5m7BRMjOUkbMrNUbduhN5p7hhZvkpRcc6x3jyATDnXJSZLbLbuwcLewtL0mLBVEvld5ecPb7PdLfr/ssl1rZWPC6w0FrKzMUOjKDP1nZmTUfF/zNfJYhozs7Ca/AY+Gbduyd+yQtWmTrI0bFdy0SdbGTVJl5f6f3BCRn4ukyM9H5N/bm7RHiN0jmIT/3ZOSQueJxYeZ1dU14ahEdknoq1VSIru0pNZ9kWNKS0M/J3uoaMw1PZ7IhxF7hi65XDUhyRdqm88XCnK+0G3ZMf3JbBDvmWcq5coJjl830QhWQJR2Vvj16coifby8UD9uLo/8j9VlSkd2zdJJ/XI0qnuWktyt75MbIBaC69ap4u57JMuS56STlHLjDbVGeu3yclmbNkXezIUDl7Vpk+ziYtk7dii4Y4eCP/6oWm9tXC65evaUq38/ufoPkGtA/9AIVwscRbZtW5UPPyJr3TpJkrV6tcqvulqeU09V8qWXyMzMdKwtwfXrVfmXvyj4/Q+SJLNTJxl5eXt8Su6TqqsibwR3PTkoVVTIrgi95dzz7WCZQ69BkpSWJrNtW5nt2sloF/pqtt31vdGmTei4qqo6RwFCIwG7vdkN3/ZVS1U1X6t9squqZJeX7RrNKCkN9YPPJ3vHDtk7djS8zaYpIzc31L62bWW2a1vT5nY137eV0bZtkz5QsG07FEh3+z0L1vyeWZs2SVVV+z9Ja+fx7BqRzMxUckaGqkpL9/j58EW+rxXGwgG+vLzpAd40a4+C7TZyHPrQwSNF++cvaCkwd658b7whV/9+8o4dG+UJWxaCFdAExZUBfbaqSDNWFOrbjWWydvsrN7hjmk7sl6vjemUrK4VfMSAaVnGxKm65VSovl2vwYKX88dq9go+RliZXnz5y9emz1/Pt0tKaN3+7wlb4E3WVlSm4fLmCy5dLb/03dK7MDLn69Zerf3+5BvSXu18/GRkZjrzWaPj++z/5P/lEMk2l3jlJ/tmz5X/vffnfeUeBmTOVfPnv5TnhhLiGRruqStX//reqX31NCgSkpCQl//Y38p59tgyPp/7n1UxVsquq6vy0PRxW5PMpMzlZxT9tk1W92zSm3UNKJMyEjq8dcEL3ye+XkZUVChvh4BQOIe3aRe43UlMb9sKzsmLUg7v1R0VFZLTDqjV9bPfRkD1GR8rKJMuSXVCgYEHBPq9hZGfXvOaa1xoOXjW3K3/6Sb4fflBwY+j3Jrhxo6zNm/c9kmeaMtu3rzUlN2a/O4Fgzb/xHoG1Jsza1XUH9riN3Jhm7ZHEOkYRzVq3Q1+VnBz5HTQMQx07dtSWLVtC/+Z1sMMBO/w6wq9595/pap/sYLDukbokb+iaNVNT5XY78sFR1bPPqvrfL6nyoYfl6tZNrp49437N5sKw6/vXhLZv3y5/HUO3TmrILx6i15B+LqsO6ovVRZqxvEhzNpQoaO16bED7VI3tnaPjemezz9R+8DPtjAOhn22/X+U3TlTwxx9ldOyo9KlPyIzRm1jbtmVv26bAkiUKLl6s4JKloYBVx99886CD5BrQX65+/eUe0F9mjx6R6VbNoZ8DS5eq/JprJb9fyb//vZLGnxu6f8ECVf75L7LWrpWkUDC99hq5unWLeRv8X3+jyscek71liyTJPWKEUq6+SmaHDjG7Rqz62rbtFjkquT92MCi7uFjW9u01a8Nq1ogV1J7qKJ9v/yerj2HIyMuTq3PNlNqaAGXmd5bZscM+A3Si2bYtWdb+D2wI04z6Z6g5/O2IFzsYVMUttyowd67Mjh2V/rcnE/YBVaz62ePxqF27dvu/HsGqfgSr1qO+fq7wBTVzTbE+Xl6kb9aVyL/b0FTvtika2ydbY3vnKD8rKRHNbpH4mXZGzN6EVlaGPuV0+A2TbduqfOgh+d97X0pLU/pjf41LIKh1Tb9fwdWrFVy8RMElobBlbdq094FJSaERsv795R4wQPnH/0zbfb6E/DxbxcUq+/3lsrdtk3vUKKVOvqv2NMlAQL5p01T14j9DU7VcLiWde66SfvPrmBRHsLZvV+UTTyjwxZeSJCMvTylXTpB71KiYhxf+dkTPtu3Q6FZBQe01ZpEQFirO4U5Plzp2lJFfsy4xEqQ6HVDrEhPpQP95tkpKVPaHK2Rv2SL3EUco9d4pCSlmQbBqRghWrcfu/VzpC2rW2mLNWFGkr9bU3muqe26yftYnR2N7Z6tLDhWbmoKfaWfEop/9X3+tiin3ykhLU9rdk+Xq3TvGraxf9WuvqepvT4Wmtt07RZ4jjnDs2ruziotDo1lLFiu4eIkCS5fuNR3KSE5W6qQ75B4+3NG22ZYV+lR4zhyZnTqFPhWup+y8tfUnVT7+uAKzZkmSjA4dlHLVlfIceWTTrh0MyvfGdFU9/3yoQIFpynv22Uq+4Ldxq8LI3w5n0M/OaA39HFy5UmVXXiX5fEr67W+UfOGFjreBYNWMEKxaD1/Q1vISl17/ZrVmrilWpX/XdIGDspM0tne2xvbJUc82radsc7wciD/TwY0bVfXXx+Q57lh5Tzop0c2RFF0/27Yt3+uvq+qpp3etSUhOVuqfbpLnmGPi0Nra/LNnq+K22yXbVvKVE5R05plxv2ZD2ZYla8OG0KjW0iUKfP+DrA0bJI9HqffcLc+wYY61pepf/1b1c89JXq/SH39Mrl699vsc/1dfqfKxx2Vv2yZJch91lFKunCAzL6/B1w0sXhyaYrhqlSTJNXBgaIphnNdRHIh/O5oj+tkZraWffR99pMr7/k+SQn8jR4509PpOBytW1qPV2lrq0+y1JZq9tljzNpSpKrArTHXM9IbCVO8c9WnHXlOon7X1J5XfcKPsbdsUXLtWnhNPbNE/L7bfr8o//0X+99+XJHlOOVn29gIF5s5VxZ13Kemii5T061/F7TUGV69WxT1TJNuW9+enyTtuXFyu01SGacrVtatcXbtKJ58kBYOyHnhApR99rIrb71DalHvkHjo07u0IfPutqp9/XpKUcs3VDQpVkuQZNUruww5T1YsvyjftPwrMnKnSefOUfOEF8p555j73kbJKSlT9zDPyvfOuZNsyMjOUfNll8px0UqvcrwbA/nmPP17Bpcvkmz5dFff9n9KfnCpX586JblbcEKzQagSCthZsLdestcWavbZEq3fULg3bMStZY3pkamzvbPVvn9qi3xzDGdaOHSq/8cbIp/92QYGstWvl6t49wS1rGquoSBWT7lRwwQLJNJX8h8vlPfNMybJU9eTf5HvjDVX/4x+y1q0LlTxPiu3aQquwUOW33iZVVsp16KFKvuqqZv97aLjdyn/4Ya28/A8KzJql8ltvU9q998p92KFxu6a1fXsofFqWPCefJO/JJzfq+UZKilJ+/3t5jz9elX95VMGFC1X1t6fk+/BDpVz7R7kPrr33VWhPqo9U9benIntSeU48Ucm/v0xmdnaMXhWAA1Xy5b9XcOUKBRcsVMUdk5T+xOMH7MbtTAXcB6YCtnw7K/w1o1IlmrO+VGW+YOQx05AGdUzTkV0zNap7lo4a1ENbt26ln+PsQPmZtoqLVf7H62StXSujQweZ2dkKLl2q5Mt/r6Rzz0108xrdz8E1a1R+622yt26V0tKUevtte61r8r39jioffVQKBuXq21ep99wtM7yXT5Rsn0/l19+g4KJFMjvnK+3xxx3de6mpwv28ed06lU+apMDX30hJSUr7v/vkHjIk5tezAwGVX3e9ggsXyuzZU+mPPxZVwLUtS/4PPlDVU0+F9k+S5DnllNDeV1lZCq5bFwpfP9TsSdW1q1KuvVbuIYNj8noa40D529Hc0c/OaG39bO3YobLL/yB7xw55xoxRyu23OfLBGVMBgShYtq2lP1Vo1toSzVpboqXbau9rnp3s1ohuGTqyW5aGd8lQZnLoV8AwjGb/yTiaD7usTOUTbwqFqjZtlPbggwrMnq3g0qUKzJ3XLIJVY/hnzw6NgFRWyuzUSalT7glNdduD97RTZXbOV8Wddyq4bJnK/nCF0u65u879oxojvLltcNEiKT1dqfdMaRGhaneG16vUO+9UxR2TFJgzR+U33xIKV4NjG0Cq/v53BRcuDIXfOydFPWpomKa8J58s98iRqnr66dDeV+++q8BXX8k9aqT8H37UqD2pAKAuZps2Sp00SeXXXSf/Z5/J1a9vi/t/ZUMQrNDilVQFNGd9qWatLdbX60pVVBmo9Xi/vBSN7JalI7tlql9eqlwmAQpNZ1dWqvyWW2WtWCEjK0tpDz0oV34n6Yhh0lQp8OOPsquqYlLKOt5s25bvtddV9XSoSIXrkCFKnTRpn3tFuQ85RGlPTFXFbbfKWrdeZddcGypqMXp0k9tR/fLL8n/0kWSaSpt0h1xdDmryuRLJ8HqVOvkuVdx2uwLz5qn8Tzcr7YH75T744Jic3//Fl/K9Pk2SlDpxolz5+TE5rySZWVlKvfFGBU46KbL3lf/d9yTFZ08qAK2P++CBSp5whaoe/auqnv67XL16x3XadCIQrNAi2batb9aX6rXvt2nu+lLtVhFdaV5TR3TJ1MhumRrRNVNt0vh0FbFh+3yquOOO0IhBerrSHnwgMrJjHnSQjLy80KazP/wgj8OltxvL9vlU+ZdHI0UqvKedGlrT1IDRCFd+J6U/9pgq7pmiwJw5qrhrspIuvEBJv/lNo0d+/V98qepnnpUkJV99tSOFH+LJ8HqVevdkld96m4LffrsrXA0YENV5gxs3quLBByVJ3nPOkefoo2LR3L24Bw1S+tNPyTftP/LP+UZJZ54Zlz2pALRO3tNPV3DpUvk/+FAVd9+t9Kf+1qiqpM0dwQotSnXA0gdLd+rV77drzc5dxSe65yZrZLdMHdktU4M7psvt4k0AYssOBFRx12QF5n8rJScr7f/uq1WJzTAMeY4YJt/b7ygwd26zDlahIhWTFFywMFSk4oo/yDtuXKPePBvp6Uqdco+qngq9Ca9+/oVQUYuJExs8PS24YoUq/i9Uhtc7bpySTv95k15Pc2MkJSntnrtVfsutCn7/vcpv+pPSHnhA7v79mnQ+u6pKFXfeJZWXyzXoYCVfekmMW1yb4XYr6bzxSjpvfFyvA6D1MQxDKddeq+Cq1bJWrlTFpDuV9uhfDpiNp6mPihZhZ4Vfz3y9ReP+sUj/98kGrdlZpVSPqXMPaafXfjtA//51f004Kl+Hdc4gVCHm7GBQlffdp8Ds2ZLXq7R7p9Q5AuE+PLSHUWDuPKeb2GDB1atV9ocrQqEqLU2p992rpDPPbNKIhOFyKeWKK5Ry/XWSyyX/p5+p/No/yioo2O9zrR07VH7b7VJVldzDhin5ij805eU0W0ZystKm3CPXkCFSebnKJ05UYNmyRp/Htm1VPvpXWatXy8jJVurtt++zJDoANHdGUpLSJt8lIzNDwWXLVPnXxxLdpJghWKFZW1VQqSkfr9O45xbpuTlbVVQZUPsMj648qpPevPhgXXtMZ3XOjm3JZ2B3tmWp8uFH5P/0M8ntVuqdd8p9yCF1Hus+7FDJNGVt2CBr61ZH29kQ/lmzVHbV1bJ/+klmp05Kf+LxmGxo6z31VKU99KCMzMxIUYt9hQi7uloVt90ue/t2mV27KPX222S4XFG3o7kxUlKUdu8UuQYdHApXN05UcPnyRp3D/9578n/wgWSaSr3tNplt28aptQDgHLNDB6XcdptkmvK/+658b7+T6CbFBMEKzY5l25q9tljXTF+p37y0VO8s3im/ZWtg+1TdfVI3vX7BQJ1/WHulJx14b8TQvNi2raonpobWIZmmUm+7VZ4R9U/xM9LT5RoYGsnyz53rVDP3y7ZtVb/yiipuvyO0R9Qhhyjticfl6tIlZtdwDxmi9KlPyOzaVfaOHSq/9o/yffZZnW2pfOABBZctk5GZodR7pshIT49ZO5obIyVFaffdJ9fAgVJZWShcrVzZoOcGV65U5aN/lSQlXXSh3IceWIu8AbRunsMPV9LFF0uSKh97TIElSxLcougRrNBsVAcsvbmwQL/61xJd/9/VmruhVKYhHdsrW0+d00d/H99XY/vkyE1VPzik+rnn5Js+XZKUMnGiPMccs9/nNLfpgLbPp8oHHlDV03+XbFven/9caQ/cv8/Kf01lduqk9Mcfk/uII6TqalVOvltVL7xYa++Q6hf/uWv07667QhUVD3BGampoTV7//rJLS1V+w40Krlq1z+fYZWWqmHSn5PfLPWK4kn75S2caCwAOSvrleXIfc7Tk96ti0p2ydu5MdJOiQrBCwhWU+/X07M36xXML9cAnG7SusFqpHlPjD2mn1y8YoCmndNegjmmJbiZamap//1vV/35JkpR87bXynnB8g57nPqImWH37rexAYD9Hx1dgxw6VXX+D/B98GCpScdVVSr72mriu0THS0pQ65R55zzlbklT9wguqvPse2VVV8n36qapfeEGSlHLtNXHZQLe5MtLSlHb//8nVt6/skpJQuFqzps5jbdtWxf33y9qyRUb79kr5059kmPzvGsCBxzAMpU6cKLNLF9kFBaq4+x7ZwWCim9VkrIBFwqzYXqFXv9+uD5cVKmCFPtHumOnVuUPa6bQBbZTGVD8kSPUbb6j62eckScmX/75R1epcvXvLyMqSXVys4OLFMd8gtqGCq1Zp7R2TFNy8OVSk4o475Bl2uCPXNlwupfzhD3J17Roq6f7ZZwquXy9r40ZJoXLh3lNOcaQtzYlRU6K//IYbFVy+XOXX36C0Rx6Wq1u3Wsf5Xn1Nga9mSR6PUu+c1OI2SwaAxjBSU5U6+S6VXTFBwR9+UNXTTyvlDy2zoBEfgcFRtm3rm3Ulunr6Cl3w8jK9u2SnApatQR3TdM/J3fTqbwdo/KF5hCokjO/dd1X1+BOSpKTf/rbRO8Mbpin34aEAE0jQOitr506VXnOt/Js3y8zPrylS4Uyo2p33lFOU9mCoqIW1erXk88k9YoSSL7vU8bY0F0Z6ulIfuF9mr16yi4pUfv0NCq5fH3k88MOPqnrmGUlS8oQJcvftm6imAoBjXF26KPWmmyRJvtenyTfjkwS3qGkYsYIjApatT1YU6t/zt2lFQaUkyWVIY3pl67xD8zSwA1P94sG2bdlbtsiuqJBdVS35qmVXV0vVPtnVVbKrfVJ1tWxftVRV87XaV3NMzbG+atnVPhlJSUq6+OIm78XTEvhmfKLKhx+RFBpVSbrgt006j3vY4fLPmBFaZ/W738WyiQ3i//hjqbxcSb17K+mhB2VkZDjehjD3kMFKf3JqaL8qt0ept916QFYAbAwzMzMycmWtWhUZuTLS0lRx992SZcnzs7Hy/vy0RDcVABzjOfooJf3qfFX/+yVVPvSQXN26ytWzZ6Kb1SgEK8RVld/SO4t36OXvtmlziU+SlOw29fOBbXTeoXnqmHlgbAjXXFU/86yqX345ZucLrliutMcfl6tz55ids7nwfzVLlffdFynwkHz575u0t5OkyIhVcPlyWYWFMnNyYtnU/Qp/0pdz/i9VlZlZq3hEIpgdOyr90UcT2obmxszKUtpDD6r8+utlrV6j8uuul9m+veydO2V266aUP/6xyT9/ANBSJV14oYLLliswb54qJt2p9CenJvTDwcYiWCEuiisDemNBgV7/fruKqkIL+LOT3Tp7SFudNbidslL40Ys3a+dOVf/nP5IkIzdXRlKSlJwc2t08KUlGcpLkTQrdn+SVkZQc+upNkpHklZKSa74myfAmqfrllxVctkwVN9+itMcfi0tVuUQJzJ+vismTQyMFxx+v5GuujupNrZmbK7NXL1krVyowf768P/tZDFu7b8H162WtWCG5XMo46SRVVVU5dm00jpmVpbQHH1T5ddfLWrdOwR07pJQUpd45SUZKSqKbBwCOM1wupdx6i8r+cIWszZtV+fgTSr35T4luVoPx7hYxtbXUp1e+26b/LdqhSr8lKVSQ4vxD83TqgDZK9rCszynV06ZJPp9c/fsr7fHHov7023XwQJVNuFLWpk2quP2O0Iaw3pY/4hhYsEDlt98RKmt99NFKmXhjTCqweQ4/XNUrVyowd56jwcr/8QxJoeqE7pwcacsWx66NxjNzcpT28EOhkasNG5Vyw/Ux3V8MAFoaMytLaXfdqcqpTyr5dxcnujmNQrBCg9m2raq//EV2MKiU666r9eZzVUGl/v3tT/poeaGCoTyl3m1T9KuheTquN3tPOc0qLpbvrf9KkpJ+/auYTCkyc3OVdt+9KrvqagUXLlTl/Q8o5dZbWnQZaGvrVpXfcqtUVSX3EUfEdP2P+4hhqn7lFQXmzZVtWY70k23b8s8IBSvv2LFxvx5iw8zNVfrTT8suLJSZl5fo5gBAwrl69w6tPW1hU6IJVmgwa/Vq+f73tiTJe+qpcvXrp+83l+tf83/S7LUlkeMO65yuXw9tr+FdMuL+CxH49lsF166V9/TT47o3T0vjmz5dqqyU2bOn3CNGxOy8rm7dlHbXnSq/6U/yf/qpzE4dlZyA4gyx4v9mjlReLrNnT6XedacMjydm53YNHCilpMguLJK1apVcvXvH7Nz1CS5ZImvLFik5WZ6RI+N+PcSO4fHIIFQBQERLC1USwQqN4P/qq8j3a976UA8sMLVoa4UkyVCowt+vhuZpQHtnKvzZPp/KJ90plZfLP2u2Uu+4nf1eJNllZap+Y7okKTlGo1W7cx92mFKuv06VDzyo6n+/JLNTJ3lPPjmm13CKXVQkSXL37xdaaxZDhscj96GHKjBrlvxz5zoSrMLTAD1HHcUaHQAAHNZy5/DAcYFZsyPf219+qUVbyuV1GfrFwW30ym/7a8op3R0LVVLNHkHl5ZKk4LffqnzClQqu3+DY9Zur6v/+Vyork9m1i9xHHx2Xa3hPOklJv/61JKnykT8rMH9+XK4Tb3ZRoSTJyI5P1T73sPB+VvPicv7d2YGA/J99JknyjD0u7tcDAAC1EazQINb27aHS0TJU5fKofWWhru1Uof9cOFATj+uig7KTHW+T/7PPJUnukSNl5OXJ2rRJZRMmyO/Am9jmyq6slO/1aZKkpF/9Kq7repIuulCesWOlYFDld96l4Jo1cbtWvFiFRZIkIzs7Luf3DBsmSQouXCi75kOAeAl8+63soiIZ2dmRcu8AAMA5BCs0yLxpH0mSluR21Za+h0iSTi9cojZpsVuT0hh2dbX8s2ZJkpLO/6XSn5wq18EHS+Xlqrj5ZlVPfzPhe/ckgu/td2QXF8vs1EmeY4+N67UMw1DKjTfINWiQVF6u8ptvkbVjR1yvGWvhqYBGTnZczm926iQzP18KBhX4/vu4XCMsMg1wzJhWvwEvAACJQLDCfr27ZIdKP58pSaoaOlwDzjpRkuT/4ouEhZfAN3OkykoZeXly9e8fKln80IPynHiCZFmqeuwxVf3lUdmBQELalwi2z6fq116TFAqbTry5NrxepU6+S2bnfNnbtqni1ttkV1bG/bqxYhcXSZLMrOy4XSM8ehSYMzdu17ArK+WfGfodZRogAACJQbDCPn24bKf+/N5yDdm+UpJ0zK9OkmfECMnrlbV5s6xVqxLSLv/nn0mSPKNHR4ozGF6vUiZOVPJll0mGId///qfym/4kq6RkH2c6cPjee1/2jh0y8vLkOf54x65rZmUp9b77ZGRlKbh8uSqm3Cs7GHTs+tGww1MB4zRiJYXKrkuSf968uH0Q4Z89W6qqktmxo1wDBsTlGgAAYN8IVqjXJysKdfeH63ToT8vksYMyO3eWu0sXGSkpch9xhCTJ//kXjrfLrqqSf/bXkkLTnnZnGIaSzhuv1LsnSykpCn73XU1Ri/WOt9NJdiCg6pdfliQlnTc+pmXDG8KVn6/Uu++WPB4FZs1S1ZN/c/T6TWEHg7JrQne81lhJkvuQQyS3W/aWLbI2bYrLNSLTAMeObZHlaQEAOBAQrFCnL1YVadIHaxW0pbMqVkiS3KN27YvjGT1akuT//HPHpwMGvvlGqqqS0aGDXP361nmMZ+RIpT/2Vxnt29cUtbjygC5q4f/oI9nbtsnIzU1Y6XP3wQOVcvOfJEm+N96IlHxvruzi4tA3hiEjjmX6jZSU0Do0xWc6oFVcHKqQKaYBAgCQSAQr7GX22mLd9t5aBS3ppF4Z6rduoSTV2nDUM2K45PHI2rhRlsPV4HyffhZqw5jR+/x03tWjh9KnPlG7qMUb0w+4ohZ2MKjql2pGq849J+b7MTWGd8wYJV1yiSSpaurUSIGR5ihSuCIzM+7r0TzhsuvzYh+s/J9/IQWDMnv1kqtr15ifHwAANAzBCrXMXV+im99Zo4Bl67he2bqpQ6lUViYjO7vW2g0jLU3umlLS/i+cmw5oV1aGRqwUehO/P7uKWpwYKmrx+OOq+stfDqiiFv7PPpO1aZOMzEx5f/7zRDdHSb88T55TTpEsSxX3TFFw+fJEN6lOkWAVx2mAYeHflcD3P8j2+WJ6bv+MjyVJ3rFjY3peAADQOAQrRHy3sVQT314tX9DW0T2ydOeJ3WTNDm0K7B4xYq9P9T3HHCPJ2XVW/q+/lqqrZXbsKLN37wY9J1TU4kYl//73NUUt3lb5xJtkhaeCtWC2Zan6X/+WJHnPPltGSkqCW1RThv3aa0LV8KqqVH7LrbJ++inRzdqL5WCwMnv0kNGmjVRVpeDChTE7r7X1JwUXLJQMQ57j4lteHwAA7BvBCpKkHzeX6Yb/rVZ1wNaR3TJ190nd5DIVmcrlGXnkXs/xjDxScrtlrVun4Nq1jrQzvCmw59gxjVqkbxiGksafq9R77g4Vtfj++wOiqEVg5ley1q2T0tKU9IszEt2cCMPtVuodt8vs3l32zp0qv+VW2WVliW5WLeERK9OBYGUYhtyHD5Uk+WO4zsr3ySeSJNeQITLbtYvZeQEAQOMRrKDFW8t13VurVOm3NOygDN17Snd53aasNWtkb9kieb1yDx261/OM9PRdbxYdmA5oV1REpgHuWQ2woTxHHhkqatGhg6zNm2uKWsRvf6F4sm1bVf/6lyQpadw4GenpCW5RbUZ6utLunSIjN1fWmjWquGtys5qCGSm17kCwknabDhjDdVb+GaFqgF6KVgAAkHAEq1Zu2bYKXfvmKlX4LR2Wn677T+uhJHfox8I/q2Ya4GGH1TvFLDId0IFg5Z89W/L5ZHbOl9mzZ5PPEylqMShc1OIWVf/njRZX1CLwzRxZK1dKycnynnVmoptTJ7N9e6XdO0VKTlZg/nxV/uXRZtPPkamAcdzDanfuoUMlw5C1eo2sgoKozxdctSpUOMbjiVTpBAAAiUOwasVWFlTqmjdXqswX1OCOaXrg5z2U7Nn1IxH46itJkme3Mut7co8cKblcslavUXD9hri21//ZZ6H2jG7cNMC6mNnZSnvwQXlOOkmyLFU+/ri2TrpTtt8fg5bGn23bqv7XPyVJ3tNPl5mVleAW1c/Vp49Sb7tVMk353303st9WokWKV2RlO3I9MytLrr6h7QECMSj9758RmgboHj682Y1WAgDQGhGsWqk1Oyp19fSVKqkKamD7VD18ek+lencVp7AKChRctkwyDLmP3Ht9VZiZmSn3YYdJkvxfxm/Uyi4vj+wB5Dl2TEzOaXi9SrnxBiVfHipqUfTaayq77npZO3fG5PzxFPzuewUXL5G8XiWde06im7NfnpEjlXzFFZKkqr8/o7Ivv0xwi3ZbY+XQiJUkuWNUdt22rMj6KqYBAgDQPBCsWqH1hVW6evpKFVUG1Lddih75RU+lJdWu+OevqQbo6t9PZm7uPs/nOebo0HPiWB3Q/9Usye+X2aWLzO7dY3ZewzCUdO65Srt3isyMDAUXLlTZ7y9XYNGimF0jHsJrq7ynnrrff5/mIunMcaGy95JKPvggwa1xttx6mHvYEZKkwLz5soPBJp8nuGCh7G3bpLS0fX7wAQAAnEOwamU2FlXrqjdWakdFQL3aJuvRcb2UkeTe67jAV6FqgO6Ro/Z7TvdRR0mmKWvlSgU3bY55m6XdpgHuZ1PgpvKMGKHur78ms2tX2Tt2qPyP18n39tsxv04sBBYuVPD77yW3W0njz010cxrFffBASVKwYEeCW+JsufUwV/9+Ulqa7NLSqPb38n8SKlrhOfpoGV5vrJoHAACiQLBqRbaU+HTV9BXaXu5X99xkPfqLXspM3jtU2ZWVCnz3naS6y6zvyczKkvvQQyRJgS8+j2mbJckuK1NgXmhNimf0mJifP8zbrZsypj4h9zFHS4GAKh/5syoefiTmG7pGK7xvlefEE2Xm5SW4NY1j5ORIkgIxKN4QDdvnk8rLJTkbrAyXS+6hoamzgSaWXbf9fvk/D/2eMQ0QAIDmg2DVSmwr9emqN1bop1K/umQn6a/jeikn1VPnsYG5c0PT7vLzZXbt2qDzuyPVAWO/dsb/1VdSICCzWze5uneL+fl3Z6SmKnXSJCVdcolkGPK/847K/3idrO3b43rdhgouX67AnDmSaSr5l+clujmNZtRMWwzsSOyIlR3eHNrlcrzwgydcdr2JZf4Dc+bKLimV0aaNXIccEsOWAQCAaBCsWgF/0NI1b67U5hKf8rO8euzMXmqTVneoknZtCuweeWSDp915Ro2STFPBZctkbd0ak3ZH2vPpZ6FrjHGmpLRhGEo+/5dKve9eGRkZCi5ZorLL/6DAggWOXH9fqsKjVWPHyuzUKcGtaTxztxGrRJZd31URMEuG6eyfwfB+VsGlS2WXljb6+eG9qzzHjpHhcu37YAAA4BiCVSswe22J1hVWKzvFrcfO7K126fWvybCDQQW+/lqS5GnA+qowMzdXrsGDJMV2TyurpESB+fND7XF4rx7PEUcobepUmT26yy4sVPl116v6zTcTFgiCa9YoMHOmZBhKOv+XCWlDtMJTAeX3NylUxEoi1leFmXl5oZFgy1Jg/reNeq5dURH54MMzdmw8mgcAAJqIYNUKfLS8UJJ0cr9cdcjY90L34MJFoWlGmRly1RQaaKhw8IllsAp89ZUUDMrs0V2uBk5LjCVXfielP/aYPMceKwWDqvrrY6p84MGErLuq/vdLkkKbMieiL2LB8HojU+/swsKEtcMuLJLkbKn13YXLrvsbWXbdP3NmzSbZneXq0yceTQMAAE1EsDrAlfuC+nJ1aD3JCX1z9nu8f1ZoU2D3iBGNnmbkOeooyTAUXLxE1rZtjW9sXe35LLRI3zPm2JicrymMlBSl3HZraL8r05T/gw9Ufs21MXuNDRHcsCFSGTHp179y7LrxEF5nlcj9wuziolBbHNoceE+Rsutz5jZqBNT/cc00wJ+NjUt1TAAA0HQEqwPcF6uK5Ava6pKTpD7tUvZ5rG3bkTLrjZkGGGa2aSPXwQdLik0RC6u4eLdpgMdEfb5oRPa7uv//ZGRmKrhsWWjd1fffO3L96pdelixL7iOPlKtnT0euGS/hfbeaw4hVIqYCSpJ78CDJ65VdUCBr7boGPcfauVOBb0NTB5kGCABA80OwOsB9uCz05vXEvrn7/YTbWrdO1ubNkscTmarUWOEAFIvpgIEvZ0qWJbNXL7kOOijq88WCe+hQpf/tSZm9eskuKlL5DTeq+j//ieu6K2vrVvk/+khSyx+tknats0rkiFVkjVWCpgIaSUlyDxkiSQrMndOg5/g/+0yyLLn69ZMrPz+OrQMAAE1BsDqA7azwa96GUIGA4/s0ZBpgTTXAww6TkbLv0a36eI4+WpIUXLgw6hLl/s8/C53ToWqADWV26KD0vz4qz8/GSpalqiemqvK++2RXVcXletUvvxIarRo6VO7+/eNyDScZuaGfxYSOWBWFrm0maMRK2lUdMDB3XoOO330aIAAAaH4IVgewGSuKFLSlAe1T1Tk7ab/HB3Yrs95UZrt2cg0MFb3wz/yqyeexiooU+O57SfHdFLipjORkpdx8s5InXBFad/XxDJVdfU3MS81b27fL9/77kqSkX/86pudOFDOnZipgItdYFYXWHSZqKqC0q4BF4Mcf9xvKg5s2Kbh0qWSa8owZ40DrAABAYxGsDmAfLgu9cT2+AUUrrJ07FVyyVJLkObLpwUoKVa2TJP/nnzf5HP4vvgxNe+rTR6785rlfk2EYSjrrLKU99KCM7GxZK1eq7PI/yD+3cQUJ9qX6tdclv1+uwYPlHjI4JudMtPCIlbUzcSNWiSy3HmZ26SIjL0/y+xX44Yd9Hhveu8p92GGRNWoAAKB5IVgdoDYVV2vR1gqZhvSz3vsPVoHZsyXblqtvX5lt20Z1bc8xNdMBFyxo8jqacAW85jYNsC7uQw5R+t+elKtvX9klJaq46U8qOf0MlV1zrSof/at8b7+jwJIlsisrG3Veq7BQvrfflnRgrK0KC28SbBcmcsSqSJJkZO//dyNeDMNo0HRA27aZBggAQAvgTnQDEB/hohVDO2eoTZpnv8f7a6oBukc1vhrgnsz27eXq10/BpUvl/3Kmks44vVHPt3buVPDHHyU5vylwU5l5eUp79C+qeuIJ+d59TyovV3DBAgUXLNh1kGHIzO8ks0cPuXr0kKtnT7l69JDRoUOdhUV80/4jVVfL1a+f3EOHOvhq4mtXufXEjFjZlZVSzdQ7MzsrIW0I8wwbJv877ygwt/79rKwVK2Rt3Ch5vfLE4PcTAADEB8HqAGTbdmQaYEP2rrIrK3eVcR41MiZt8BxzTChYffFFo4OV/8svI9XPzI4dY9IeJxher1L++EclX3mlrPXrFVy1WsHVq2WtXq3gqlWyCwtlbdwka+MmBXYvR5+aGgpaPXqEQlfPHjLbtlX1m29KCo1WHUh7Fu1ebt22LBmmswPndnFofZU8Hik11dFr78l92KGSacrasEHW1q0yO3TY6xjfxx9LkjwjR8pIS3O6iQAAoIEIVgegFQWVWldYLa/L0Jie2fs9PjB/vuTzyejYUWa3bjFpg2f0Map6+mkFf/hBVlFRo6qv+T/9LHSOFjANsC6GxxMajdpjvylr505Za9YouGqVgqtXK7h6jax166SKCgUXLlRw4cK9zmX27Cl3lGvempvIuibLkl1S4vg6Jyu8h1VOTsIDq5GeLteAAQouXCj/3LlK+vnPaz1uB4O7fh/YuwoAgGaNYHUACk8DHNU9S2lJrv0e749sCjwyZm80zY4d5erTR8HlyxWY+ZW8p53aoOdZBQWR6XOeY1pmsKqPmZsrMze31rQ+OxCQtWFDKGitWlUzurVa9o4dkqTkCy9M+Jv/WDPcbrlychQsLAyVXHc4WNnFRaF2ZCV2GmCYe9gwBRcuVGDuvL2CVfCHH2Tv2CEjI0PuI4YlqIUAAKAhCFYHGMu29VFNsGrQNMBgUIGvv5YkeaIos14X9zHHKLh8ufyff97gYOX/4stQEY0B/WV2aB/T9jRHhtstV/fucnXvLu02ImEVF0sVFS1qKmRjuNu2CQWrnTul7t0dvbZdM2JlJmhz4D25hx2u6n/8Q4Fvv5UdCMhw7/qz7AsXrRh9jAzP/tdKAgCAxGlRwcqyLL322mv68ssvVVRUpNzcXI0ePVpnnXVW5FN927b12muvacaMGSovL1e/fv10ySWXqOMB+gZ1Tz9sKtP2cr/SvS4d2TVzv8cHFy+WXVwsIyNDrkGDYtoWzzFHq/qZZxT47jtZxcUyGzBCsGtT4GNj2paWxszKkprJiEo8uNq2lVasbHLVyGiENwdOZKn13bn69JGRlSW7uFjBxYvlHhwqq2/7fKH1hpI8Y3+WyCYCAIAGaFHl1t9880199NFH+t3vfqc///nP+tWvfqX//ve/eu+99yLHvPXWW3rvvfd06aWX6t5771VSUpKmTJkin8+XwJY754Oa0apje2XL697/P68/vCnw8CNqfVIeC67OnWX27ClZVmTz4X2xtm9XcEFonZFn9DExbQuaF3ebUEl/u9D5yoBWZHPgxJVa351hmpHpobuXXQ98/bVUXi4jL0+uQQcnqnkAAKCBWlSwWr58uQ4//HAddthhysvL04gRIzR48GCtXLlSUmi06t1339WZZ56pYcOGqWvXrrryyitVWFioufsoZ3yg8AUsfbqySFLDNgWWpEBkfVV8yjiHy6X7P/9iv8eGj3EdfLDMdu3i0h40D+6avdISUXI9vIdVokut7y68fmr3suuRaYDHHet45UQAANB4LWoqYJ8+fTRjxgxt3rxZnTp10tq1a7Vs2TL99re/lSRt27ZNRUVFGlwzlUaSUlNT1atXLy1fvlyj6tkDxu/3y+/3R24bhqGUlJTI94kUvn5D2jFnQ6lKq4Nqm+bRYZ0z9vuc4Pr1of1xPB55hh8Rl9fqHX2Mqp97LrR+pKxMZkZGvceGpwF6x4xxvN8b08+IjmEYcrfbNWLldJ9HNgduBlUBwzzDhqlSUnD58lD73G4FvvlGkpT0s581qZ38TDuDfnYOfe0M+tkZ9LMznO7nFhWsfvGLX6iyslJ//OMfZZqmLMvSeeedp6OPPlqSVFTzhilrj7UpWVlZkcfqMn36dE2bNi1yu3v37rr//vvVrhmNmnSoY3+bPX3+6RZJ0i8O7azO+Z32e/yOd95RqaS04cPVaY/S4DHTsaNW9+6t6hUrlLZosbLH/aLOw/ybN6to0WLJMJR/zjnytM+LT3v2oyH9jOgVtWkjSfKWlzu+/nF1eZkCktr26KH05rL2smNHVffrp+qlS5W+apWsqiqV+P1K6t1L+aNGRfU/BH6mnUE/O4e+dgb97Az62RlO9XOLClazZ8/WzJkzdfXVV+uggw7S2rVr9fzzzysnJ0djxoxp8nnHjRun0047LXI7/CZm+/btCgQC0TY7KoZhqEOHDtq6dats2673uHJfUB8t2ipJGtU5SVu2bNnvuUvfe1+SZB0+tEHHN5UxaqS0YoW2//ctVY4YXucxVa+/LklyDRqkAisoxbE9dWloPyN6hmEovW3oQ4vKrVvj+rNXF9/2AklSoWWp1OFr79Ohh0hLl2r7hx/JLtguSTJGj9HWrVubdDp+pp1BPzuHvnYG/ewM+tkZsepnt9vdoAGXFhWs/vWvf+mMM86ITOnr0qWLtm/frjfffFNjxoxRdk2Vr+LiYuXk7FpjVFxcrG772PjW4/HIU08p4+byw27b9j7b8vnKIvmCtrpkJ6lPu+T9ttsqLFRw8WJJkvvII+P6Ot1HHyM9/4IC8+bLKi2VkZ6+1zG7bwqcyD7fXz8jNtxtQyNWduFOR/vbtu1dUwGzspvVv7X78MNV/fIroYIyFRWSQuurom0jP9POoJ+dQ187g352Bv3sDKf6uUWtiK6urpa5xyJu0zQjHZWXl6fs7GwtqNlgVpIqKiq0cuVK9enTx9G2Ou3DZaGy1Sf0bdi6kcDXX4f2i+rTJ+6FIlzdu8ns2kXy++Wv2TNrd9bWrQouXSqZpjzHUA2wNQgXr7CLimUHg85duLxcqllPaTSj4hVSqGiLkpNDbbTtUBEXpogAANBitKhgNXToUL3xxhv69ttvtW3bNs2ZM0dvv/22hg0LVdQyDEOnnHKK3njjDc2bN0/r16/X448/rpycnMgxB6KdFX7N21AqqeHVAP011QDdMd4UuD7hwFRXdUD/Z59LklyDB8vMzXWkPUgsV06OZJqSbcsuLnbsulb4WsnJMpKTHbtuQxgej9yHHhq57dltw2gAAND8taipgBdffLFeffVVPfPMMyouLlZubq6OP/54nX322ZFjzjjjDFVXV+upp55SRUWF+vXrp1tuuUVerzeBLY+vT1YUKWhL/dun6qDs/b9ZtKuqFJg/X5LkqadSYqx5jjlG1f/8lwJz5siuqJCRmhp5zP/ZZ6Fjolgnh5bFcLlCm+IWFsreuVNyKFDbhUWh6+c07AMIp7mPGKbA7NmSyyXPmNGJbg4AAGiEFhWsUlJSdOGFF+rCCy+s9xjDMDR+/HiNHz/euYYl2Ae7TQNsiMD8b6Xqahnt28vs0SOeTYswe/SQ2Tlf1sZN8n/9tbzHHSdJCm7arODy5aFpgEcf5Uhb0DwYubmyCwtlFRbK5dA17aLQvllmzXrM5sYzerR8/3tb7mGHy8xqXlMVAQDAvrWoqYDY26biai3aWiHTkMb2buA0wNnhTYFHOlbX3zCMXdMBv9g1HdD/ec00wEMOkdlMRxEQH+F/b3vnTseuaReFpgIazTS0mNnZynjm70r5/e8T3RQAANBIBKsW7qPloU/gh3bOUNu0uisb7s4OBkNTjSR5Ro2Ma9v25BkdmtoU+GaO7MpKSbumAXqZBtjqGDXT/5wMVlZkc+Bsx64JAABaB4JVC2bbtj5cGgpWDZ0GGFy6NLTOJC1NrsGD49i6vZm9esns2FGqrlZgzhwFN26UtXKlZJpyMw2w1QmPWFmFhY5dc9dUQEZHAQBAbBGsWrAVBZVaW1glr8vQ6J7ZDXpOoKYaoGf4cBluZ5fYGYYh9+hd0wHD1QDdhx3GepJWaNeIlZPBqmYqYDNdYwUAAFouglUL9tGy0BvSkd2ylJ7UsOX//lnOllnfU2Sd1eyv5f/449B9VD9rlcKl9Z0csYpMBWxme1gBAICWj2DVQlm2HVlfdWK/Bk4D3LBB1vr1ktstzxFHxLN59XL17SujfXupqirUFpdL7qOYBtgaGQkpXhH6nTGYCggAAGKMYNVC/bCpTNvK/Er3ujSia2aDnhOYFSpa4R4yREZ6ejybV6/dqwNKknvoUJmZDWs/Dixmbk2wcnKNVc0+VibFKwAAQIwRrFqoD2tGq8b0ylKSu2H/jLumATpbDXBPntG7ghXTAFuvyBqrkhLZfn/cr2dbluzi5l1uHQAAtFwEqxbIH7T0yYoiSdIJfXMb9ByruFjBRYskSZ4Era8Kc/XrF5oS2K6dPEwDbLWMjAzJFVobaNesfYonu7RUsqzQtSleAQAAYszZsnCIia/Xlaq0Oqi2aW4dmt+wKX2Br7+WLCtU8rx9+zi3cN8M01TaY3+VLEuG15vQtiBxDNOUkZ0te8eO0HTAdu3ier1IeEtPl+HZ/55vAAAAjcGIVQv04bLQYv+xvXPkMo0GPccfLrOe4GmAYYbbTahCZDqg5UABi3CpdZOKgAAAIA4YsWphyn1BzVwTeoPYkGmAtm3L/8mnCsydKynx0wCB3Zm5ubLkTAELKgICAIB4Ili1MF+sKlZ1wFaX7CT1y0vZ57HB5ctV+fgTCi5cKElyDRggs3dvJ5oJNEi45LoTI1a79rDKjvu1AABA60OwamE+Wh56A3p83xwZRt3TAK2dO1X17LPyv/+BZNtScrKSzj9fSeecXe9zgERwsuQ6UwEBAEA8EaxakJ0Vfs1dXypJOqHv3tOZbL9fvjemq+qf/5QqKiRJnp+NVfKll8qMc2EAoCl2bRLMVEAAANCyEaxakE9WFCloS/3bp+qg7OTI/bZtK/D116p68klZGzdJklx9+yp5wgS5Dx6YqOYC++Vk8QqrZnNgpgICAIB4IFi1IB8uC33ifkKfXZ+4B9etU9XUJyPFKYycHCVfeok8J5wgw6ToI5o3M8fJqYBFkiQjJzvu1wIAAK0PwaqF2FRcrYVby2Ua0tg+ObLLylT1wovyvfmmFAxKbre8Z5+l5F/9SkZaWqKbCzSIo+XWi4skSWZWdtyvBQAAWh+CVQvxUc3eVYd3SlPGJ++r9Ll/yC4OLcZ3jxyp5Mt/L1fnzolsItBoZk2wUnm5bJ8vrnub2eGpgIxYAQCAOCBYtQC2beuDZYUaVLBKN859V1Wb1kmSzK5dlHzFBHmGHZ7gFgJNlJYmeTyS3y97Z6GMDu3jchk7GJRdUiKJNVYAACA+CFYtwJLvluuX7z+tYzb/GLojPV3JF14g7+mny3DzT4iWyzAMGTk5srdtk1VYKDNewapmdFeGISMzMy7XAAAArRvvypsxu7JSVa++JuulV3RMwCfLMJT8858r6aILZWaxFw8ODGZOjoLbtsmO4zqrSOGKzEwZLlfcrgMAAFovglUzFvj2O1W/+KJckn5o21PeK67QiDGHJLpZQEyFC1jYhQ4EK6YBAgCAOCFYNWPukUeq9Ojj9GhVZ33fbYjePmpwopsExFx4k2ArjiXXLYIVAACIMzY6asYMw9C/R/9WX+UP1pjeuUpy88+FA0+4MqATUwFNghUAAIgT3qk3Y/6gpU9WhD7FP7Fvzn6OBlomIzf+I1aRUusEKwAAECcEq2ZszvpSlVYH1S4jSYd1zkh0c4C4MGumAto74xisajYHZg8rAAAQL6yxasZGdM3UX8f1kpIz5DIN2bad6CYBMbereEUc11iFR6yysuN2DQAA0LoRrJoxl2loWJdMdezYUVu2bEl0c4C4iBSvcGKNFSNWAAAgTpgKCCChwsUrVFkpu7IyLteg3DoAAIg3ghWAxEpJkZKSJMVvOiDl1gEAQLwRrAAklGEYkXVWVhwKWNg+n1ReHroWwQoAAMQJwQpAwkUqA8ZhxMouLg5943LJSE+P+fkBAAAkghWAZiCeBSwi66uysmSY/MkDAADxwbsMAAlnxrHkOuurAACAEwhWABLOiEwFjMOIVc0eVpRaBwAA8USwApBwu4pXxCFYFReFrsHmwAAAII4IVgASzsyNY/GKmhErpgICAIB4IlgBSLhdxSviuMaKqYAAACCOCFYAEm734hW2bcf03OGqgCYjVgAAII4IVgASLjxipepqqaIipue2qQoIAAAcQLACkHBGcrKUmipJsmK8zopy6wAAwAkEKwDNghkuuR7jyoC7RqxyYnpeAACA3RGsADQLRrgyYAwLWNiVlVJVlSTJzM6K2XkBAAD2RLAC0CwYOTV7WcVwKqBdXBz6xuOJTDUEAACIB4IVgGYhHlMBrfAeVjk5MgwjZucFAADYE8EKQLNg5MZjxKoodO4spgECAID4IlgBaBbiMWJl14xYmWwODAAA4oxgBaBZiBSviOWIVVHoXJRaBwAA8UawAtAsxKN4hVUUKl5BqXUAABBvBCsAzYK524iVbdsxOWd4DytKrQMAgHgjWAFoFoyaNVby+6Wyspicc9fmwNkxOR8AAEB9CFYAmgXD65XS0yVJVowKWFiRYMVUQAAAEF8EKwDNhllTcj1WBSx2jVgxFRAAAMQXwQpAsxGeDhiLESvbtndbY8WIFQAAiC+CFYBmw4xlyfXy8tB6LTFiBQAA4o9gBaDZMCKbBEcfrKziUKl1JSfLSE6O+nwAAAD7QrAC0GwYNWusYjIVsLAodM4cpgECAID4I1gBaDbMnNgVr7CLQucwKbUOAAAcQLAC0GzEtHhFUWgqoJHF+ioAABB/BCsAzUYsi1dE9rDKyY76XAAAAPtDsALQbESKVxQWyrasqM61ayoga6wAAED8EawANBuRQhOWJbukJKpzRaYCssYKAAA4gGAFoNkw3G4ZmZmSop8OGJkKyB5WAADAAQQrAM1KuOS6HWUBi/BUQIOpgAAAwAEEKwDNSmQvqyhHrMJTAU2KVwAAAAcQrAA0K2a4gEUUI1a2ZckOTwWk3DoAAHAAwQpAs2LUlFyPZsTKLi2VaqoKUrwCAAA4gWAFoFnZNWIVRbCqGa1SeroMjycGrQIAANg3ghWAZiUWxSsi66uoCAgAABxCsALQrIT3sopqKiAVAQEAgMMIVgCaFTM8YlXY9BGrXXtYZcegRQAAAPtHsALQrIRHrOziEtnBYJPOwVRAAADgNIIVgGbFyMqSTFOyLNnFxU06B1MBAQCA0whWAJoVw+WK7D1lN3GdlVVYFDoXUwEBAIBDCFYAmp1IAYsmVgYMj3QZOdmxahIAAMA+EawANDtmlCXXw1MBzazsWDUJAABgnwhWAJodI7emgEUTpwLa4amAjFgBAACHEKwANDvRTAW0g0HZJSWh87DGCgAAOIRgBaDZ2bWXVVGjnxupJGgYMjIzY9gqAACA+hGsADQ7UY1YhTcHzsyU4XLFslkAAAD1IlgBaHZ2jVg1fo1VJFgxDRAAADiIYAWg2QmPWDWlKqBFsAIAAAlAsALQ7BjhEauSEtmBQKOeGx6xMglWAADAQQQrAM2OkZEh1ayPaux0wEipdYIVAABwEMEKQLNjmGYkGDU6WBUXhc7BHlYAAMBBBCsAzVJ4OqC1s3HBygqPWGVlx7hFAAAA9SNYAWiWzHABi8LGFbCIrLFixAoAADiIYAWgWYqMWDV1KiBrrAAAgIMIVgCaJbOJJdctilcAAIAEIFgBaJaM3HCwaviIle3zSeXloecTrAAAgIMIVgCapaZMBbSLi0PfuFwy0tPj0SwAAIA6uRPdgMbauXOn/vWvf+n7779XdXW1OnTooCuuuEI9e/aUJNm2rddee00zZsxQeXm5+vXrp0suuUQdO3ZMcMsBNEZTpgKGC1cYWVkyTD43AgAAzmlRwaqsrEy33367Bg4cqFtuuUWZmZnasmWL0tLSIse89dZbeu+99zRhwgTl5eXp1Vdf1ZQpU/TII4/I6/UmsPUAGqMpI1ZWOFgxDRAAADisRX2k+9Zbb6lNmza64oor1KtXL+Xl5WnIkCHq0KGDpNBo1bvvvqszzzxTw4YNU9euXXXllVeqsLBQc+fOTXDrATRGeMRKZWWhtVMNYNcUrqDUOgAAcFqLGrGaN2+ehgwZokceeUSLFy9Wbm6uTjjhBP3sZz+TJG3btk1FRUUaPHhw5Dmpqanq1auXli9frlGjRtV5Xr/fL7/fH7ltGIZSUlIi3ydS+PqJbseBjn52ToP7OiND8ngkv18qKpLRvv1+zx1eY2VkZbf6f0t+pp1BPzuHvnYG/ewM+tkZTvdziwpW27Zt00cffaRTTz1V48aN06pVq/SPf/xDbrdbY8aMUVHNNKCsrKxaz8vKyoo8Vpfp06dr2rRpkdvdu3fX/fffr3bt2sXjZTRJeFQO8UU/O6chfV3etq0CW7Yo1zSV0oB1ktsCflVJSu+crw6sq5TEz7RT6Gfn0NfOoJ+dQT87w6l+blHByrIs9ezZU+eff76kUABav369PvroI40ZM6bJ5x03bpxOO+20yO1wqt2+fbsCgUBUbY6WYRjq0KGDtm7dKtu2E9qWAxn97JzG9LWdlSlt2aLty5fL04APOio2bJQkVXq82rJlS0za21LxM+0M+tk59LUz6Gdn0M/OiFU/u93uBg24NClYrVixQr17927KU6OSk5Ojzp0717qvc+fO+uabbyRJ2TUL1ouLi5UTXp9Rc7tbt271ntfj8cjj8dT5WHP5Ybdtu9m05UBGPzunIX1t5NQUsNhZ2KB/l13FK7L4d6zBz7Qz6Gfn0NfOoJ+dQT87w6l+blLxittuu03XXHONpk2bpp9++inWbapX3759tXnz5lr3bd68OZIg8/LylJ2drQULFkQer6io0MqVK9WnTx/H2gkgNoyaD0iswoaVXLepCggAABKkScHqqquuUocOHfSf//xHV199tW6//XZ9+OGHKisri3X7ajn11FO1YsUKvfHGG9q6datmzpypGTNm6MQTT5QUGu475ZRT9MYbb2jevHlav369Hn/8ceXk5GjYsGFxbRuA2DNrSq7bOxtWcp1y6wAAIFGaNBXwqKOO0lFHHaWSkhLNmjVLM2fO1LPPPqsXXnhBQ4YM0THHHKPDDz9cbndsl3D16tVLN9xwg1566SX95z//UV5eni644AIdffTRkWPOOOMMVVdX66mnnlJFRYX69eunW265hT2sgBao6SNWOfs+EAAAIMaiSj6ZmZk66aSTdNJJJ0VGkGbOnKk///nPSk1N1YgRIzR69Gj169cvVu3V0KFDNXTo0HofNwxD48eP1/jx42N2TQCJYeaGApLdgE2C7cpKqaoq9LzsrP0cDQAAEFsxG1Lyer1KSkqKFIEwDEPz5s3TJ598oh49emjChAl7FZ4AgH0Jj1g1ZCpgeA8reTxSamo8mwUAALCXqIJVZWWlvv76a82cOVOLFy+WYRg65JBDdPbZZ2vo0KEyTVNz5szRiy++qKlTp+ree++NVbsBtAJGbrgq4P6nAlqFRaHn5OSw4SIAAHBck4LV3Llz9eWXX+rbb7+V3+9Xz549dcEFF2jUqFHKyMiodeyIESNUVlamZ599NiYNBtB6hItXqLJSdmWljJSUeo+1i4skSUYW0wABAIDzmhSsHnroIbVp00annnqqRo8erU6dOu3z+G7dutUqMAEADZKSIiUlSdXVsgsL9x2sakaszJxsZ9oGAACwmyYFqzvuuEMDBw5s8PG9evVSr169mnIpAK2YYRgycnNlb9kiq7BQ5j4+xLGLQuuwKLUOAAASoUn7WDUmVAFANMIjUPsrYGEVhYpXGFnZcW4RAADA3poUrF555RXdeOON9T4+ceJEvf76601uFACEGTk1BSz2U3I9vIcVUwEBAEAiNClYff311zr00EPrffzQQw/VrFmzmtwoAAiL7GW1n8qAuzYHzo5ziwAAAPbWpGBVUFCg9u3b1/t4Xl6eCgoKmtwoAAgLj1jZhfsOVlYkWOXEu0kAAAB7aVKwSk5O1vbt2+t9fNu2bZGNggEgGrv2smrYVEAjm3LrAADAeU0KVgMGDNDHH3+snXVMzSkoKNDHH39MgQsAMWHm1EwF3MeIlW3bu9ZYMWIFAAASoEnl1s877zzdfPPNuu6663Tcccepc+fOkqQNGzbo008/lW3bGj9+fEwbCqB1MmrWWFk1+1TVqaJC8vtDxzNiBQAAEqBJwapTp06aPHmynnvuOb3zzju1Huvfv78uuuiiSNgCgGhERqx27pRt2zIMY69jwuurlJwsIznZwdYBAACENClYSVLXrl111113qaSkRNu2bZMUKlqRmZkZs8YBgFETrFRdLVVWSqmpex1j14xmRY4FAABwWJODVVhmZiZhCkDcGCkpUkqKVFkpa+dOueoKVkWhwhYmpdYBAECCRBWsduzYoTVr1qiiokK2be/1+OjRo6M5PQBIkszcXFmbNoX2sqpjmrFdVCxJMrJYXwUAABKjScHK5/PpiSee0DfffFNnoAojWAGIBSM3R9q0SXZh3SXXI3tY5WQ71ygAAIDdNClYvfzyy5ozZ47OO+889enTR3fddZcmTJig7OxsvfvuuyosLNSECRNi3VYArVR47VR9e1ntmgrIGisAAJAYTdrH6uuvv9aYMWP0i1/8QgcddJAkKTc3V4MHD9af/vQnpaam6oMPPohpQwG0XmZOaJPg+kasIlMBWWMFAAASpEnBqqSkRL169ZIkeb1eSVJVVVXk8eHDh2vOnDkxaB4A7LaXVR2bkku7TQVkDysAAJAgTQpWWVlZKi0tlSQlJSUpLS1NmzdvjjxeWVkpn88XmxYCaPX2P2IVut9gKiAAAEiQJq2x6tWrl5YuXRq5PXToUP3vf/9TTk6ObNvWO++8oz59+sSskQBat/CIlV3PiFV4KqBJ8QoAAJAgTQpWp5xyimbPni2/3y+Px6Px48dr+fLlevzxxyVJ7du310UXXRTThgJovYyaESurjhEr27Jkh6cCUm4dAAAkSJOCVb9+/dSvX7/I7bZt2+rPf/6z1q9fL9M0lZ+fL5fLFbNGAmjdzPCIVWGhbNuWYRiRx+zSUsmyJFG8AgAAJE6j11hVV1froYce0pdffln7RKapbt26qUuXLoQqADEVLrcuv18qK6v1WHi0SunpMjweZxsGAABQo9HBKikpSQsWLFB1dXU82gMAezG8Xik9XdLe0wEj66uoCAgAABKoSVUB+/Xrp+XLl8e6LQBQLzOn7gIWVAQEAADNQZOC1cUXX6ylS5fqlVde0Y4dO2LdJgDYi5FbdwGLXXtYZTvcIgAAgF2aVLzixhtvVDAY1PTp0zV9+nS5XC556ljb8MILL0TdQACQQgUsgqprxIqpgAAAIPGaFKyGDx9eqyoXAMSbEZkKuOcaK6YCAgCAxGtSsJowYUKs2wEA+1TvVMDCotDjTAUEAAAJ1KQ1VgDgtHqLVxSHpgIaOdlONwkAACCiSSNWn3/+eYOOGz16dFNODwB7MXLqHrEKTwU0s7KdbhIAAEBEk4LV1KlTG3QcwQpArJi59YxYhacCMmIFAAASqEnB6vHHH9/rPsuytH37dn3wwQcqKChgHRaAmIoUrygslG1ZMkxTdjAou7Q09DhrrAAAQAI1aY1Vu3bt9vqvffv2Ovjgg3X99dcrMzNT77//fqzbCqAVCwcrWVYkTNnFxZJtS4YhIzMzga0DAACtXVyKVwwdOlSzZ8+Ox6kBtFKG2x0JT+HpgHZ4c+DMTBkuV6KaBgAAEJ9gtXXrVvn9/nicGkArFi65btcUsIgEK6YBAgCABGvSGqvFixfXeX9FRYUWL16s9957T8OGDYuqYQCwJyMnR1q7VlbNiJVFsAIAAM1Ek4LVXXfdVe9jpmlqxIgRuvjii5vcKACoi5mbq6D2HrEyCVYAACDBmhSsJk2aVOf96enpatu2rVJTU6NqFADUJVxSPTxiFSm1TrACAAAJ1qRgNWDAgFi3AwD2ywyvsdpZM2JVXCSJPawAAEDiNal4xbZt2zRv3rx6H583b562bdvW5EYBQF32LF5hhUessrIT1CIAAICQJgWrF198Ue+99169j3/wwQd66aWXmtwoAKhLeC8ra49y6yYjVgAAIMGaFKxWrFihwYMH1/v4oEGDtGTJkiY3CgDqYu5Zbj08FZA1VgAAIMGaFKzKysqUkpJS7+PJyckqKytrcqMAoC7hESu7uFh2MLhrKiDBCgAAJFiTglXbtm21dOnSeh9fsmSJcms+WQaAWDGysiTTlCxLdkGBVF4eup9gBQAAEqxJwWrUqFH66quv9O6778qyrMj9lmXp3Xff1axZs3TUUUfFrJEAIEmGyyUjK1OSFFyzNnSnyyUjPT1xjQIAAFATy62PGzdOy5Yt0wsvvKDp06erU6dOkqTNmzerpKREAwYM0JlnnhnThgKAJBk5ubILixRcvTp0OytLhtmkz4gAAABipknByuPx6NZbb9Xnn3+ub775Rj/99JMkqWfPnhoxYoSOOeYYmbzRARAHZm6urNWrZa1ZI4lpgAAAoHloUrCSJNM0deyxx+rYY4+NZXsAYJ/CBSyCa0IjVpRaBwAAzUGTqwKuW7eu3sfXr19PVUAAcWHk1uxltX5D6DabAwMAgGagScHq+eef19NPP13v408//bT++c9/NrlRAFAfs2bESoGAJKYCAgCA5qFJwWrRokUaOnRovY8PHTpUCxYsaHKjAKA+xh5bORhMBQQAAM1Ak4JVSUmJMjMz6308IyNDxcXFTW4UANQnMmIVvs2IFQAAaAaaFKyys7O1pqYiV11Wr169z+AFAE2114gVwQoAADQDTQpWw4YN0yeffKJ58+bt9djcuXP16aef6ogjjoi6cQCwJ4IVAABojppUbv3cc8/VggUL9OCDD6pbt2466KCDJEkbNmzQ2rVr1blzZ5177rkxbSgASJKRkSGZpmRZodvZOft5BgAAQPw1KVilpqZqypQp+u9//6tvvvlGX3/9tSSpffv2Ouuss3TGGWfI7/fHtKEAIEmGacrIyZG9Y4ckyczOSnCLAAAAotggODk5Weeee26tkSmfz6f58+fr0Ucf1Q8//KB///vfMWkkAOwuEqw8Hik1NdHNAQAAaHqwCrNtWwsWLNDMmTM1Z84cVVZWKjMzU6NGjYpF+wBgL2ZuriyFApZhGIluDgAAQNOD1erVq/Xll19q1qxZKioqkiSNGjVKJ510knr37s2bHQBxEy5gYWQxDRAAADQPjQpWP/30k7788kvNnDlTW7ZsUW5uro466ij16tVLf/nLXzR8+HD16dMnXm0FAEm79rIy2RwYAAA0Ew0OVrfeeqtWrlypzMxMDR8+XJdffrn69esnSdq6dWvcGggAezK7hCqRmp07J7glAAAAIQ0OVitXrlReXp5++9vf6rDDDpPL5YpnuwCgXp6xY2VkZ8s9cGCimwIAACCpEcHq4osv1syZM/XQQw8pPT1dw4cP18iRIzWQNzYAHGa43fIMH57oZgAAAEQ0OFideOKJOvHEE7Vt27bIOqsZM2YoOzs7Eq4oWAEAAACgNWp0VcC8vDydddZZOuuss2pVBpSkZ555Rt99950OP/xwDRo0SF6vN+YNBgAAAIDmJqp9rHr06KEePXroN7/5jRYuXBgJWZ988om8Xq/++c9/xqqdAAAAANBsRb1BsCSZpqnBgwdr8ODBuvTSSzVv3jzNnDkzFqcGAAAAgGYvJsFqd16vVyNHjtTIkSNjfWoAAAAAaJbMRDcAAAAAAFo6ghUAAAAARIlgBQAAAABRIlgBAAAAQJQIVgAAAAAQJYIVAAAAAESJYAUAAAAAUSJYAQAAAECUCFYAAAAAECWCFQAAAABEiWAFAAAAAFEiWAEAAABAlAhWAAAAABAlghUAAAAARIlgBQAAAABRIlgBAAAAQJQIVgAAAAAQJYIVAAAAAESJYAUAAAAAUSJYAQAAAECU3IluQDTefPNNvfTSSzrllFN04YUXSpJ8Pp9efPFFzZo1S36/X0OGDNEll1yi7OzshLYVAAAAwIGrxY5YrVy5Uh999JG6du1a6/4XXnhB8+fP13XXXae77rpLhYWFevjhhxPUSgAAAACtQYsMVlVVVXrsscf0+9//XmlpaZH7Kyoq9Mknn+iCCy7QwQcfrB49euiKK67QsmXLtHz58gS2GAAAAMCBrEVOBXzmmWd06KGHavDgwXrjjTci969evVrBYFCDBg2K3Jefn6+2bdtq+fLl6tOnT53n8/v98vv9kduGYSglJSXyfSKFr5/odhzo6Gfn0NfOoJ+dQT87h752Bv3sDPrZGU73c4sLVl999ZXWrFmj++67b6/HioqK5Ha7a41iSVJWVpaKiorqPef06dM1bdq0yO3u3bvr/vvvV7t27WLW7mh16NAh0U1oFehn59DXzqCfnUE/O4e+dgb97Az62RlO9XOLClYFBQV6/vnnddttt8nr9cbsvOPGjdNpp50WuR1Otdu3b1cgEIjZdZrCMAx16NBBW7dulW3bCW3LgYx+dg597Qz62Rn0s3Poa2fQz86gn50Rq352u90NGnBpUcFq9erVKi4u1k033RS5z7IsLVmyRO+//75uvfVWBQIBlZeX1xq1Ki4u3mdVQI/HI4/HU+djzeWH3bbtZtOWAxn97Bz62hn0szPoZ+fQ186gn51BPzvDqX5uUcFq0KBBeuihh2rd9+STT6pTp04644wz1LZtW7lcLi1YsEAjRoyQJG3evFkFBQX1rq8CAAAAgGi1qGCVkpKiLl261LovKSlJGRkZkfuPO+44vfjii0pPT1dqaqqee+459enTh2AFAAAAIG5aVLBqiAsuuECGYejhhx9WIBCIbBAMAAAAAPHS4oPVnXfeWeu21+vVJZdcQpgCAAAA4JgWuUEwAAAAADQnBCsAAAAAiBLBCgAAAACiRLACAAAAgCgRrAAAAAAgSgQrAAAAAIgSwQoAAAAAokSwAgAAAIAoEawAAAAAIEoEKwAAAACIEsEKAAAAAKJEsAIAAACAKBGsAAAAACBKBCsAAAAAiBLBCgAAAACiRLACAAAAgCgRrAAAAAAgSgQrAAAAAIgSwQoAAAAAokSwAgAAAIAoEawAAAAAIEoEKwAAAACIEsEKAAAAAKJEsAIAAACAKBGsAAAAACBKBCsAAAAAiBLBCgAAAACiRLACAAAAgCgRrAAAAAAgSgQrAAAAAIgSwQoAAAAAokSwAgAAAIAoEawAAAAAIEoEKwAAAACIEsEKAAAAAKJEsAIAAACAKBGsAAAAACBKBCsAAAAAiBLBCgAAAACiRLACAAAAgCgRrAAAAAAgSgQrAAAAAIgSwQoAAAAAokSwAgAAAIAoEawAAAAAIEoEKwAAAACIEsEKAAAAAKJEsAIAAACAKBGsAAAAACBKBCsAAAAAiBLBCgAAAACiRLACAAAAgCgRrAAAAAAgSgQrAAAAAIgSwQoAAAAAokSwAgAAAIAoEawAAAAAIEoEKwAAAACIEsEKAAAAAKJEsAIAAACAKBGsAAAAACBKBCsAAAAAiBLBCgAAAACiRLACAAAAgCgRrAAAAAAgSgQrAAAAAIgSwQoAAAAAokSwAgAAAIAoEawAAAAAIEoEKwAAAACIEsEKAAAAAKJEsAIAAACAKBGsAAAAACBKBCsAAAAAiBLBCgAAAACiRLACAAAAgCgRrAAAAAAgSgQrAAAAAIgSwQoAAAAAokSwAgAAAIAoEawAAAAAIEoEKwAAAACIEsEKAAAAAKJEsAIAAACAKBGsAAAAACBKBCsAAAAAiBLBCgAAAACiRLACAAAAgCgRrAAAAAAgSgQrAAAAAIgSwQoAAAAAokSwAgAAAIAouRPdgMaYPn265syZo02bNsnr9apPnz769a9/rU6dOkWO8fl8evHFFzVr1iz5/X4NGTJEl1xyibKzsxPXcAAAAAAHtBY1YrV48WKdeOKJmjJlim677TYFg0Hdc889qqqqihzzwgsvaP78+bruuut01113qbCwUA8//HACWw0AAADgQNeigtWtt96qMWPG6KCDDlK3bt00YcIEFRQUaPXq1ZKkiooKffLJJ7rgggt08MEHq0ePHrriiiu0bNkyLV++PMGtBwAAAHCgalFTAfdUUVEhSUpPT5ckrV69WsFgUIMGDYock5+fr7Zt22r58uXq06dPnefx+/3y+/2R24ZhKCUlJfJ9IoWvn+h2HOjoZ+fQ186gn51BPzuHvnYG/ewM+tkZTvdziw1WlmXp+eefV9++fdWlSxdJUlFRkdxut9LS0modm5WVpaKionrPNX36dE2bNi1yu3v37rr//vvVrl27uLS9KTp06JDoJrQK9LNz6Gtn0M/OoJ+dQ187g352Bv3sDKf6ucUGq2effVYbNmzQ5MmToz7XuHHjdNppp0Vuh1Pt9u3bFQgEoj5/NAzDUIcOHbR161bZtp3QthzI6Gfn0NfOoJ+dQT87h752Bv3sDPrZGbHqZ7fb3aABlxYZrJ599ll9++23uuuuu9SmTZvI/dnZ2QoEAiovL681alVcXLzPqoAej0cej6fOx5rLD7tt282mLQcy+tk59LUz6Gdn0M/Ooa+dQT87g352hlP93KKKV9i2rWeffVZz5szRHXfcoby8vFqP9+jRQy6XSwsWLIjct3nzZhUUFNS7vgoAAAAAotWiRqyeffZZzZw5UxMnTlRKSkpk3VRqaqq8Xq9SU1N13HHH6cUXX1R6erpSU1P13HPPqU+fPgQrAAAAAHHTooLVhx9+KEm68847a91/xRVXaMyYMZKkCy64QIZh6OGHH1YgEIhsEAwAAAAA8dKigtVrr72232O8Xq8uueQSwhQAAAAAx7SoNVYAAAAA0BwRrAAAAAAgSgQrAAAAAIgSwQoAAAAAokSwAgAAAIAoEawAAAAAIEoEKwAAAACIEsEKAAAAAKJEsAIAAACAKBGsAAAAACBKBCsAAAAAiBLBCgAAAACiRLACAAAAgCgRrAAAAAAgSgQrAAAAAIgSwQoAAAAAokSwAgAAAIAoEawAAAAAIEoEKwAAAACIEsEKAAAAAKJEsAIAAACAKBGsAAAAACBKBCsAAAAAiBLBCgAAAACiRLACAAAAgCgRrAAAAAAgSgQrAAAAAIgSwQoAAAAAokSwAgAAAIAoEawAAAAAIEoEKwAAAACIEsEKAAAAAKJEsAIAAACAKBGsAAAAACBKBCsAAAAAiBLBCgAAAACiRLACAAAAgCgRrAAAAAAgSgQrAAAAAIgSwQoAAAAAokSwAgAAAIAoEawAAAAAIEoEKwAAAACIkjvRDWipysvLFQgEZBhG3K9VWVkpn88X9+u0dvRzw6Wmpsrt5s8HAABAGO+MmqC6ulqGYSgrK8uR63k8Hvn9fkeu1ZrRzw1jWZZKS0uVlpZGuAIAAKjBVMAmqK6uVkpKSqKbASSEaZrKyMhQRUVFopsCAADQbBCsmsiJKYBAc2Wa/OkAAADYHe+OAAAAACBKBCsAAAAAiBLBCk0yfPhw/f3vf090MwAAAIBmgZJercTZZ5+tAQMGaPLkyTE537vvvqvU1NSYnAsAAABo6QhWiLBtW8FgsEEltNu0aeNAi5xl27YCgQAlxAEAANBoTAWMkm3bqvQHE/KfbdsNauO1116r2bNn69lnn1V+fr7y8/O1YcMGzZo1S/n5+frkk0900kknqXv37pozZ47Wrl2riy66SEOGDFHv3r11yimn6Isvvqh1zj2nAubn5+ull17S7373O/Xs2VOjRo3Shx9+uM92TZs2TSeffLL69OmjQw45RBMmTFBBQUGtY5YtW6bf/va36tu3r/r06aNx48Zp7dq1kcdfeeUVHXvsserevbsOPfRQ3XrrrZKkDRs2KD8/XwsXLowcW1xcrPz8fM2aNUuS9nr9nTt3bvDrr66u1pQpU3T44Yere/fuGjVqlF5++WXZtq1Ro0bpb3/7W63jFy5cqPz8fK1Zs2Y//1oAAABoifhoPkpVAUtjn/wxIdee8YfBSvG49nvc5MmTtXr1avXr10833HCDpNCI04YNGyRJ9957r+644w516dJFWVlZ2rx5s4477jjddNNN8nq9mjZtmi666CJ98cUXys/Pr/c6jzzyiG677Tbddttt+sc//qErr7xS33zzjXJycuo8PhAI6MYbb1TPnj1VUFCgu+66S3/84x/1z3/+U5K0ZcsWnXnmmRo5cqRee+01paena968eQoEApKkF154QZMnT9bNN9+sY489VqWlpZo7d26j+nD319+jRw+lpaU16PVfc801mj9/vu6++24NGDBA69ev186dO2UYhsaPH69XX31Vl19+eeQar732mkaMGKHu3bs3un0AAABo/ghWrUBmZqa8Xq+Sk5OVl5e31+M33nijjjnmmMjtnJwcDRw4MHJ74sSJev/99/Xhhx/qoosuqvc65557rn7xi19Ikv70pz/p2Wef1ffff69jjz22zuPPO++8yPddu3bV3XffrVNOOUXl5eVKS0vT888/r8zMTE2dOlUej0eS1LNnz8hz/vrXv+qyyy7TJZdcErnvkEMO2Xdn1CH8+j0ej/x+/35f/6pVq/S///1PL7/8cqTfunbtWqsfHnroIX333Xc69NBD5ff7NX36dN1+++2NbhsAAABaBoJVlJLdpmb8YXBcrxF+w1/XtWNh8ODa7S8vL9fDDz+sGTNmaNu2bQoEAqqqqtKmTZv2eZ7+/ftHvk9NTVVGRsZeU/t29+OPP+rhhx/W4sWLVVxcLMuyJEmbNm1Snz59tHjxYh1xxBGRULW7goICbd26VUcddVRjXmqdGvv6Fy1aJJfLpSOPPLLO83Xo0EFjx47VK6+8okMPPVQfffSRfD6ffv7zn0fdVgAAADRPBKsoGYbRoOl40fB4XHLLitv596zuN3nyZH355Ze6/fbb1a1bNyUnJ+uyyy6Tz+fbTztrByDDMCJhaU8VFRU6//zzNWbMGD3++ONq06aNNm3apPPPPz9yneTk5Hqvta/HJMk09w6d4SmEe2rs69/ftSXpl7/8pa655hrdeeedevXVV3X66acrJSVlv88DAABAy0TxilbC4/HUG3L2NG/ePJ1zzjk6+eST1b9/f+Xl5Wnjxo0xbc/KlStVWFiom2++WcOHD1evXr32Gt3q37+/5syZU+doXXp6ug466CDNnDmzzvPn5uZKkn766afIfYsWLWpQ2/b3+vv37y/LsjR79ux6zzF27FilpqbqxRdf1Geffabx48c36NoAAABomQhWrcRBBx2k7777Ths2bNDOnTv3GbK6d++u9957TwsXLtSiRYs0YcKEBoeyhsrPz5fX69U//vEPrVu3Th9++KH+8pe/1DrmwgsvVGlpqa644gr98MMPWr16taZNm6aVK1dKkq677jo9/fTTevbZZ7V69WotWLBAzz33nCQpJSVFhx12mJ544gmtWLFCs2fP1gMPPNCgtu3v9R900EE655xzdP311+v999/X+vXrNWvWLP33v/+NHONyuXTOOefo//7v/9S9e3cdfvjhUfYYAAAAmjOCVSvx+9//XqZpasyYMRo0aNA+10tNmjRJWVlZOuOMM3ThhRdGnhNLbdq00Z///Ge9/fbbOvbYY/X444/vVdwhNzdXr732msrLy3XWWWfp5JNP1ksvvRSZcnjuuefqzjvv1AsvvKDjjjtOF1xwQa1y5o888ogCgYBOOukkTZo0SRMnTmxQ2xry+u+77z6deuqpuuWWWzR69GjdeOONqqysrHXML3/5S/l8PkarAAAAWgHDbuhmSK3Q9u3b65yGVlJSoszMTMfaUV/xCsRWrPv5m2++0fjx4zV37ly1a9cuZudtLpr6e2AYhjp27KgtW7Y0eC82NB797Az62Tn0tTPoZ2fQz86IVT97PJ4GvZejeAUQY9XV1dqxY4cefvhhnXbaaQdkqAIAAEBtTAUEYuzNN9/U8OHDVVJSoltvvTXRzQEAAIADGLECYmz8+PGsqwIAAGhlGLECAAAAgCgRrAAAAAAgSgQrAAAAAIgSwQoAAAAAokSwAgAAAIAoEazQYMOHD9ff//73yO38/Hy9//779R6/YcMG5efna+HChXFv28MPP6zjjz8+7tcBAAAA6kK5dTTZd999p6ysrJie89prr1VJSYmee+65Rj3v8ssv10UXXRTTtgAAAAANRbBCk+Xl5SW6CRFpaWlKS0tLdDMcFwwGZRiGTJPBZwAAgETi3Vgr8K9//UuHHXaYLMuqdf9FF12k6667TpK0du1aXXTRRRoyZIh69+6tU045RV988cU+z7vnVMDvvvtOJ5xwgnr06KGTTz55rymAwWBQ119/vUaMGKGePXvq6KOP1jPPPBN5/OGHH9brr7+uDz74QPn5+crPz9esWbMkSVOmTNFRRx2lnj176sgjj9QDDzwgv99f67m7TwW0LEt//vOfNXToUHXv3l3HH3+8Pv3008jj4WmK7777rs4++2z17NlTY8aM0bx58/b5mp966imNHTtWvXr10uGHH66bb75Z5eXltY6ZO3du5JwDBgzQ+eefr6Kioki7pk6dqlGjRql79+4aNmyYHn30UUnSrFmzlJ+fr+Li4si5Fi5cqPz8fG3YsEGS9Oqrr6p///768MMPNWbMGHXv3l2bNm3S999/r/POO08HH3yw+vXrp7POOksLFiyo1a7i4mJNnDhRQ4YMUY8ePXTcccfpo48+UkVFhfr27au333671vHvv/++evXqpbKysn32CQAAABixippt21JVVXyvEQjI3i1ERCQnyzCM/T7/tNNO0+23366vvvpKRx99tCSpsLBQn332mV588UVJUnl5uY477jjddNNN8nq9mjZtmi666CJ98cUXys/P3+81ysvLdcEFF+iYY47RY489pvXr12vSpEm1jrEsSx07dtRTTz2lnJwczZs3TxMnTlReXp5OP/10XX755VqxYoXKysr0yCOPSJKys7MlhUak/vznP6tDhw5asmSJJk6cqPT0dF1xxRV1tueZZ57RU089pfvvv18DBw7Uq6++qosuukiffPKJevToETnu/vvv1+23367u3bvrwQcf1IQJE/TVV1/J7a77V8M0TU2ePFldunTRunXrdMstt+iee+7RfffdJykUhMaPH6/x48frrrvuktvt1qxZsyKh9r777tNLL72kSZMm6YgjjtC2bdu0cuXK/fbv7iorK/XEE0/owQcfVE5Ojtq2bat169bpnHPO0T333CPbtvXUU0/pN7/5jWbOnKn09HRZlqVf//rXKi8v12OPPaauXbtq+fLlcrlcSk1N1RlnnKFXX31Vp512WuQ6r776qk499VSlp6c3qn0AAACtEcEqWlVVKjn1tP0fFweZ77wtpaTs97js7Gwde+yxevPNNyPB6p133lFubq5GjRolSRo4cKAGDhwYec7EiRP1/vvv68MPP2zQ2qXp06fLsiw99NBDSk5OVt++fbVlyxbdfPPNkWM8Ho9uuOGGyO0uXbpo/vz5+t///qfTTz9daWlpSk5Ols/n22ua4bXXXhv5/qCDDtLq1av11ltv1RusnnrqKV1xxRU644wzJEm33nqrZs2apWeeeUb33ntv5LjLL79cP/vZzyKv+eijj9batWvVq1evOs976aWX1mrHxIkT9ac//SkSrJ588kkNHjw4cluS+vbtK0kqKyvTs88+q3vuuUfnnnuuJKlbt2464ogj6unVuvn9ft177721/r2OOuqoWsc88MAD6t+/v2bPnq3jjz9eX375pb7//nt99tln6tmzpySpa9eukeN/+ctf6owzztBPP/2k9u3bq6CgQJ988oleeeWVRrUNAACgtSJYtRLjxo3TxIkTde+99yopKUnTp0/X6aefHlmbU15erocfflgzZszQtm3bFAgEVFVVpU2bNjXo/CtWrFD//v2VnJwcuW/o0KF7Hff888/rlVde0aZNm1RVVSW/318rINTnrbfe0nPPPad169apvLxcwWCw3pGU0tJSbd26VcOGDat1/+GHH67FixfXuq9///6R79u3by9JKigoqDdYffHFF3r88ce1atUqlZaWKhgMqqqqSpWVlUpJSdGiRYtqjfrsbsWKFaqurt4rBDWW1+vVgAEDat23fft2PfDAA5o1a5Z27NihYDCoysrKyL/fokWL1LFjx0io2tOhhx6qPn366PXXX9eVV16p//znP+rcubNGjBgRVVsBAABaC4JVtJKTQyNHceTxeGqtJ9r92g11/PHHy7ZtzZgxQ0OGDNE333yjO++8M/L45MmT9eWXX+r2229Xt27dlJycrMsuu0w+ny8GryDkrbfe0t13363bb79dhx9+uNLS0vTkk0/qu+++2+fz5s2bp6uuukrXX3+9xowZo4yMDL311lt6+umno27T7lP+wtMq91yLFrZhwwZdeOGF+s1vfqObbrpJ2dnZmjt3rq6//nr5fD6lpKTUCpZ72tdjkiIh17btyH2BQKDO8+w5BfTaa69VYWGhJk+erM6dO8vr9er000+P/Nzs79qSdP755+v555/XlVdeqddee03nnntug6aaAgAAgOIVUTMMQ0ZKSmL+a8Sb3uTkZJ188smaPn263nrrLfXs2VODBg2KPD5v3jydc845Ovnkk9W/f3/l5eVp48aNDT5/7969tWTJElXttt7s22+/rXXM3LlzNXToUF144YU6+OCD1b17d61bt67WMV6vV8FgsNZ98+bNU+fOnXXNNddECi/sayQtIyNDHTp00Ny5c/c6T58+fRr8mvb0448/yrIsTZo0SUOHDlXPnj21devWWsf0799fM2fOrPP53bt3V3Jycr2Pt2nTRpK0bdu2yH2LFi1qUNvmzp2riy++WGPHjlXfvn3l9Xq1c+fOWu3asmWLVq1aVe85zjzzTG3atEnPPvusli9frnPOOadB1wYAAADBqlUZN26cZsyYoVdeeUXjxo2r9Vj37t313nvvaeHChVq0aJEmTJhQ78hNfec2DEM33nijli9frhkzZuhvf/vbXtf48ccf9dlnn2nVqlV64IEH9MMPP9Q6pnPnzlqyZIlWrlypnTt3yu/3R4LUW2+9pbVr1+rZZ5/Ve++9t8/2XH755Zo6dareeustrVy5Uvfee68WLVqk3/3udw1+TXvq1q2b/H5/ZEritGnT9M9//rPWMVdeeaV++OEH3XzzzVq8eLFWrlypF154QTt37lRycrImTJigKVOm6PXXX9fatWs1f/58vfzyy5Hzd+rUSQ8//LBWr16tjz/+WE899VSD2ta9e3f95z//0YoVK/Ttt9/qqquuqjVKdeSRR2r48OG67LLL9MUXX2j9+vX65JNPalVKzM7O1sknn6x77rlHo0ePVqdOnZrcVwAAAK0NwaoVOeqoo5Sdna1Vq1btFawmTZqkrKwsnXHGGbrwwgs1ZsyYWiNa+5OWlqbnn39eS5cu1Yknnqj7779ft956a61jfv3rX+vkk0/WH/7wB/385z9XYWGhLrjgglrH/OpXv1LPnj11yimnaNCgQZo7d65OOOEEXXrppbr11lt1wgknaN68ebWKWdTld7/7nS677DJNnjxZP/vZz/Tpp5/qH//4R62KgI01cOBATZo0SVOnTtVxxx2n6dOn1yrOIUk9e/bUSy+9pMWLF+u0007T6aefrg8//FAul0tSaMreZZddpoceekhjxozRH/7wBxUUFEgKTfmcOnWqVq1apeOPP15Tp07VxIkTG9S2hx9+WMXFxTrppJN09dVX6+KLL1bbtm1rHfP3v/9dQ4YM0RVXXKFjjz1WU6ZM2Wt08LzzzpPP59P48eOb2k0AAACtkmHvvqADtWzfvr3OtU0lJSXKzMx0rB31rrFCTNHP0rRp03TnnXfq22+/ldfr3eexTf09MAxDHTt21JYtW8Sfn/ihn51BPzuHvnYG/ewM+tkZsepnj8ejdu3a7fc4ilcAUGVlpX766Sc98cQT+vWvf73fUAUAAIDamAoIQFOnTtXo0aPVrl07XXXVVYluDgAAQIvDiBUAXX/99br++usT3QwAAIAWixErAAAAAIgSwQoAAAAAokSwAgAAAIAoEayaiNKYaM0as3k0AABAa0CwaoKkpCRVVlYmuhlAQliWpdLSUqWmpia6KQAAAM0GVQGbICkpSeXl5SouLpZhGHG/ntfrlc/ni/t1Wjv6ueHS0tLkdvPnAwAAIIx3Rk2UlpbmyHXYmdsZ9DMAAACiccAGq/fff1//+9//VFRUpK5du+riiy9Wr169Et0sAAAAAAegA3KN1axZs/Tiiy/q7LPP1v3336+uXbtqypQpKi4uTnTTAAAAAByADshg9fbbb2vs2LE69thj1blzZ1166aXyer369NNPE900AAAAAAegAy5YBQIBrV69WoMGDYrcZ5qmBg0apOXLlyewZQAAAAAOVAfcGquSkhJZlqXs7Oxa92dnZ2vz5s11Psfv98vv90duG4ahlJSUZlH1LFx10OPxUFQhjuhn59DXzqCfnUE/O4e+dgb97Az62Rmx6ueGZoLEJ4dmYPr06Zo2bVrk9qhRo3TNNdcoJycnga2qrW3btoluQqtAPzuHvnYG/ewM+tk59LUz6Gdn0M/OcKqfD7ipgJmZmTJNU0VFRbXuLyoq2msUK2zcuHF6/vnnI/9deumltUawEqmyslI33XQTGxLHGf3sHPraGfSzM+hn59DXzqCfnUE/O8Ppfj7ggpXb7VaPHj20cOHCyH2WZWnhwoXq06dPnc/xeDxKTU2t9Z/H43Gqyftk27bWrFnDMHGc0c/Ooa+dQT87g352Dn3tDPrZGfSzM5zu5wNyKuBpp52mJ554Qj169FCvXr307rvvqrq6WmPGjEl00wAAAAAcgA7IYDVy5EiVlJTotddeU1FRkbp166Zbbrml3qmAAAAAABCNAzJYSdJJJ52kk046KdHNiJrH49HZZ5/dbKYmHqjoZ+fQ186gn51BPzuHvnYG/ewM+tkZTvezYTO5EwAAAACicsAVrwAAAAAApxGsAADA/7d37zFN3e8fwN9URCgFC3YdVKQNlqqoWNTqsrlNxagxiyxuIjIS520myEy2GbcJLoigm7eYGec/wynx2hk33UDi5iaKl2nUqYhRuQ0j64BRqlIKaPv9w3B+v4qK2MKx3fuVEDyfc0qfPHly7NPzOZ9DREQuYmNFRERERETkIjZWRERERERELvLaVQG9QWFhIX766Sc0NjZCrVZj3rx50Gq1YoflVYxGI/bv3+80plKpsGnTJnEC8hKlpaU4dOgQKisrYTabsXTpUowZM0bY73A4YDQacfToUTQ1NWHw4MFYsGABwsPDRYzaM3WW6y1btqCoqMjpNSNGjEB6enpPh+qxfvjhB5w9exa3b9+Gn58fdDodUlJSoFKphGNaW1uRl5eHU6dOoa2tDSNGjMCCBQv4mI8uepZcZ2ZmorS01Ol1kyZNwgcffNDT4XqsI0eO4MiRI6irqwMARERE4N1330VcXBwA1rO7dJZn1nL3+PHHH7F7925MmzYN77//PoCeq2k2Vi+oU6dOIS8vDwsXLkR0dDTy8/ORk5ODTZs2oW/fvmKH51UGDBiAFStWCNsSCS/kuqqlpQUajQYTJ07E+vXrO+w/ePAgDh8+jMWLF0OpVGLfvn3IycnBxo0b4efnJ0LEnquzXAOAXq9HamqqsO3ry1N/V5SWlmLKlCkYOHAgHjx4gD179iA7OxsbN26Ev78/AGDHjh24cOECPv74Y0ilUuTm5mLDhg1YtWqVyNF7lmfJNQDEx8dj1qxZwjbPG10TGhqK5ORkhIeHw+FwoKioCGvXrsXatWsxYMAA1rObdJZngLXsbmVlZfjll1+gVqudxnuqpvkJ8gX1888/Iz4+HhMmTEBERAQWLlwIPz8//P7772KH5nUkEgnkcrnwExwcLHZIHi8uLg5JSUlOV07aORwOFBQUYMaMGTAYDFCr1UhLS4PZbMa5c+dEiNazPS3X7Xx9fZ1qXCaT9WCEni89PR3jx4/HgAEDoNFosHjxYtTX16OiogIAYLVa8dtvv2HOnDkYNmwYoqKikJqaiuvXr+PGjRsiR+9ZOst1uz59+jjVtFQqFSlizzR69GiMHDkS4eHhUKlUmD17Nvz9/XHz5k3Wsxs9Lc/tWMvuY7PZsHnzZixatAiBgYHCeE/WNL+2fAHdv38fFRUVePvtt4UxiUSC4cOH86TWDUwmExYtWoTevXtDp9MhOTkZCoVC7LC8Vm1tLRobGxEbGyuMSaVSaLVa3LhxA6+99pqI0Xmn0tJSLFiwAIGBgRg2bBiSkpIQFBQkdlgey2q1AoDQoFZUVODBgwcYPny4cEz//v2hUChw48YN6HQ6UeL0Bo/mut2JEydw4sQJyOVyjBo1Cu+88w769OkjRogez2634/Tp02hpaYFOp2M9d5NH89yOtew+3377LeLi4hAbG4sDBw4I4z1Z02ysXkB37tyB3W7vMO9TLpejpqZGnKC8VHR0NFJTU6FSqWA2m7F//3588cUX2LBhAwICAsQOzys1NjYCQIcprX379hX2kfvo9XqMHTsWSqUSJpMJe/bswerVq5GTk8Npr8/Bbrdj+/btGDRoECIjIwE8rGlfX1+nb0gB1rSrHpdrABg3bhwUCgVCQ0Px119/YdeuXaipqcHSpUtFjNbzVFdXIz09HW1tbfD398fSpUsRERGBqqoq1rMbPSnPAGvZnU6ePInKykqsWbOmw76ePEezsaL/tPYbSAFArVYLjdbp06cxceJEESMjco//fwUwMjISarUaH374Ia5ever07R09m9zcXNy6dQtZWVlih+L1npTrSZMmCf+OjIxESEgIsrKyYDKZEBYW1tNheiyVSoV169bBarXizJkz2LJlC1auXCl2WF7nSXmOiIhgLbtJfX09tm/fjoyMDNHvUWNj9QIKDg6GRCLp0EU3NjZyRZ5uFhgYCJVKBZPJJHYoXqu9hi0WC0JCQoRxi8UCjUYjTlD/IS+//DKCgoJgMpnYWHVRbm4uLly4gJUrV6Jfv37CuFwux/3799HU1OT0jajFYuE5+zk9KdeP075aLj+Mdo2vr6+Qr6ioKJSXl6OgoACvvvoq69mNnpTnx638x1p+PhUVFbBYLPj000+FMbvdjmvXrqGwsBDp6ek9VtNsrF5Avr6+iIqKQklJiXBDut1uR0lJCaZOnSpydN7NZrPBZDLh9ddfFzsUr6VUKiGXy3HlyhWhkbJarSgrK8PkyZPFDe4/4N9//8W9e/ecmlp6OofDgW3btuHs2bPIzMyEUql02h8VFYVevXrhypUreOWVVwAANTU1qK+v5/0oXdRZrh+nqqoKAFjTLrLb7Whra2M9d7P2PD8Oa/n5DB8+vMOquFu3boVKpUJCQgIUCkWP1TQbqxfUW2+9hS1btiAqKgparRYFBQVoaWnB+PHjxQ7Nq+Tl5WH06NFQKBQwm80wGo2QSCQYN26c2KF5tPYGtV1tbS2qqqogk8mgUCgwbdo0HDhwAOHh4VAqldi7dy9CQkJgMBhEjNozPS3XMpkM33//PcaOHQu5XI5//vkHO3fuRFhYGEaMGCFi1J4lNzcXxcXFWLZsGQICAoTZBFKpFH5+fpBKpZg4cSLy8vIgk8kglUqxbds26HQ6fhDtos5ybTKZUFxcjJEjR0Imk6G6uho7duzAkCFDOiyvTE+2e/du6PV6KBQK2Gw2FBcXo7S0FOnp6axnN3panlnL7hMQEOB0HybwcLXFoKAgYbynatrH4XA43PoXyW0KCwtx6NAhNDY2QqPRYO7cuYiOjhY7LK+yadMmXLt2DXfv3kVwcDAGDx6MpKQkXoJ30dWrVx87V//NN9/E4sWLhQcE//rrr7BarRg8eDDmz5/v9BBQejZPy/XChQuxbt06VFZWoqmpCaGhoYiNjcWsWbM4pacLEhMTHzuempoqfNnV/vDJkydP4v79+3yg6nPqLNf19fXYvHkzbt26hZaWFvTr1w9jxozBjBkzuEx1F2zduhUlJSUwm82QSqVQq9VISEgQVmtlPbvH0/LMWu5emZmZ0Gg0HR4Q3N01zcaKiIiIiIjIRVxrl4iIiIiIyEVsrIiIiIiIiFzExoqIiIiIiMhFbKyIiIiIiIhcxMaKiIiIiIjIRWysiIiIiIiIXMTGioiIiIiIyEVsrIiIiNzg2LFjSExMRHl5udihEBGRCHzFDoCIiOhZHTt2DN98880T92dnZ0On0/VgRERERA+xsSIiIo+TmJgIpVLZYTwsLEyEaIiIiNhYERGRB4qLi8PAgQPFDoOIiEjAxoqIiLxKbW0t0tLSkJKSAolEgoKCAlgsFmi1WsyfPx+RkZFOx5eUlMBoNKKyshK9evVCTEwMkpOTERER4XRcQ0MD9u3bhz///BN3795FSEgI9Ho95s6dC1/f//vvtK2tDTt27MDx48fR2tqK2NhYLFq0CMHBwcIx5eXl2Lt3LyoqKmCz2SCXyzF06FCkpqZ2b3KIiKjbsLEiIiKPY7VacefOHacxHx8fBAUFCdvHjx9Hc3MzpkyZgra2NhQUFCArKwvr16+HXC4HAFy+fBlr1qyBUqnEzJkz0draisOHD2PFihX46quvhOmGDQ0N+Pzzz2G1WhEfH4/+/fujoaEBZ86cQUtLi1Nj9d133yEwMBAzZ85EbW0tCgoKkJubi48++ggAYLFYkJ2djeDgYCQkJCAwMBB1dXX4448/ujlrRETUndhYERGRx1m1alWHsd69e2PXrl3Ctslkwtdff43Q0FAAgF6vx/Lly3Hw4EHMmTMHALBz507IZDLk5ORAJpMBAAwGA5YtWwaj0Yi0tDQAwO7du9HY2IjVq1c7TUGcNWsWHA6HUxwymQwZGRnw8fEBADgcDhw+fBhWqxVSqRTXr19HU1MTMjIynP5WUlKSO1JDREQiYWNFREQeZ/78+QgPD3cak0icnyBiMBiEpgoAtFotoqOjcfHiRcyZMwdmsxlVVVWYPn260FQBgFqtRmxsLC5evAgAsNvtOHfuHEaNGvXY+7raG6h2kyZNchobMmQI8vPzUVdXB7VajcDAQADA+fPnoVarna52ERGR5+LZnIiIPI5Wq+108YpHG6/2sdOnTwMA6urqAAAqlarDcf3798elS5dgs9lgs9nQ3Nzc4d6sJ1EoFE7b7Y1UU1MTACAmJgZjx47F/v37kZ+fj6FDh8JgMGDcuHHo3bv3M70HERG9ePiAYCIiIjd69MpZu/Ypgz4+Pvjkk0+QnZ2NqVOnoqGhAVu3bsVnn30Gm83Wk6ESEZEbsbEiIiKv9Pfffz927KWXXgIA4XdNTU2H42pqahAUFAR/f38EBwcjICAA1dXVbo1Pp9Nh9uzZ+PLLL7FkyRLcunULJ0+edOt7EBFRz2FjRUREXuncuXNoaGgQtsvKynDz5k3o9XoAQEhICDQaDYqKioRpegBQXV2NS5cuIS4uDsDDK1AGgwHnz59HeXl5h/d5dPGKzty7d6/DazQaDYCHS7UTEZFn4j1WRETkcS5evIjbt293GB80aJCwcERYWBhWrFiByZMnC8utBwUFISEhQTg+JSUFa9asQUZGBiZMmIDW1lYUFhZCKpUiMTFROC45ORmXL19GZmYm4uPjERERAbPZjDNnziArK0u4j+pZFBUV4ciRIzAYDAgLC0NzczOOHj2KgIAAjBw50oWsEBGRmNhYERGRxzEajY8dT01NRUxMDADgjTfegEQiQX5+Pu7cuQOtVot58+YhJCREOD42NhbLly+H0WiE0WgUHhD83nvvCc+wAoDQ0FCsXr0ae/fuRXFxMZqbmxEaGgq9Xo8+ffp0KfaYmBiUlZXh1KlTsFgskEqlGDhwIJYsWeL0nkRE5Fl8HF2dw0BERPQCq62tRVpaGlJSUjB9+nSxwyEiov8I3mNFRERERETkIjZWRERERERELmJjRURERERE5CLeY0VEREREROQiXrEiIiIiIiJyERsrIiIiIiIiF7GxIiIiIiIichEbKyIiIiIiIhexsSIiIiIiInIRGysiIiIiIiIXsbEiIiIiIiJyERsrIiIiIiIiF7GxIiIiIiIictH/AKBQbgm1suLqAAAAAElFTkSuQmCC\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x700 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# Save model\n","torch.save(model.state_dict(), '/content/drive/MyDrive/Curriculum Learning Experiment/Model Weights/resnet18_fore40.pt')"],"metadata":{"id":"Di-zrkoyBeFN","executionInfo":{"status":"ok","timestamp":1699125151228,"user_tz":240,"elapsed":286,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"}}},"execution_count":37,"outputs":[]}]}