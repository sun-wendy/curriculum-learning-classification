{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":374865,"status":"ok","timestamp":1699237000089,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"XzM32K4bzCOk","outputId":"2ca1a335-c1af-47aa-d937-98f4cb5103a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"WuTpCy9iaLia"},"source":["**Code reference:** https://www.appsloveworld.com/python/1383/how-to-extract-foreground-objects-from-coco-dataset-or-open-images-v6-dataset?expand_article=1"]},{"cell_type":"markdown","metadata":{"id":"0hmCPosKMJPR"},"source":["### **Preprocess COCO dataset**"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":431,"status":"ok","timestamp":1699237000517,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"Hk4nEOUcMpqH"},"outputs":[],"source":["import os\n","import cv2 as cv\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699237000517,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"gFXePTrOMvoB"},"outputs":[],"source":["def extract_classwise_instances(samples, output_dir, label_field, ext=\".png\"):\n","    print(\"Extracting object instances...\")\n","    for sample in samples.iter_samples(progress=True):\n","        img = cv.imread(sample.filepath)\n","        img_h, img_w, c = img.shape\n","        for det in sample[label_field].detections:\n","            mask = det.mask\n","            [x, y, w, h] = det.bounding_box\n","            x = int(x * img_w)\n","            y = int(y * img_h)\n","            h, w = mask.shape\n","            mask_img = img[y:y+h, x:x+w, :]\n","            alpha = mask.astype(np.uint8)*255\n","            alpha = np.expand_dims(alpha, 2)\n","            mask_img = np.concatenate((mask_img, alpha), axis=2)\n","\n","            label = det.label\n","            label_dir = os.path.join(output_dir, label)\n","            if not os.path.exists(label_dir):\n","                os.mkdir(label_dir)\n","            output_filepath = os.path.join(label_dir, det.id+ext)\n","            cv.imwrite(output_filepath, mask_img)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1699237000517,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"s9ex5lm82aEU"},"outputs":[],"source":["def save_composite(samples, output_dir, label_field, ext=\".png\"):\n","    print(\"Saving composite images...\")\n","    for sample in samples.iter_samples(progress=True):\n","        img = cv.imread(sample.filepath)\n","        img_h, img_w, c = img.shape\n","        output_filepath = output_dir\n","\n","        counter = 0\n","        for i, det in enumerate(sample[label_field].detections):\n","            if counter \u003e 0:\n","              break\n","            label = det.label\n","            label_dir = os.path.join(output_dir, label)\n","            if not os.path.exists(label_dir):\n","                os.mkdir(label_dir)\n","            output_filepath = os.path.join(label_dir, det.id+ext)\n","        cv.imwrite(output_filepath, img)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45990,"status":"ok","timestamp":1699237046503,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"6U8FeIKbISdY","outputId":"cff3796e-525b-452d-d961-31f59733cf6f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting fiftyone\n","  Downloading fiftyone-0.22.3-py3-none-any.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles (from fiftyone)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Collecting argcomplete (from fiftyone)\n","  Downloading argcomplete-3.1.4-py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.11.2)\n","Collecting boto3 (from fiftyone)\n","  Downloading boto3-1.28.78-py3-none-any.whl (135 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.3.2)\n","Collecting dacite\u003c1.8.0,\u003e=1.6.0 (from fiftyone)\n","  Downloading dacite-1.7.0-py3-none-any.whl (12 kB)\n","Collecting Deprecated (from fiftyone)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Collecting ftfy (from fiftyone)\n","  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.7.0)\n","Collecting hypercorn\u003e=0.13.2 (from fiftyone)\n","  Downloading hypercorn-0.15.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Jinja2\u003e=3 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.1.2)\n","Collecting kaleido!=0.2.1.post1 (from fiftyone)\n","  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.7.1)\n","Collecting mongoengine==0.24.2 (from fiftyone)\n","  Downloading mongoengine-0.24.2-py3-none-any.whl (108 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting motor\u003e=2.5 (from fiftyone)\n","  Downloading motor-3.3.1-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fiftyone) (23.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.5.3)\n","Requirement already satisfied: Pillow\u003e=6.2 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (9.4.0)\n","Requirement already satisfied: plotly\u003e=4.14 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.15.0)\n","Collecting pprintpp (from fiftyone)\n","  Downloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.9.5)\n","Collecting pymongo\u003e=3.12 (from fiftyone)\n","  Downloading pymongo-4.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.1/677.1 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2023.3.post1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from fiftyone) (6.0.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2023.6.3)\n","Collecting retrying (from fiftyone)\n","  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.2.2)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.19.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (67.7.2)\n","Collecting sseclient-py\u003c2,\u003e=1.7.2 (from fiftyone)\n","  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n","Collecting sse-starlette\u003c1,\u003e=0.10.3 (from fiftyone)\n","  Downloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\n","Collecting starlette\u003e=0.24.0 (from fiftyone)\n","  Downloading starlette-0.32.0-py3-none-any.whl (69 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.0/70.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting strawberry-graphql==0.138.1 (from fiftyone)\n","  Downloading strawberry_graphql-0.138.1-py3-none-any.whl (192 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.5/192.5 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.9.0)\n","Collecting xmltodict (from fiftyone)\n","  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n","Collecting universal-analytics-python3\u003c2,\u003e=1.0.1 (from fiftyone)\n","  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\n","Collecting fiftyone-brain~=0.13.2 (from fiftyone)\n","  Downloading fiftyone_brain-0.13.3-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fiftyone-db~=0.4 (from fiftyone)\n","  Downloading fiftyone_db-0.4.2.tar.gz (7.7 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting voxel51-eta~=0.12 (from fiftyone)\n","  Downloading voxel51_eta-0.12.0-py2.py3-none-any.whl (570 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.0/570.0 kB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.8.1.78)\n","Collecting graphql-core\u003c3.3.0,\u003e=3.2.0 (from strawberry-graphql==0.138.1-\u003efiftyone)\n","  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil\u003c3.0.0,\u003e=2.7.0 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1-\u003efiftyone) (2.8.2)\n","Requirement already satisfied: typing_extensions\u003c5.0.0,\u003e=3.7.4 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1-\u003efiftyone) (4.5.0)\n","Requirement already satisfied: scipy\u003e=1.2.0 in /usr/local/lib/python3.10/dist-packages (from fiftyone-brain~=0.13.2-\u003efiftyone) (1.11.3)\n","Collecting h11 (from hypercorn\u003e=0.13.2-\u003efiftyone)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h2\u003e=3.1.0 (from hypercorn\u003e=0.13.2-\u003efiftyone)\n","  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting priority (from hypercorn\u003e=0.13.2-\u003efiftyone)\n","  Downloading priority-2.0.0-py3-none-any.whl (8.9 kB)\n","Collecting taskgroup (from hypercorn\u003e=0.13.2-\u003efiftyone)\n","  Downloading taskgroup-0.0.0a4-py2.py3-none-any.whl (9.1 kB)\n","Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from hypercorn\u003e=0.13.2-\u003efiftyone) (2.0.1)\n","Collecting wsproto\u003e=0.14.0 (from hypercorn\u003e=0.13.2-\u003efiftyone)\n","  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2\u003e=3-\u003efiftyone) (2.1.3)\n","Requirement already satisfied: tenacity\u003e=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly\u003e=4.14-\u003efiftyone) (8.2.3)\n","Collecting dnspython\u003c3.0.0,\u003e=1.16.0 (from pymongo\u003e=3.12-\u003efiftyone)\n","  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio\u003c5,\u003e=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette\u003e=0.24.0-\u003efiftyone) (3.7.1)\n","Collecting httpx\u003e=0.10.0 (from universal-analytics-python3\u003c2,\u003e=1.0.1-\u003efiftyone)\n","  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill (from voxel51-eta~=0.12-\u003efiftyone)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12-\u003efiftyone) (0.18.3)\n","Requirement already satisfied: glob2 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12-\u003efiftyone) (0.7)\n","Collecting jsonlines (from voxel51-eta~=0.12-\u003efiftyone)\n","  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n","Collecting py7zr (from voxel51-eta~=0.12-\u003efiftyone)\n","  Downloading py7zr-0.20.7-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rarfile (from voxel51-eta~=0.12-\u003efiftyone)\n","  Downloading rarfile-4.1-py3-none-any.whl (28 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12-\u003efiftyone) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12-\u003efiftyone) (1.16.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12-\u003efiftyone) (2.4.0)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12-\u003efiftyone) (5.2)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta~=0.12-\u003efiftyone) (2.0.7)\n","Requirement already satisfied: soupsieve\u003e1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4-\u003efiftyone) (2.5)\n","Collecting botocore\u003c1.32.0,\u003e=1.31.78 (from boto3-\u003efiftyone)\n","  Downloading botocore-1.31.78-py3-none-any.whl (11.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath\u003c2.0.0,\u003e=0.7.1 (from boto3-\u003efiftyone)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer\u003c0.8.0,\u003e=0.7.0 (from boto3-\u003efiftyone)\n","  Downloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wrapt\u003c2,\u003e=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated-\u003efiftyone) (1.14.1)\n","Requirement already satisfied: wcwidth\u003e=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy-\u003efiftyone) (0.2.8)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003efiftyone) (1.1.1)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003efiftyone) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003efiftyone) (4.43.1)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003efiftyone) (1.4.5)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003efiftyone) (3.1.1)\n","Requirement already satisfied: networkx\u003e=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image-\u003efiftyone) (3.2)\n","Requirement already satisfied: imageio\u003e=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image-\u003efiftyone) (2.31.6)\n","Requirement already satisfied: tifffile\u003e=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image-\u003efiftyone) (2023.9.26)\n","Requirement already satisfied: PyWavelets\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image-\u003efiftyone) (1.4.1)\n","Requirement already satisfied: joblib\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn-\u003efiftyone) (1.3.2)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn-\u003efiftyone) (3.2.0)\n","Requirement already satisfied: idna\u003e=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio\u003c5,\u003e=3.4.0-\u003estarlette\u003e=0.24.0-\u003efiftyone) (3.4)\n","Requirement already satisfied: sniffio\u003e=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio\u003c5,\u003e=3.4.0-\u003estarlette\u003e=0.24.0-\u003efiftyone) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio\u003c5,\u003e=3.4.0-\u003estarlette\u003e=0.24.0-\u003efiftyone) (1.1.3)\n","Collecting hyperframe\u003c7,\u003e=6.0 (from h2\u003e=3.1.0-\u003ehypercorn\u003e=0.13.2-\u003efiftyone)\n","  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n","Collecting hpack\u003c5,\u003e=4.0 (from h2\u003e=3.1.0-\u003ehypercorn\u003e=0.13.2-\u003efiftyone)\n","  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx\u003e=0.10.0-\u003euniversal-analytics-python3\u003c2,\u003e=1.0.1-\u003efiftyone) (2023.7.22)\n","Collecting httpcore (from httpx\u003e=0.10.0-\u003euniversal-analytics-python3\u003c2,\u003e=1.0.1-\u003efiftyone)\n","  Downloading httpcore-1.0.1-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs\u003e=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines-\u003evoxel51-eta~=0.12-\u003efiftyone) (23.1.0)\n","Collecting texttable (from py7zr-\u003evoxel51-eta~=0.12-\u003efiftyone)\n","  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n","Collecting pycryptodomex\u003e=3.16.0 (from py7zr-\u003evoxel51-eta~=0.12-\u003efiftyone)\n","  Downloading pycryptodomex-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyzstd\u003e=0.15.9 (from py7zr-\u003evoxel51-eta~=0.12-\u003efiftyone)\n","  Downloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyppmd\u003c1.2.0,\u003e=1.1.0 (from py7zr-\u003evoxel51-eta~=0.12-\u003efiftyone)\n","  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pybcj\u003c1.1.0,\u003e=1.0.0 (from py7zr-\u003evoxel51-eta~=0.12-\u003efiftyone)\n","  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multivolumefile\u003e=0.2.3 (from py7zr-\u003evoxel51-eta~=0.12-\u003efiftyone)\n","  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n","Collecting inflate64\u003c1.1.0,\u003e=1.0.0 (from py7zr-\u003evoxel51-eta~=0.12-\u003efiftyone)\n","  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting brotli\u003e=1.1.0 (from py7zr-\u003evoxel51-eta~=0.12-\u003efiftyone)\n","  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003evoxel51-eta~=0.12-\u003efiftyone) (3.3.1)\n","Building wheels for collected packages: fiftyone-db\n","  Building wheel for fiftyone-db (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fiftyone-db: filename=fiftyone_db-0.4.2-py3-none-manylinux1_x86_64.whl size=42156165 sha256=907b312176053a64e80dabd1609b5beac053ca6005c57fcc9f036ef4f892069d\n","  Stored in directory: /root/.cache/pip/wheels/5a/de/29/0fc86b17f83d9466513fa2c2182676983b5af53bb0b72ec1a7\n","Successfully built fiftyone-db\n","Installing collected packages: texttable, sseclient-py, pprintpp, kaleido, brotli, xmltodict, taskgroup, retrying, rarfile, pyzstd, pyppmd, pycryptodomex, pybcj, priority, multivolumefile, jsonlines, jmespath, inflate64, hyperframe, hpack, h11, graphql-core, ftfy, fiftyone-db, dnspython, dill, Deprecated, dacite, argcomplete, aiofiles, wsproto, strawberry-graphql, starlette, pymongo, py7zr, httpcore, h2, botocore, voxel51-eta, sse-starlette, s3transfer, motor, mongoengine, hypercorn, httpx, fiftyone-brain, universal-analytics-python3, boto3, fiftyone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Deprecated-1.2.14 aiofiles-23.2.1 argcomplete-3.1.4 boto3-1.28.78 botocore-1.31.78 brotli-1.1.0 dacite-1.7.0 dill-0.3.7 dnspython-2.4.2 fiftyone-0.22.3 fiftyone-brain-0.13.3 fiftyone-db-0.4.2 ftfy-6.1.1 graphql-core-3.2.3 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.1 httpx-0.25.1 hypercorn-0.15.0 hyperframe-6.0.1 inflate64-1.0.0 jmespath-1.0.1 jsonlines-4.0.0 kaleido-0.2.1 mongoengine-0.24.2 motor-3.3.1 multivolumefile-0.2.3 pprintpp-0.4.0 priority-2.0.0 py7zr-0.20.7 pybcj-1.0.2 pycryptodomex-3.19.0 pymongo-4.6.0 pyppmd-1.1.0 pyzstd-0.15.9 rarfile-4.1 retrying-1.3.4 s3transfer-0.7.0 sse-starlette-0.10.3 sseclient-py-1.8.0 starlette-0.32.0 strawberry-graphql-0.138.1 taskgroup-0.0.0a4 texttable-1.7.0 universal-analytics-python3-1.1.1 voxel51-eta-0.12.0 wsproto-1.2.0 xmltodict-0.13.0\n","Collecting fiftyone-db-ubuntu2204\n","  Downloading fiftyone_db_ubuntu2204-0.4.0-py3-none-manylinux1_x86_64.whl (42.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: fiftyone-db-ubuntu2204\n","Successfully installed fiftyone-db-ubuntu2204-0.4.0\n"]}],"source":["!pip install fiftyone\n","!pip install fiftyone-db-ubuntu2204"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6888,"status":"ok","timestamp":1699237053378,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"GW0YoZnCGWE0","outputId":"0706f69c-9320-4965-8338-3afa317c1153"},"outputs":[{"name":"stdout","output_type":"stream","text":["Migrating database to v0.22.3\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.migrations.runner:Migrating database to v0.22.3\n"]}],"source":["import fiftyone as fo\n","import fiftyone.zoo as foz\n","from fiftyone import ViewField as F"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1699237053378,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"vvgHIsRHIfaU","outputId":"eef801f9-755a-48b2-86bc-d3e6247044db"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\ndataset_name = \"coco-image-example\"\\nif dataset_name in fo.list_datasets():\\n    fo.delete_dataset(dataset_name)\\n'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","dataset_name = \"coco-image-example\"\n","if dataset_name in fo.list_datasets():\n","    fo.delete_dataset(dataset_name)\n","\"\"\""]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699237053378,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"OtQkl5U4L5Km"},"outputs":[],"source":["label_field = \"ground_truth\"\n","classes = [\"horse\", \"airplane\", \"toilet\", \"train\"]"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1850500,"status":"ok","timestamp":1699238903871,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"B6ZQTp3qMQZT","outputId":"86f1a93d-22d7-45bf-e78c-dd685c1b216f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"]},{"name":"stdout","output_type":"stream","text":["Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.utils.coco:Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"]},{"name":"stdout","output_type":"stream","text":[" 100% |██████|    1.9Gb/1.9Gb [13.8s elapsed, 0s remaining, 172.1Mb/s]      \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |██████|    1.9Gb/1.9Gb [13.8s elapsed, 0s remaining, 172.1Mb/s]      \n"]},{"name":"stdout","output_type":"stream","text":["Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.utils.coco:Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"]},{"name":"stdout","output_type":"stream","text":["Downloading 12825 images\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.utils.coco:Downloading 12825 images\n"]},{"name":"stdout","output_type":"stream","text":[" 100% |██████████████| 12825/12825 [28.1m elapsed, 0s remaining, 8.8 images/s]      \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |██████████████| 12825/12825 [28.1m elapsed, 0s remaining, 8.8 images/s]      \n"]},{"name":"stdout","output_type":"stream","text":["Writing annotations for 12825 downloaded samples to '/root/fiftyone/coco-2017/train/labels.json'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.utils.coco:Writing annotations for 12825 downloaded samples to '/root/fiftyone/coco-2017/train/labels.json'\n"]},{"name":"stdout","output_type":"stream","text":["Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"]},{"name":"stdout","output_type":"stream","text":["Loading 'coco-2017' split 'train'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'train'\n"]},{"name":"stdout","output_type":"stream","text":[" 100% |█████████████| 12825/12825 [2.0m elapsed, 0s remaining, 111.8 samples/s]      \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |█████████████| 12825/12825 [2.0m elapsed, 0s remaining, 111.8 samples/s]      \n"]},{"name":"stdout","output_type":"stream","text":["Dataset 'coco-2017-train' created\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-train' created\n"]},{"name":"stdout","output_type":"stream","text":["12825\n"]}],"source":["train_dataset = foz.load_zoo_dataset(\"coco-2017\",\n","                                     split=\"train\",\n","                                     label_types=[\"segmentations\"],\n","                                     classes=classes,\n","                                     # max_samples=10,\n","                                     shuffle=True,\n","                                     label_field=label_field)\n","print(len(train_dataset))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":75900,"status":"ok","timestamp":1699238979753,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"q71MMrg49fvD","outputId":"4181187c-56f0-4a2e-887f-2b0e2982abb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"]},{"name":"stdout","output_type":"stream","text":["Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.utils.coco:Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"]},{"name":"stdout","output_type":"stream","text":["Downloading 527 images\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.utils.coco:Downloading 527 images\n"]},{"name":"stdout","output_type":"stream","text":[" 100% |██████████████████| 527/527 [1.2m elapsed, 0s remaining, 7.7 images/s]      \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |██████████████████| 527/527 [1.2m elapsed, 0s remaining, 7.7 images/s]      \n"]},{"name":"stdout","output_type":"stream","text":["Writing annotations for 527 downloaded samples to '/root/fiftyone/coco-2017/validation/labels.json'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.utils.coco:Writing annotations for 527 downloaded samples to '/root/fiftyone/coco-2017/validation/labels.json'\n"]},{"name":"stdout","output_type":"stream","text":["Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"]},{"name":"stdout","output_type":"stream","text":["Loading 'coco-2017' split 'validation'\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'validation'\n"]},{"name":"stdout","output_type":"stream","text":[" 100% |█████████████████| 527/527 [4.9s elapsed, 0s remaining, 117.7 samples/s]      \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |█████████████████| 527/527 [4.9s elapsed, 0s remaining, 117.7 samples/s]      \n"]},{"name":"stdout","output_type":"stream","text":["Dataset 'coco-2017-validation' created\n"]},{"name":"stderr","output_type":"stream","text":["INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-validation' created\n"]},{"name":"stdout","output_type":"stream","text":["527\n"]}],"source":["test_dataset = foz.load_zoo_dataset(\"coco-2017\",\n","                                    split=\"validation\",\n","                                    label_types=[\"segmentations\"],\n","                                    classes=classes,\n","                                    # max_samples=10,\n","                                    shuffle=True,\n","                                    label_field=label_field)\n","print(len(test_dataset))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":415,"status":"ok","timestamp":1699238980151,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"FdhxGsZ2MWnr","outputId":"e338ed41-4cfd-4f77-a867-60226bf7774f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset:     coco-2017-train\n","Media type:  image\n","Num samples: 12825\n","Sample fields:\n","    id:           fiftyone.core.fields.ObjectIdField\n","    filepath:     fiftyone.core.fields.StringField\n","    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n","    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n","    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n","View stages:\n","    1. FilterLabels(field='ground_truth', filter={'$in': ['$$this.label', [...]]}, only_matches=True, trajectories=False)\n","Dataset:     coco-2017-validation\n","Media type:  image\n","Num samples: 527\n","Sample fields:\n","    id:           fiftyone.core.fields.ObjectIdField\n","    filepath:     fiftyone.core.fields.StringField\n","    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n","    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n","    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n","View stages:\n","    1. FilterLabels(field='ground_truth', filter={'$in': ['$$this.label', [...]]}, only_matches=True, trajectories=False)\n"]}],"source":["train_view = train_dataset.filter_labels(label_field, F(\"label\").is_in(classes))\n","print(train_view)\n","test_view = test_dataset.filter_labels(label_field, F(\"label\").is_in(classes))\n","print(test_view)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699238980152,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"AvhjTVqoMb72"},"outputs":[],"source":["foreground_train_output_dir = \"/data/foreground/train\"\n","foreground_test_output_dir = \"/data/foreground/test\"\n","composite_train_output_dir = \"/data/composite/train\"\n","composite_test_output_dir = \"/data/composite/test\"\n","\n","os.makedirs(foreground_train_output_dir, exist_ok=True)\n","os.makedirs(foreground_test_output_dir, exist_ok=True)\n","os.makedirs(composite_train_output_dir, exist_ok=True)\n","os.makedirs(composite_test_output_dir, exist_ok=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":199579,"status":"ok","timestamp":1699239179724,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"sDPw0iSINaph","outputId":"d4d7bbbf-9831-42a7-be91-0c9e7edf5915"},"outputs":[{"name":"stdout","output_type":"stream","text":["Extracting object instances...\n"," 100% |█████████████| 12825/12825 [3.2m elapsed, 0s remaining, 65.2 samples/s]      \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |█████████████| 12825/12825 [3.2m elapsed, 0s remaining, 65.2 samples/s]      \n"]},{"name":"stdout","output_type":"stream","text":["Extracting object instances...\n"," 100% |█████████████████| 527/527 [7.6s elapsed, 0s remaining, 68.2 samples/s]      \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |█████████████████| 527/527 [7.6s elapsed, 0s remaining, 68.2 samples/s]      \n"]}],"source":["extract_classwise_instances(train_view, foreground_train_output_dir, label_field)\n","extract_classwise_instances(test_view, foreground_test_output_dir, label_field)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324651,"status":"ok","timestamp":1699239504354,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"0nKnJf32xRjl","outputId":"b3cfd9f0-993e-4dad-8d26-5bd851c91b90"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving composite images...\n"," 100% |█████████████| 12825/12825 [5.2m elapsed, 0s remaining, 41.7 samples/s]      \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |█████████████| 12825/12825 [5.2m elapsed, 0s remaining, 41.7 samples/s]      \n"]},{"name":"stdout","output_type":"stream","text":["Saving composite images...\n"," 100% |█████████████████| 527/527 [12.7s elapsed, 0s remaining, 42.7 samples/s]      \n"]},{"name":"stderr","output_type":"stream","text":["INFO:eta.core.utils: 100% |█████████████████| 527/527 [12.7s elapsed, 0s remaining, 42.7 samples/s]      \n"]}],"source":["save_composite(train_view, composite_train_output_dir, label_field)\n","save_composite(test_view, composite_test_output_dir, label_field)"]},{"cell_type":"markdown","metadata":{"id":"GK3hyt5AsfrE"},"source":["### **Turn preprocessed images into a custom dataset**"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":4614,"status":"ok","timestamp":1699239508950,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"fKDrPnVxsk53"},"outputs":[],"source":["import torch\n","from torchvision import transforms, datasets"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1699239508951,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"wNwdUef7srjX"},"outputs":[],"source":["data_transform = transforms.Compose([transforms.ToTensor(),\n","                                     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                                          std=[0.229, 0.224, 0.225]),\n","                                     transforms.Resize([400, 600])])"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1699239508951,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"ZbpgKMxDs6F_","outputId":"95754eae-136e-4182-9b5a-99c6b254cda6"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nforeground_dataset = datasets.ImageFolder(root='/data/foreground',\\n                                          transform=data_transform)\\n\""]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","foreground_dataset = datasets.ImageFolder(root='/data/foreground',\n","                                          transform=data_transform)\n","\"\"\""]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699239508951,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"ie0gwKcMtdWT","outputId":"1182ff88-a921-44ff-c5de-21452628933d"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nfore_dataset_loader = torch.utils.data.DataLoader(foreground_dataset,\\n                                                  batch_size=64, shuffle=True,\\n                                                  num_workers=1)\\n'"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","fore_dataset_loader = torch.utils.data.DataLoader(foreground_dataset,\n","                                                  batch_size=64, shuffle=True,\n","                                                  num_workers=1)\n","\"\"\""]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":322,"status":"ok","timestamp":1699239509267,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"noHe6Mzj5Eoq"},"outputs":[],"source":["composite_train_dataset = datasets.ImageFolder(root='/data/composite/train',\n","                                               transform=data_transform)\n","composite_test_dataset = datasets.ImageFolder(root='/data/composite/test',\n","                                              transform=data_transform)\n","foreground_train_dataset = datasets.ImageFolder(root='/data/foreground/train',\n","                                                transform=data_transform)\n","foreground_test_dataset = datasets.ImageFolder(root='/data/foreground/test',\n","                                               transform=data_transform)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1699239509267,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"PiGz-N6mNM8y","outputId":"3077cc51-1bf5-47ce-8289-6ef716b4b97c"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\ngenerator = torch.Generator().manual_seed(42)\\ncomposite_train, composite_test = torch.utils.data.random_split(composite_dataset,\\n                                                                [int(len(composite_dataset)*0.8),\\n                                                                 int(len(composite_dataset)*0.2)],\\n                                                                generator=generator)\\n'"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","generator = torch.Generator().manual_seed(42)\n","composite_train, composite_test = torch.utils.data.random_split(composite_dataset,\n","                                                                [int(len(composite_dataset)*0.8),\n","                                                                 int(len(composite_dataset)*0.2)],\n","                                                                generator=generator)\n","\"\"\""]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1699239509267,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"I5ma6u8k5I97"},"outputs":[],"source":["\"\"\"\n","composite_dataset_loader = torch.utils.data.DataLoader(composite_dataset,\n","                                                       batch_size=64, shuffle=True,\n","                                                       num_workers=1)\n","\"\"\"\n","foreground_train_loader = torch.utils.data.DataLoader(foreground_train_dataset,\n","                                                      batch_size=64, shuffle=True,\n","                                                      num_workers=1)\n","foreground_test_loader = torch.utils.data.DataLoader(foreground_test_dataset,\n","                                                     batch_size=16, shuffle=True,\n","                                                     num_workers=1)\n","composite_train_loader = torch.utils.data.DataLoader(composite_train_dataset,\n","                                                     batch_size=64, shuffle=True,\n","                                                     num_workers=1)\n","composite_test_loader = torch.utils.data.DataLoader(composite_test_dataset,\n","                                                    batch_size=16, shuffle=True,\n","                                                    num_workers=1)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1699239509267,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"XnaQGxGgttKI","outputId":"cc96ffbd-6b36-4b1f-cc00-3e910ed3efdd"},"outputs":[{"name":"stdout","output_type":"stream","text":["['airplane', 'horse', 'toilet', 'train']\n","['airplane', 'horse', 'toilet', 'train']\n","['airplane', 'horse', 'toilet', 'train']\n","['airplane', 'horse', 'toilet', 'train']\n"]}],"source":["# print(fore_dataset_loader.dataset.classes)\n","print(foreground_train_loader.dataset.classes)\n","print(foreground_test_loader.dataset.classes)\n","print(composite_train_loader.dataset.classes)\n","print(composite_test_loader.dataset.classes)"]},{"cell_type":"markdown","metadata":{"id":"b3GmgFNAY41O"},"source":["**Code reference:** https://debuggercafe.com/training-resnet18-from-scratch-using-pytorch/"]},{"cell_type":"markdown","metadata":{"id":"4BbXlcapMb5U"},"source":["### **Build ResNet-18**"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1699239509267,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"AOsFCZioMhwI"},"outputs":[],"source":["import torch.nn as nn\n","\n","from torch import Tensor\n","from typing import Type"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1699239509268,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"-deWpe4fMnIq"},"outputs":[],"source":["class BasicBlock(nn.Module):\n","    def __init__(\n","        self,\n","        in_channels: int,\n","        out_channels: int,\n","        stride: int = 1,\n","        expansion: int = 1,\n","        downsample: nn.Module = None\n","    ) -\u003e None:\n","        super(BasicBlock, self).__init__()\n","        # Multiplicative factor for the subsequent conv2d layer's output channels\n","        # It is 1 for ResNet18 and ResNet34\n","        self.expansion = expansion\n","        self.downsample = downsample\n","        self.conv1 = nn.Conv2d(\n","            in_channels,\n","            out_channels,\n","            kernel_size=3,\n","            stride=stride,\n","            padding=1,\n","            bias=False\n","        )\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(\n","            out_channels,\n","            out_channels*self.expansion,\n","            kernel_size=3,\n","            padding=1,\n","            bias=False\n","        )\n","        self.bn2 = nn.BatchNorm2d(out_channels*self.expansion)\n","\n","    def forward(self, x: Tensor) -\u003e Tensor:\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","        return  out"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1699239509268,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"J1e09e27Mvyl"},"outputs":[],"source":["class ResNet(nn.Module):\n","    def __init__(\n","        self,\n","        img_channels: int,\n","        num_layers: int,\n","        block: Type[BasicBlock],\n","        num_classes: int  = 1000\n","    ) -\u003e None:\n","        super(ResNet, self).__init__()\n","        if num_layers == 18:\n","            # The following `layers` list defines the number of `BasicBlock`\n","            # to use to build the network and how many basic blocks to stack together\n","            layers = [2, 2, 2, 2]\n","            self.expansion = 1\n","\n","        self.in_channels = 64\n","        # All ResNets (18 to 152) contain a Conv2d =\u003e BN =\u003e ReLU for the first\n","        # three layers. Here, kernel size is 7\n","        self.conv1 = nn.Conv2d(\n","            in_channels=img_channels,\n","            out_channels=self.in_channels,\n","            kernel_size=7,\n","            stride=2,\n","            padding=3,\n","            bias=False\n","        )\n","        self.bn1 = nn.BatchNorm2d(self.in_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n","\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512*self.expansion, num_classes)\n","\n","    def _make_layer(\n","        self,\n","        block: Type[BasicBlock],\n","        out_channels: int,\n","        blocks: int,\n","        stride: int = 1\n","    ) -\u003e nn.Sequential:\n","        downsample = None\n","        if stride != 1:\n","            \"\"\"\n","            This should pass from `layer2` to `layer4` or\n","            when building ResNets50 and above. Section 3.3 of the paper\n","            Deep Residual Learning for Image Recognition\n","            (https://arxiv.org/pdf/1512.03385v1.pdf).\n","            \"\"\"\n","            downsample = nn.Sequential(\n","                nn.Conv2d(\n","                    self.in_channels,\n","                    out_channels*self.expansion,\n","                    kernel_size=1,\n","                    stride=stride,\n","                    bias=False\n","                ),\n","                nn.BatchNorm2d(out_channels * self.expansion),\n","            )\n","        layers = []\n","        layers.append(\n","            block(\n","                self.in_channels, out_channels, stride, self.expansion, downsample\n","            )\n","        )\n","        self.in_channels = out_channels * self.expansion\n","\n","        for i in range(1, blocks):\n","            layers.append(block(\n","                self.in_channels,\n","                out_channels,\n","                expansion=self.expansion\n","            ))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x: Tensor) -\u003e Tensor:\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        # The spatial dimension of the final layer's feature\n","        # map should be (7, 7) for all ResNets\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"DVg_kXZHQH6O"},"source":["### **Utils**"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1699239509268,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"oRF75C9ZQExc"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import os\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","\n","plt.style.use('ggplot')"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1699239509268,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"tYDNRa0YQRrV"},"outputs":[],"source":["def save_plots(train_acc, fore_valid_acc, composite_valid_acc, train_loss, fore_valid_loss, composite_valid_loss, name=None):\n","    \"\"\"\n","    Function to save the loss and accuracy plots to disk.\n","    \"\"\"\n","    # Accuracy plots\n","    plt.figure(figsize=(10, 7))\n","    plt.ylim(0, 105)\n","    plt.plot(\n","        train_acc, color='tab:blue', linestyle='-',\n","        label='train accuracy'\n","    )\n","    plt.plot(\n","        fore_valid_acc, color='tab:red', linestyle='-',\n","        label='foreground validataion accuracy'\n","    )\n","    plt.plot(\n","        composite_valid_acc, color='tab:green', linestyle='-',\n","        label='composite validataion accuracy'\n","    )\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","    if not os.path.exists('outputs'):\n","        os.makedirs('outputs')\n","    plt.savefig(os.path.join('outputs', name+'_accuracy.png'))\n","\n","    # Loss plots\n","    plt.figure(figsize=(10, 7))\n","    plt.plot(\n","        train_loss, color='tab:blue', linestyle='-',\n","        label='train loss'\n","    )\n","    plt.plot(\n","        fore_valid_loss, color='tab:red', linestyle='-',\n","        label='foreground validataion loss'\n","    )\n","    plt.plot(\n","        composite_valid_loss, color='tab:green', linestyle='-',\n","        label='composite validataion loss'\n","    )\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.savefig(os.path.join('outputs', name+'_loss.png'))"]},{"cell_type":"markdown","metadata":{"id":"Al4ZxHChQUN4"},"source":["### **Set up for training**"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1699239509268,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"tWqOWUlPQWUh"},"outputs":[],"source":["from tqdm import tqdm"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1699239509268,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"Xa_NQE5lQYvJ"},"outputs":[],"source":["def train(model, trainloader, optimizer, criterion, device):\n","    model.train()\n","    print('Training...')\n","    train_running_loss = 0.0\n","    train_running_correct = 0\n","    counter = 0\n","    for i, data in tqdm(enumerate(trainloader), total=len(trainloader)):\n","        counter += 1\n","        image, labels = data\n","        image = image.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        # Forward pass\n","        outputs = model(image)\n","        # Calculate loss\n","        loss = criterion(outputs, labels)\n","        train_running_loss += loss.item()\n","        # Calculate accuracy\n","        _, preds = torch.max(outputs.data, 1)\n","        train_running_correct += (preds == labels).sum().item()\n","        # Backpropagation\n","        loss.backward()\n","        # Update weights\n","        optimizer.step()\n","\n","    # Loss \u0026 accuracy for the complete epoch\n","    epoch_loss = train_running_loss / counter\n","    # epoch_acc = 100. * (train_running_correct / len(trainloader.dataset))\n","    epoch_acc = 100. * (train_running_correct / len(trainloader.dataset))\n","    return epoch_loss, epoch_acc"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699239509268,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"9Z9iK7D7QcJw"},"outputs":[],"source":["def validate(model, testloader, criterion, device):\n","    model.eval()\n","    print('Validation')\n","    valid_running_loss = 0.0\n","    valid_running_correct = 0\n","    counter = 0\n","\n","    # Keep track of misclassified images\n","    misclassified = {}\n","\n","    # Keep track of performance on different classes\n","    perf_classes = {0: [0, 0], 1: [0, 0], 2: [0, 0], 3: [0, 0]}\n","\n","    with torch.no_grad():\n","        for i, data in tqdm(enumerate(testloader), total=len(testloader)):\n","            counter += 1\n","\n","            image, labels = data\n","            image_filename = testloader.dataset.imgs[i][0]\n","            image = image.to(device)\n","            labels = labels.to(device)\n","            # Forward pass\n","            outputs = model(image)\n","            # Calculate loss\n","            loss = criterion(outputs, labels)\n","            valid_running_loss += loss.item()\n","            # Calculate accuracy\n","            _, preds = torch.max(outputs.data, 1)\n","            valid_running_correct += (preds == labels).sum().item()\n","            # Update misclassified\n","            for j in range(len(preds)):\n","                if preds[j] != labels[j]:\n","                    if image_filename not in misclassified:\n","                        misclassified[image_filename] = 1\n","                    else:\n","                        misclassified[image_filename] += 1\n","                category = labels[j].item()\n","                perf_classes[category][0] += 1\n","                if preds[j] == labels[j]:\n","                    perf_classes[category][1] += 1\n","\n","    # Loss \u0026 accuracy for the complete epoch\n","    epoch_loss = valid_running_loss / counter\n","    epoch_acc = 100. * (valid_running_correct / len(testloader.dataset))\n","    return epoch_loss, epoch_acc, misclassified, perf_classes"]},{"cell_type":"markdown","metadata":{"id":"HN3-dy-3QgKX"},"source":["### **Training**"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699239509268,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"v5O-eI3dQv37"},"outputs":[],"source":["import torch.optim as optim\n","import numpy as np\n","import random"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1699239509268,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"0jCsqa69QxeD"},"outputs":[],"source":["# Set seed\n","seed = 42\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = True\n","np.random.seed(seed)\n","random.seed(seed)"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699239509269,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"NfeFNuaLQzWE"},"outputs":[],"source":["epochs = 60\n","epochs_fore = 40\n","batch_size = 64\n","learning_rate = 0.01\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":5827,"status":"ok","timestamp":1699239515089,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"SkZXo4E9Q3SR"},"outputs":[],"source":["model = ResNet(img_channels=3, num_layers=18, block=BasicBlock, num_classes=4).to(device)\n","plot_name = 'ResNet-18 on COCO Foreground (40) + Composite (40)'"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1699239515089,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"evpnT6TxQ6QT","outputId":"0632fb3b-d7b3-4d31-f11e-ca2f4f41c9d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["11,178,564 total parameters.\n","11,178,564 training parameters.\n"]}],"source":["# Total parameters \u0026 trainable parameters\n","total_params = sum(p.numel() for p in model.parameters())\n","print(f\"{total_params:,} total parameters.\")\n","total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(f\"{total_trainable_params:,} training parameters.\")\n","\n","# Optimizer\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n","\n","# Loss function\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":18716167,"status":"ok","timestamp":1699258231238,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"sXmTDlJGQ8jL","outputId":"e764e9fa-35de-48e2-b4f9-b883bd6d7dbb"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO]: Epoch 1 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:50\u003c00:00,  1.10s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  2.80it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.696, training acc: 73.506\n","Foreground validation loss: 0.835, foreground validation acc: 71.720\n","Composite validation loss: 2.340, composite validation acc: 39.089\n","--------------------------------------------------\n","[INFO]: Epoch 2 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:03\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.00it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.455, training acc: 83.692\n","Foreground validation loss: 0.466, foreground validation acc: 80.764\n","Composite validation loss: 1.680, composite validation acc: 51.233\n","--------------------------------------------------\n","[INFO]: Epoch 3 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:03\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.03it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  3.00it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.373, training acc: 86.724\n","Foreground validation loss: 1.966, foreground validation acc: 37.834\n","Composite validation loss: 2.829, composite validation acc: 29.981\n","--------------------------------------------------\n","[INFO]: Epoch 4 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:03\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.97it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  2.95it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.316, training acc: 88.998\n","Foreground validation loss: 0.418, foreground validation acc: 83.312\n","Composite validation loss: 1.693, composite validation acc: 51.613\n","--------------------------------------------------\n","[INFO]: Epoch 5 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.06it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.272, training acc: 90.284\n","Foreground validation loss: 0.558, foreground validation acc: 79.873\n","Composite validation loss: 1.171, composite validation acc: 56.546\n","--------------------------------------------------\n","[INFO]: Epoch 6 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:03\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.07it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.235, training acc: 91.677\n","Foreground validation loss: 0.823, foreground validation acc: 77.325\n","Composite validation loss: 3.149, composite validation acc: 31.499\n","--------------------------------------------------\n","[INFO]: Epoch 7 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:03\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.00it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.01it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.207, training acc: 92.621\n","Foreground validation loss: 0.308, foreground validation acc: 88.662\n","Composite validation loss: 1.596, composite validation acc: 57.495\n","--------------------------------------------------\n","[INFO]: Epoch 8 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.09it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.03it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.172, training acc: 93.912\n","Foreground validation loss: 0.464, foreground validation acc: 83.057\n","Composite validation loss: 1.235, composite validation acc: 58.634\n","--------------------------------------------------\n","[INFO]: Epoch 9 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:03\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.145, training acc: 95.056\n","Foreground validation loss: 0.278, foreground validation acc: 90.191\n","Composite validation loss: 1.005, composite validation acc: 66.224\n","--------------------------------------------------\n","[INFO]: Epoch 10 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:03\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.94it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.117, training acc: 95.995\n","Foreground validation loss: 0.240, foreground validation acc: 91.338\n","Composite validation loss: 1.454, composite validation acc: 59.583\n","--------------------------------------------------\n","[INFO]: Epoch 11 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  2.99it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.094, training acc: 96.704\n","Foreground validation loss: 0.651, foreground validation acc: 85.987\n","Composite validation loss: 1.341, composite validation acc: 67.932\n","--------------------------------------------------\n","[INFO]: Epoch 12 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:03\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.93it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  2.98it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.073, training acc: 97.565\n","Foreground validation loss: 0.422, foreground validation acc: 89.554\n","Composite validation loss: 1.482, composite validation acc: 62.429\n","--------------------------------------------------\n","[INFO]: Epoch 13 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.96it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  2.96it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.054, training acc: 98.298\n","Foreground validation loss: 0.246, foreground validation acc: 91.083\n","Composite validation loss: 1.580, composite validation acc: 60.911\n","--------------------------------------------------\n","[INFO]: Epoch 14 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.03it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  2.96it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.047, training acc: 98.533\n","Foreground validation loss: 2.468, foreground validation acc: 70.191\n","Composite validation loss: 6.385, composite validation acc: 29.602\n","--------------------------------------------------\n","[INFO]: Epoch 15 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.01it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.00it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.037, training acc: 98.856\n","Foreground validation loss: 0.389, foreground validation acc: 86.752\n","Composite validation loss: 1.280, composite validation acc: 68.121\n","--------------------------------------------------\n","[INFO]: Epoch 16 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:03\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.88it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  2.99it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.023, training acc: 99.423\n","Foreground validation loss: 0.307, foreground validation acc: 90.446\n","Composite validation loss: 1.721, composite validation acc: 60.152\n","--------------------------------------------------\n","[INFO]: Epoch 17 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.88it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.03it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.016, training acc: 99.623\n","Foreground validation loss: 0.203, foreground validation acc: 93.631\n","Composite validation loss: 1.640, composite validation acc: 58.634\n","--------------------------------------------------\n","[INFO]: Epoch 18 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.92it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.04it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.015, training acc: 99.648\n","Foreground validation loss: 0.269, foreground validation acc: 91.083\n","Composite validation loss: 2.239, composite validation acc: 55.028\n","--------------------------------------------------\n","[INFO]: Epoch 19 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.95it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  2.95it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.014, training acc: 99.638\n","Foreground validation loss: 0.271, foreground validation acc: 92.102\n","Composite validation loss: 1.865, composite validation acc: 60.721\n","--------------------------------------------------\n","[INFO]: Epoch 20 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  5.00it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  2.98it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.013, training acc: 99.677\n","Foreground validation loss: 0.361, foreground validation acc: 90.318\n","Composite validation loss: 1.796, composite validation acc: 61.480\n","--------------------------------------------------\n","[INFO]: Epoch 21 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.99it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.007, training acc: 99.848\n","Foreground validation loss: 0.242, foreground validation acc: 92.866\n","Composite validation loss: 1.416, composite validation acc: 66.603\n","--------------------------------------------------\n","[INFO]: Epoch 22 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.06it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.006, training acc: 99.892\n","Foreground validation loss: 0.297, foreground validation acc: 90.318\n","Composite validation loss: 2.426, composite validation acc: 56.926\n","--------------------------------------------------\n","[INFO]: Epoch 23 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.07it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.01it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.006, training acc: 99.883\n","Foreground validation loss: 0.432, foreground validation acc: 92.357\n","Composite validation loss: 2.092, composite validation acc: 55.408\n","--------------------------------------------------\n","[INFO]: Epoch 24 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.97it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.005, training acc: 99.897\n","Foreground validation loss: 0.333, foreground validation acc: 90.701\n","Composite validation loss: 1.411, composite validation acc: 67.742\n","--------------------------------------------------\n","[INFO]: Epoch 25 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.06it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.003, training acc: 99.961\n","Foreground validation loss: 0.232, foreground validation acc: 93.121\n","Composite validation loss: 1.774, composite validation acc: 59.772\n","--------------------------------------------------\n","[INFO]: Epoch 26 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.99it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.003, training acc: 99.956\n","Foreground validation loss: 0.222, foreground validation acc: 93.121\n","Composite validation loss: 1.483, composite validation acc: 65.275\n","--------------------------------------------------\n","[INFO]: Epoch 27 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.07it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.06it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.002, training acc: 99.980\n","Foreground validation loss: 0.263, foreground validation acc: 91.592\n","Composite validation loss: 1.638, composite validation acc: 63.567\n","--------------------------------------------------\n","[INFO]: Epoch 28 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.07it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.001, training acc: 100.000\n","Foreground validation loss: 0.235, foreground validation acc: 92.102\n","Composite validation loss: 1.938, composite validation acc: 58.254\n","--------------------------------------------------\n","[INFO]: Epoch 29 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  5.00it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.06it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.001, training acc: 99.990\n","Foreground validation loss: 0.213, foreground validation acc: 92.994\n","Composite validation loss: 1.619, composite validation acc: 63.567\n","--------------------------------------------------\n","[INFO]: Epoch 30 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.03it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.07it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.001, training acc: 100.000\n","Foreground validation loss: 0.224, foreground validation acc: 92.611\n","Composite validation loss: 1.647, composite validation acc: 62.239\n","--------------------------------------------------\n","[INFO]: Epoch 31 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.06it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.06it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.001, training acc: 100.000\n","Foreground validation loss: 0.219, foreground validation acc: 92.739\n","Composite validation loss: 1.818, composite validation acc: 60.911\n","--------------------------------------------------\n","[INFO]: Epoch 32 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.03it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.001, training acc: 100.000\n","Foreground validation loss: 0.237, foreground validation acc: 91.720\n","Composite validation loss: 1.816, composite validation acc: 60.531\n","--------------------------------------------------\n","[INFO]: Epoch 33 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.92it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  2.96it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.001, training acc: 100.000\n","Foreground validation loss: 0.224, foreground validation acc: 93.121\n","Composite validation loss: 1.674, composite validation acc: 62.808\n","--------------------------------------------------\n","[INFO]: Epoch 34 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.08it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  2.98it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.002, training acc: 99.971\n","Foreground validation loss: 0.369, foreground validation acc: 91.465\n","Composite validation loss: 1.573, composite validation acc: 63.567\n","--------------------------------------------------\n","[INFO]: Epoch 35 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.01it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.04it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.001, training acc: 99.990\n","Foreground validation loss: 0.224, foreground validation acc: 92.994\n","Composite validation loss: 1.590, composite validation acc: 62.998\n","--------------------------------------------------\n","[INFO]: Epoch 36 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.97it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.04it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.001, training acc: 99.995\n","Foreground validation loss: 0.263, foreground validation acc: 92.102\n","Composite validation loss: 1.777, composite validation acc: 59.393\n","--------------------------------------------------\n","[INFO]: Epoch 37 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.99it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.003, training acc: 99.927\n","Foreground validation loss: 0.246, foreground validation acc: 92.484\n","Composite validation loss: 1.749, composite validation acc: 63.188\n","--------------------------------------------------\n","[INFO]: Epoch 38 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.98it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.04it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.001, training acc: 99.990\n","Foreground validation loss: 0.241, foreground validation acc: 93.758\n","Composite validation loss: 1.758, composite validation acc: 62.429\n","--------------------------------------------------\n","[INFO]: Epoch 39 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.06it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.001, training acc: 99.995\n","Foreground validation loss: 0.253, foreground validation acc: 93.121\n","Composite validation loss: 1.801, composite validation acc: 62.049\n","--------------------------------------------------\n","[INFO]: Epoch 40 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/320 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 320/320 [05:04\u003c00:00,  1.05it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.06it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Saving model...\n","Training loss: 0.001, training acc: 99.995\n","Foreground validation loss: 0.237, foreground validation acc: 93.376\n","Composite validation loss: 1.725, composite validation acc: 63.188\n","--------------------------------------------------\n","[INFO]: Epoch 41 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:30\u003c00:00,  1.35s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.08it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.04it/s]"]},{"name":"stdout","output_type":"stream","text":["Saving model...\n","Training loss: 0.790, training acc: 76.437\n","Foreground validation loss: 1.762, foreground validation acc: 45.987\n","Composite validation loss: 0.834, composite validation acc: 71.537\n","--------------------------------------------------\n","[INFO]: Epoch 42 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:17\u003c00:00,  1.28s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.03it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.00it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.408, training acc: 85.107\n","Foreground validation loss: 1.646, foreground validation acc: 55.669\n","Composite validation loss: 0.839, composite validation acc: 73.245\n","--------------------------------------------------\n","[INFO]: Epoch 43 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:18\u003c00:00,  1.29s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.98it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.312, training acc: 88.803\n","Foreground validation loss: 0.835, foreground validation acc: 75.287\n","Composite validation loss: 1.568, composite validation acc: 63.757\n","--------------------------------------------------\n","[INFO]: Epoch 44 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:18\u003c00:00,  1.28s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.03it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.04it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.220, training acc: 92.468\n","Foreground validation loss: 1.086, foreground validation acc: 68.535\n","Composite validation loss: 0.845, composite validation acc: 76.091\n","--------------------------------------------------\n","[INFO]: Epoch 45 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:17\u003c00:00,  1.28s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.04it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.03it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.134, training acc: 95.548\n","Foreground validation loss: 3.103, foreground validation acc: 57.325\n","Composite validation loss: 2.668, composite validation acc: 62.049\n","--------------------------------------------------\n","[INFO]: Epoch 46 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:21\u003c00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.99it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.104, training acc: 96.312\n","Foreground validation loss: 1.924, foreground validation acc: 50.828\n","Composite validation loss: 1.433, composite validation acc: 70.398\n","--------------------------------------------------\n","[INFO]: Epoch 47 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:21\u003c00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.99it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  2.98it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.065, training acc: 97.942\n","Foreground validation loss: 1.463, foreground validation acc: 63.694\n","Composite validation loss: 1.286, composite validation acc: 67.742\n","--------------------------------------------------\n","[INFO]: Epoch 48 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:21\u003c00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.96it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.037, training acc: 99.166\n","Foreground validation loss: 1.239, foreground validation acc: 69.554\n","Composite validation loss: 0.967, composite validation acc: 78.368\n","--------------------------------------------------\n","[INFO]: Epoch 49 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:20\u003c00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.01it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.01it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.021, training acc: 99.571\n","Foreground validation loss: 1.289, foreground validation acc: 66.369\n","Composite validation loss: 0.702, composite validation acc: 81.784\n","--------------------------------------------------\n","[INFO]: Epoch 50 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:18\u003c00:00,  1.29s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.07it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  2.98it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.009, training acc: 99.945\n","Foreground validation loss: 1.019, foreground validation acc: 74.904\n","Composite validation loss: 0.699, composite validation acc: 82.922\n","--------------------------------------------------\n","[INFO]: Epoch 51 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:20\u003c00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.82it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  2.88it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.006, training acc: 99.930\n","Foreground validation loss: 1.207, foreground validation acc: 72.357\n","Composite validation loss: 1.039, composite validation acc: 78.558\n","--------------------------------------------------\n","[INFO]: Epoch 52 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:24\u003c00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.02it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.00it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.005, training acc: 99.977\n","Foreground validation loss: 1.067, foreground validation acc: 73.503\n","Composite validation loss: 0.622, composite validation acc: 82.922\n","--------------------------------------------------\n","[INFO]: Epoch 53 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:23\u003c00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.92it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  2.95it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.004, training acc: 99.977\n","Foreground validation loss: 0.941, foreground validation acc: 77.580\n","Composite validation loss: 0.750, composite validation acc: 82.163\n","--------------------------------------------------\n","[INFO]: Epoch 54 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:19\u003c00:00,  1.29s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:09\u003c00:00,  5.01it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.01it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.003, training acc: 99.984\n","Foreground validation loss: 1.026, foreground validation acc: 76.051\n","Composite validation loss: 0.651, composite validation acc: 83.681\n","--------------------------------------------------\n","[INFO]: Epoch 55 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:21\u003c00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.97it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  2.96it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.003, training acc: 99.984\n","Foreground validation loss: 1.122, foreground validation acc: 76.178\n","Composite validation loss: 0.668, composite validation acc: 83.681\n","--------------------------------------------------\n","[INFO]: Epoch 56 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:21\u003c00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.90it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.03it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.002, training acc: 99.992\n","Foreground validation loss: 1.064, foreground validation acc: 77.325\n","Composite validation loss: 0.705, composite validation acc: 82.922\n","--------------------------------------------------\n","[INFO]: Epoch 57 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:22\u003c00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.99it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  2.96it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.002, training acc: 99.984\n","Foreground validation loss: 1.163, foreground validation acc: 74.904\n","Composite validation loss: 0.682, composite validation acc: 84.061\n","--------------------------------------------------\n","[INFO]: Epoch 58 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:20\u003c00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.93it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  2.99it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.003, training acc: 99.977\n","Foreground validation loss: 1.120, foreground validation acc: 75.287\n","Composite validation loss: 0.729, composite validation acc: 83.871\n","--------------------------------------------------\n","[INFO]: Epoch 59 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:24\u003c00:00,  1.32s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.86it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:11\u003c00:00,  2.94it/s]"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.001, training acc: 99.992\n","Foreground validation loss: 1.304, foreground validation acc: 73.376\n","Composite validation loss: 0.687, composite validation acc: 84.061\n","--------------------------------------------------\n","[INFO]: Epoch 60 of 60\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/201 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 201/201 [04:21\u003c00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/50 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 50/50 [00:10\u003c00:00,  4.98it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/33 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","100%|██████████| 33/33 [00:10\u003c00:00,  3.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 0.001, training acc: 99.992\n","Foreground validation loss: 1.204, foreground validation acc: 74.522\n","Composite validation loss: 0.683, composite validation acc: 84.061\n","--------------------------------------------------\n","TRAINING COMPLETE\n"]},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 1000x700 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 1000x700 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# Lists to keep track of losses \u0026 accuracies\n","train_loss, fore_valid_loss, composite_valid_loss = [], [], []\n","train_acc, fore_valid_acc, composite_valid_acc = [], [], []\n","\n","# Keep track of misclassified images\n","misclassified_fore_all = {}\n","misclassified_composite_all = {}\n","\n","# Keep track of performance on different classes\n","perf_classes_fore_all = {0: [0, 0], 1: [0, 0], 2: [0, 0], 3: [0, 0]}\n","perf_classes_composite_all = {0: [0, 0], 1: [0, 0], 2: [0, 0], 3: [0, 0]}\n","\n","# Start training\n","for epoch in range(epochs):\n","    print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n","    if epoch \u003c epochs_fore:\n","      train_epoch_loss, train_epoch_acc = train(model,\n","                                                foreground_train_loader,\n","                                                optimizer,\n","                                                criterion,\n","                                                device)\n","    else:\n","      train_epoch_loss, train_epoch_acc = train(model,\n","                                                composite_train_loader,\n","                                                optimizer,\n","                                                criterion,\n","                                                device)\n","\n","    fore_valid_epoch_loss, fore_valid_epoch_acc, fore_misclassified, fore_perf_classes = validate(model,\n","                                                                                                  foreground_test_loader,\n","                                                                                                  criterion,\n","                                                                                                  device)\n","    composite_valid_epoch_loss, composite_valid_epoch_acc, composite_misclassified, composite_perf_classes = validate(model,\n","                                                                                                                      composite_test_loader,\n","                                                                                                                      criterion,\n","                                                                                                                      device)\n","\n","    train_loss.append(train_epoch_loss)\n","    fore_valid_loss.append(fore_valid_epoch_loss)\n","    composite_valid_loss.append(composite_valid_epoch_loss)\n","    train_acc.append(train_epoch_acc)\n","    fore_valid_acc.append(fore_valid_epoch_acc)\n","    composite_valid_acc.append(composite_valid_epoch_acc)\n","\n","    if epoch == epochs_fore - 1:\n","      print('Saving model...')\n","      torch.save(model.state_dict(), '/content/drive/MyDrive/Curriculum Learning Experiment/Model Weights/resnet18_fore40+composite20_pre_composite.pt')\n","    if epoch == epochs_fore:\n","      print('Saving model...')\n","      torch.save(model.state_dict(), '/content/drive/MyDrive/Curriculum Learning Experiment/Model Weights/resnet18_fore40+composite20_post_composite.pt')\n","\n","    for k, v in fore_misclassified.items():\n","        if k in misclassified_fore_all:\n","            misclassified_fore_all[k] += v\n","        else:\n","            misclassified_fore_all[k] = v\n","\n","    for k, v in composite_misclassified.items():\n","        if k in misclassified_composite_all:\n","            misclassified_composite_all[k] += v\n","        else:\n","            misclassified_composite_all[k] = v\n","\n","    for category, [total, correct] in fore_perf_classes.items():\n","        if k in perf_classes_fore_all:\n","            perf_classes_fore_all[category][0] += total\n","            perf_classes_fore_all[category][1] += correct\n","        else:\n","            perf_classes_fore_all[category] = [total, correct]\n","\n","    for category, [total, correct] in composite_perf_classes.items():\n","        if k in perf_classes_composite_all:\n","            perf_classes_composite_all[category][0] += total\n","            perf_classes_composite_all[category][1] += correct\n","        else:\n","            perf_classes_composite_all[category] = [total, correct]\n","\n","    print(f\"Training loss: {train_epoch_loss:.3f}, training acc: {train_epoch_acc:.3f}\")\n","    print(f\"Foreground validation loss: {fore_valid_epoch_loss:.3f}, foreground validation acc: {fore_valid_epoch_acc:.3f}\")\n","    print(f\"Composite validation loss: {composite_valid_epoch_loss:.3f}, composite validation acc: {composite_valid_epoch_acc:.3f}\")\n","    print('-'*50)\n","\n","# Save the loss \u0026 accuracy plots\n","save_plots(train_acc, fore_valid_acc, composite_valid_acc, train_loss, fore_valid_loss, composite_valid_loss, name=plot_name)\n","print('TRAINING COMPLETE')"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1699258231238,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"bmRrLNmCz-m7"},"outputs":[],"source":["# Save model\n","torch.save(model.state_dict(), '/content/drive/MyDrive/Curriculum Learning Experiment/Model Weights/resnet18_fore40+composite20_final.pt')"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1699258231238,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"Wu9BuMJUMDwB"},"outputs":[],"source":["from collections import Counter\n","\n","fore_most_misclassified = Counter(fore_misclassified).most_common(10)\n","composite_most_misclassified = Counter(composite_misclassified).most_common(10)"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1TVpEZe3YCtjsDWrzeM268RL8T6MxgKHs"},"executionInfo":{"elapsed":20667,"status":"ok","timestamp":1699258251894,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"adjbTXrzps9F","outputId":"89d2c4ac-f436-46b7-a86e-ab62d66a9b89"},"outputs":[],"source":["import io\n","from PIL import Image\n","\n","for img_filename, count in fore_most_misclassified:\n","  with io.open(img_filename, 'rb') as f:\n","    img = Image.open(f)\n","    display(img)\n","\n","for img_filename, count in composite_most_misclassified:\n","  with io.open(img_filename, 'rb') as f:\n","    img = Image.open(f)\n","    display(img)"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1699258251895,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"lRqOiM3uuP7i"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["horse\n","horse\n","horse\n","horse\n","horse\n","horse\n","horse\n","train\n","horse\n","horse\n"]}],"source":["# Get the outputs of the top misclassified images (composite)\n","model.eval()\n","\n","with torch.no_grad():\n","  for img_filename, count in composite_most_misclassified:\n","    with io.open(img_filename, 'rb') as f:\n","      img = Image.open(f)\n","      img_input = data_transform(img)\n","      img_input = img_input.to(device)\n","      img_input = img_input.unsqueeze(0)\n","      output = model(img_input)\n","      print(classes[torch.argmax(output)])"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1699258251895,"user":{"displayName":"Wendy Sun","userId":"06681558649481276740"},"user_tz":300},"id":"dmK4pq5Ng8f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["{0: [143, 95], 1: [273, 182], 2: [179, 156], 3: [190, 152]}\n","{0: [97, 79], 1: [126, 97], 2: [149, 142], 3: [155, 125]}\n"]}],"source":["# Performance of each class - first # = total number of images, second # = number of images classified correctly\n","print(perf_classes_fore_all)\n","print(perf_classes_composite_all)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNfQOQQg/n7JFksp0k3ctDL","machine_shape":"hm","name":"","provenance":[{"file_id":"1MpkPW5SsVv8fupv64RxGCghgWl6JKuVU","timestamp":1695961594111}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}